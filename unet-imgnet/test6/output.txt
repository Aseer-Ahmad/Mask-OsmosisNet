CONFIG : 
{'EPOCHS': 10, 'RESUME_CHECKPOINT': None, 'SAVE_EVERY': 10, 'VAL_EVERY': 10, 'OUTPUT_DIR': 'unet-imgnet', 'EXP_NAME': 'test6', 'TRAIN_FILENAME': 'iids_train.txt', 'TEST_FILENAME': 'iids_test.txt', 'ROOT_DIR': 'dataset\\imagenet\\images\\', 'IMG_SIZE': 128, 'INP_CHANNELS': 1, 'OUT_CHANNELS': 1, 'LR': 0.001, 'WEIGHT_DECAY': 0.0, 'MOMENTUM': 0.9, 'OPT': 'Adam', 'SCHEDL': 'lambdaLR', 'TRAIN_BATCH': 8, 'TEST_BATCH': 8, 'ALPHA': 0.001, 'MASK_DEN': 0.1, 'BIN_METH': 'QUANT', 'OFFSET': None, 'TAU': None, 'ITERATIONS': None, 'NOTE': 'scaling prob to density ; alpha removed from dens ; loss(binaried input again)'}

train test dataset loaded
train size : 100000
test  size  : 1000
model loaded
model summary
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
??DoubleConv: 1-1                        --
|    ??Sequential: 2-1                   --
|    |    ??Conv2d: 3-1                  576
|    |    ??BatchNorm2d: 3-2             128
|    |    ??ReLU: 3-3                    --
|    |    ??Conv2d: 3-4                  36,864
|    |    ??BatchNorm2d: 3-5             128
|    |    ??ReLU: 3-6                    --
??Down: 1-2                              --
|    ??Sequential: 2-2                   --
|    |    ??MaxPool2d: 3-7               --
|    |    ??DoubleConv: 3-8              221,696
??Down: 1-3                              --
|    ??Sequential: 2-3                   --
|    |    ??MaxPool2d: 3-9               --
|    |    ??DoubleConv: 3-10             885,760
??Up: 1-4                                --
|    ??ConvTranspose2d: 2-4              131,200
|    ??DoubleConv: 2-5                   --
|    |    ??Sequential: 3-11             442,880
??Up: 1-5                                --
|    ??ConvTranspose2d: 2-6              32,832
|    ??DoubleConv: 2-7                   --
|    |    ??Sequential: 3-12             110,848
??OutConv: 1-6                           --
|    ??Conv2d: 2-8                       65
=================================================================
Total params: 1,862,977
Trainable params: 1,862,977
Non-trainable params: 0
=================================================================
device : cuda
trainer configurations set
train and test dataloaders created
total train batches  : 12500
total test  batches  : 125
optimizer : Adam, scheduler : lambdaLR loaded
optimizer : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
scheduler : <torch.optim.lr_scheduler.LambdaLR object at 0x0000024EAC748D00>
initializing weights using Kaiming/He Initialization

cleaning torch mem and cache

beginning training ...
Epoch 0/10 , batch 1/12500 
ITERATION : 1, loss : 0.3048556310211902 ITERATION : 2, loss : 0.3048556310211902 ITERATION : 3, loss : 0.3048556310211902 ITERATION : 4, loss : 0.3048556310211902 ITERATION : 5, loss : 0.3048556310211902 ITERATION : 6, loss : 0.3048556310211902 ITERATION : 7, loss : 0.3048556310211902 ITERATION : 8, loss : 0.3048556310211902 ITERATION : 9, loss : 0.3048556310211902 ITERATION : 10, loss : 0.3048556310211902 ITERATION : 11, loss : 0.3048556310211902 ITERATION : 12, loss : 0.3048556310211902 ITERATION : 13, loss : 0.3048556310211902 ITERATION : 14, loss : 0.3048556310211902 ITERATION : 15, loss : 0.3048556310211902 ITERATION : 16, loss : 0.3048556310211902 ITERATION : 17, loss : 0.3048556310211902 ITERATION : 18, loss : 0.3048556310211902 ITERATION : 19, loss : 0.3048556310211902 ITERATION : 20, loss : 0.3048556310211902 ITERATION : 21, loss : 0.3048556310211902 ITERATION : 22, loss : 0.3048556310211902 ITERATION : 23, loss : 0.3048556310211902 ITERATION : 24, loss : 0.3048556310211902 ITERATION : 25, loss : 0.3048556310211902 ITERATION : 26, loss : 0.3048556310211902 ITERATION : 27, loss : 0.3048556310211902 ITERATION : 28, loss : 0.3048556310211902 ITERATION : 29, loss : 0.3048556310211902 ITERATION : 30, loss : 0.3048556310211902 ITERATION : 31, loss : 0.3048556310211902 ITERATION : 32, loss : 0.3048556310211902 ITERATION : 33, loss : 0.3048556310211902 ITERATION : 34, loss : 0.3048556310211902 ITERATION : 35, loss : 0.3048556310211902 ITERATION : 36, loss : 0.3048556310211902 ITERATION : 37, loss : 0.3048556310211902 ITERATION : 38, loss : 0.3048556310211902 ITERATION : 39, loss : 0.3048556310211902 ITERATION : 40, loss : 0.3048556310211902 ITERATION : 41, loss : 0.3048556310211902 ITERATION : 42, loss : 0.3048556310211902 ITERATION : 43, loss : 0.3048556310211902 ITERATION : 44, loss : 0.3048556310211902 ITERATION : 45, loss : 0.3048556310211902 ITERATION : 46, loss : 0.3048556310211902 ITERATION : 47, loss : 0.3048556310211902 ITERATION : 48, loss : 0.3048556310211902 ITERATION : 49, loss : 0.3048556310211902 ITERATION : 50, loss : 0.3048556310211902 ITERATION : 51, loss : 0.3048556310211902 ITERATION : 52, loss : 0.3048556310211902 ITERATION : 53, loss : 0.3048556310211902 ITERATION : 54, loss : 0.3048556310211902 ITERATION : 55, loss : 0.3048556310211902 ITERATION : 56, loss : 0.3048556310211902 ITERATION : 57, loss : 0.3048556310211902 ITERATION : 58, loss : 0.3048556310211902 ITERATION : 59, loss : 0.3048556310211902 ITERATION : 60, loss : 0.3048556310211902 ITERATION : 61, loss : 0.3048556310211902 ITERATION : 62, loss : 0.3048556310211902 ITERATION : 63, loss : 0.3048556310211902 ITERATION : 64, loss : 0.3048556310211902 ITERATION : 65, loss : 0.3048556310211902 ITERATION : 66, loss : 0.3048556310211902 ITERATION : 67, loss : 0.3048556310211902 ITERATION : 68, loss : 0.3048556310211902 ITERATION : 69, loss : 0.3048556310211902 ITERATION : 70, loss : 0.3048556310211902 ITERATION : 71, loss : 0.3048556310211902 ITERATION : 72, loss : 0.3048556310211902 ITERATION : 73, loss : 0.3048556310211902 ITERATION : 74, loss : 0.3048556310211902 ITERATION : 75, loss : 0.3048556310211902 ITERATION : 76, loss : 0.3048556310211902 ITERATION : 77, loss : 0.3048556310211902 ITERATION : 78, loss : 0.3048556310211902 ITERATION : 79, loss : 0.3048556310211902 ITERATION : 80, loss : 0.3048556310211902 ITERATION : 81, loss : 0.3048556310211902 ITERATION : 82, loss : 0.3048556310211902 ITERATION : 83, loss : 0.3048556310211902 ITERATION : 84, loss : 0.3048556310211902 ITERATION : 85, loss : 0.3048556310211902 ITERATION : 86, loss : 0.3048556310211902 ITERATION : 87, loss : 0.3048556310211902 ITERATION : 88, loss : 0.3048556310211902 ITERATION : 89, loss : 0.3048556310211902 ITERATION : 90, loss : 0.3048556310211902 ITERATION : 91, loss : 0.3048556310211902 ITERATION : 92, loss : 0.3048556310211902 ITERATION : 93, loss : 0.3048556310211902 ITERATION : 94, loss : 0.3048556310211902 ITERATION : 95, loss : 0.3048556310211902 ITERATION : 96, loss : 0.3048556310211902 ITERATION : 97, loss : 0.3048556310211902 ITERATION : 98, loss : 0.3048556310211902 ITERATION : 99, loss : 0.3048556310211902 ITERATION : 100, loss : 0.3048556310211902 
ITERATION : 1, loss : 0.7238309097664517 ITERATION : 2, loss : 0.7238309097664517 ITERATION : 3, loss : 0.7238309097664517 ITERATION : 4, loss : 0.7238309097664517 ITERATION : 5, loss : 0.7238309097664517 ITERATION : 6, loss : 0.7238309097664517 ITERATION : 7, loss : 0.7238309097664517 ITERATION : 8, loss : 0.7238309097664517 ITERATION : 9, loss : 0.7238309097664517 ITERATION : 10, loss : 0.7238309097664517 ITERATION : 11, loss : 0.7238309097664517 ITERATION : 12, loss : 0.7238309097664517 ITERATION : 13, loss : 0.7238309097664517 ITERATION : 14, loss : 0.7238309097664517 ITERATION : 15, loss : 0.7238309097664517 ITERATION : 16, loss : 0.7238309097664517 ITERATION : 17, loss : 0.7238309097664517 ITERATION : 18, loss : 0.7238309097664517 ITERATION : 19, loss : 0.7238309097664517 ITERATION : 20, loss : 0.7238309097664517 ITERATION : 21, loss : 0.7238309097664517 ITERATION : 22, loss : 0.7238309097664517 ITERATION : 23, loss : 0.7238309097664517 ITERATION : 24, loss : 0.7238309097664517 ITERATION : 25, loss : 0.7238309097664517 ITERATION : 26, loss : 0.7238309097664517 ITERATION : 27, loss : 0.7238309097664517 ITERATION : 28, loss : 0.7238309097664517 ITERATION : 29, loss : 0.7238309097664517 ITERATION : 30, loss : 0.7238309097664517 ITERATION : 31, loss : 0.7238309097664517 ITERATION : 32, loss : 0.7238309097664517 ITERATION : 33, loss : 0.7238309097664517 ITERATION : 34, loss : 0.7238309097664517 ITERATION : 35, loss : 0.7238309097664517 ITERATION : 36, loss : 0.7238309097664517 ITERATION : 37, loss : 0.7238309097664517 ITERATION : 38, loss : 0.7238309097664517 ITERATION : 39, loss : 0.7238309097664517 ITERATION : 40, loss : 0.7238309097664517 ITERATION : 41, loss : 0.7238309097664517 ITERATION : 42, loss : 0.7238309097664517 ITERATION : 43, loss : 0.7238309097664517 ITERATION : 44, loss : 0.7238309097664517 ITERATION : 45, loss : 0.7238309097664517 ITERATION : 46, loss : 0.7238309097664517 ITERATION : 47, loss : 0.7238309097664517 ITERATION : 48, loss : 0.7238309097664517 ITERATION : 49, loss : 0.7238309097664517 ITERATION : 50, loss : 0.7238309097664517 ITERATION : 51, loss : 0.7238309097664517 ITERATION : 52, loss : 0.7238309097664517 ITERATION : 53, loss : 0.7238309097664517 ITERATION : 54, loss : 0.7238309097664517 ITERATION : 55, loss : 0.7238309097664517 ITERATION : 56, loss : 0.7238309097664517 ITERATION : 57, loss : 0.7238309097664517 ITERATION : 58, loss : 0.7238309097664517 ITERATION : 59, loss : 0.7238309097664517 ITERATION : 60, loss : 0.7238309097664517 ITERATION : 61, loss : 0.7238309097664517 ITERATION : 62, loss : 0.7238309097664517 ITERATION : 63, loss : 0.7238309097664517 ITERATION : 64, loss : 0.7238309097664517 ITERATION : 65, loss : 0.7238309097664517 ITERATION : 66, loss : 0.7238309097664517 ITERATION : 67, loss : 0.7238309097664517 ITERATION : 68, loss : 0.7238309097664517 ITERATION : 69, loss : 0.7238309097664517 ITERATION : 70, loss : 0.7238309097664517 ITERATION : 71, loss : 0.7238309097664517 ITERATION : 72, loss : 0.7238309097664517 ITERATION : 73, loss : 0.7238309097664517 ITERATION : 74, loss : 0.7238309097664517 ITERATION : 75, loss : 0.7238309097664517 ITERATION : 76, loss : 0.7238309097664517 ITERATION : 77, loss : 0.7238309097664517 ITERATION : 78, loss : 0.7238309097664517 ITERATION : 79, loss : 0.7238309097664517 ITERATION : 80, loss : 0.7238309097664517 ITERATION : 81, loss : 0.7238309097664517 ITERATION : 82, loss : 0.7238309097664517 ITERATION : 83, loss : 0.7238309097664517 ITERATION : 84, loss : 0.7238309097664517 ITERATION : 85, loss : 0.7238309097664517 ITERATION : 86, loss : 0.7238309097664517 ITERATION : 87, loss : 0.7238309097664517 ITERATION : 88, loss : 0.7238309097664517 ITERATION : 89, loss : 0.7238309097664517 ITERATION : 90, loss : 0.7238309097664517 ITERATION : 91, loss : 0.7238309097664517 ITERATION : 92, loss : 0.7238309097664517 ITERATION : 93, loss : 0.7238309097664517 ITERATION : 94, loss : 0.7238309097664517 ITERATION : 95, loss : 0.7238309097664517 ITERATION : 96, loss : 0.7238309097664517 ITERATION : 97, loss : 0.7238309097664517 ITERATION : 98, loss : 0.7238309097664517 ITERATION : 99, loss : 0.7238309097664517 ITERATION : 100, loss : 0.7238309097664517 
ITERATION : 1, loss : 0.6150438057895271 ITERATION : 2, loss : 0.6150438057895271 ITERATION : 3, loss : 0.6150438057895271 ITERATION : 4, loss : 0.6150438057895271 ITERATION : 5, loss : 0.6150438057895271 ITERATION : 6, loss : 0.6150438057895271 ITERATION : 7, loss : 0.6150438057895271 ITERATION : 8, loss : 0.6150438057895271 ITERATION : 9, loss : 0.6150438057895271 ITERATION : 10, loss : 0.6150438057895271 ITERATION : 11, loss : 0.6150438057895271 ITERATION : 12, loss : 0.6150438057895271 ITERATION : 13, loss : 0.6150438057895271 ITERATION : 14, loss : 0.6150438057895271 ITERATION : 15, loss : 0.6150438057895271 ITERATION : 16, loss : 0.6150438057895271 ITERATION : 17, loss : 0.6150438057895271 ITERATION : 18, loss : 0.6150438057895271 ITERATION : 19, loss : 0.6150438057895271 ITERATION : 20, loss : 0.6150438057895271 ITERATION : 21, loss : 0.6150438057895271 ITERATION : 22, loss : 0.6150438057895271 ITERATION : 23, loss : 0.6150438057895271 ITERATION : 24, loss : 0.6150438057895271 ITERATION : 25, loss : 0.6150438057895271 ITERATION : 26, loss : 0.6150438057895271 ITERATION : 27, loss : 0.6150438057895271 ITERATION : 28, loss : 0.6150438057895271 ITERATION : 29, loss : 0.6150438057895271 ITERATION : 30, loss : 0.6150438057895271 ITERATION : 31, loss : 0.6150438057895271 ITERATION : 32, loss : 0.6150438057895271 ITERATION : 33, loss : 0.6150438057895271 ITERATION : 34, loss : 0.6150438057895271 ITERATION : 35, loss : 0.6150438057895271 ITERATION : 36, loss : 0.6150438057895271 ITERATION : 37, loss : 0.6150438057895271 ITERATION : 38, loss : 0.6150438057895271 ITERATION : 39, loss : 0.6150438057895271 ITERATION : 40, loss : 0.6150438057895271 ITERATION : 41, loss : 0.6150438057895271 ITERATION : 42, loss : 0.6150438057895271 ITERATION : 43, loss : 0.6150438057895271 ITERATION : 44, loss : 0.6150438057895271 ITERATION : 45, loss : 0.6150438057895271 ITERATION : 46, loss : 0.6150438057895271 ITERATION : 47, loss : 0.6150438057895271 ITERATION : 48, loss : 0.6150438057895271 ITERATION : 49, loss : 0.6150438057895271 ITERATION : 50, loss : 0.6150438057895271 ITERATION : 51, loss : 0.6150438057895271 ITERATION : 52, loss : 0.6150438057895271 ITERATION : 53, loss : 0.6150438057895271 ITERATION : 54, loss : 0.6150438057895271 ITERATION : 55, loss : 0.6150438057895271 ITERATION : 56, loss : 0.6150438057895271 ITERATION : 57, loss : 0.6150438057895271 ITERATION : 58, loss : 0.6150438057895271 ITERATION : 59, loss : 0.6150438057895271 ITERATION : 60, loss : 0.6150438057895271 ITERATION : 61, loss : 0.6150438057895271 ITERATION : 62, loss : 0.6150438057895271 ITERATION : 63, loss : 0.6150438057895271 ITERATION : 64, loss : 0.6150438057895271 ITERATION : 65, loss : 0.6150438057895271 ITERATION : 66, loss : 0.6150438057895271 ITERATION : 67, loss : 0.6150438057895271 ITERATION : 68, loss : 0.6150438057895271 ITERATION : 69, loss : 0.6150438057895271 ITERATION : 70, loss : 0.6150438057895271 ITERATION : 71, loss : 0.6150438057895271 ITERATION : 72, loss : 0.6150438057895271 ITERATION : 73, loss : 0.6150438057895271 ITERATION : 74, loss : 0.6150438057895271 ITERATION : 75, loss : 0.6150438057895271 ITERATION : 76, loss : 0.6150438057895271 ITERATION : 77, loss : 0.6150438057895271 ITERATION : 78, loss : 0.6150438057895271 ITERATION : 79, loss : 0.6150438057895271 ITERATION : 80, loss : 0.6150438057895271 ITERATION : 81, loss : 0.6150438057895271 ITERATION : 82, loss : 0.6150438057895271 ITERATION : 83, loss : 0.6150438057895271 ITERATION : 84, loss : 0.6150438057895271 ITERATION : 85, loss : 0.6150438057895271 ITERATION : 86, loss : 0.6150438057895271 ITERATION : 87, loss : 0.6150438057895271 ITERATION : 88, loss : 0.6150438057895271 ITERATION : 89, loss : 0.6150438057895271 ITERATION : 90, loss : 0.6150438057895271 ITERATION : 91, loss : 0.6150438057895271 ITERATION : 92, loss : 0.6150438057895271 ITERATION : 93, loss : 0.6150438057895271 ITERATION : 94, loss : 0.6150438057895271 ITERATION : 95, loss : 0.6150438057895271 ITERATION : 96, loss : 0.6150438057895271 ITERATION : 97, loss : 0.6150438057895271 ITERATION : 98, loss : 0.6150438057895271 ITERATION : 99, loss : 0.6150438057895271 ITERATION : 100, loss : 0.6150438057895271 
ITERATION : 1, loss : 0.4246550677820337 ITERATION : 2, loss : 0.4246550677820337 ITERATION : 3, loss : 0.4246550677820337 ITERATION : 4, loss : 0.4246550677820337 ITERATION : 5, loss : 0.4246550677820337 ITERATION : 6, loss : 0.4246550677820337 ITERATION : 7, loss : 0.4246550677820337 ITERATION : 8, loss : 0.4246550677820337 ITERATION : 9, loss : 0.4246550677820337 ITERATION : 10, loss : 0.4246550677820337 ITERATION : 11, loss : 0.4246550677820337 ITERATION : 12, loss : 0.4246550677820337 ITERATION : 13, loss : 0.4246550677820337 ITERATION : 14, loss : 0.4246550677820337 ITERATION : 15, loss : 0.4246550677820337 ITERATION : 16, loss : 0.4246550677820337 ITERATION : 17, loss : 0.4246550677820337 ITERATION : 18, loss : 0.4246550677820337 ITERATION : 19, loss : 0.4246550677820337 ITERATION : 20, loss : 0.4246550677820337 ITERATION : 21, loss : 0.4246550677820337 ITERATION : 22, loss : 0.4246550677820337 ITERATION : 23, loss : 0.4246550677820337 ITERATION : 24, loss : 0.4246550677820337 ITERATION : 25, loss : 0.4246550677820337 ITERATION : 26, loss : 0.4246550677820337 ITERATION : 27, loss : 0.4246550677820337 ITERATION : 28, loss : 0.4246550677820337 ITERATION : 29, loss : 0.4246550677820337 ITERATION : 30, loss : 0.4246550677820337 ITERATION : 31, loss : 0.4246550677820337 ITERATION : 32, loss : 0.4246550677820337 ITERATION : 33, loss : 0.4246550677820337 ITERATION : 34, loss : 0.4246550677820337 ITERATION : 35, loss : 0.4246550677820337 ITERATION : 36, loss : 0.4246550677820337 ITERATION : 37, loss : 0.4246550677820337 ITERATION : 38, loss : 0.4246550677820337 ITERATION : 39, loss : 0.4246550677820337 ITERATION : 40, loss : 0.4246550677820337 ITERATION : 41, loss : 0.4246550677820337 ITERATION : 42, loss : 0.4246550677820337 ITERATION : 43, loss : 0.4246550677820337 ITERATION : 44, loss : 0.4246550677820337 ITERATION : 45, loss : 0.4246550677820337 ITERATION : 46, loss : 0.4246550677820337 ITERATION : 47, loss : 0.4246550677820337 ITERATION : 48, loss : 0.4246550677820337 ITERATION : 49, loss : 0.4246550677820337 ITERATION : 50, loss : 0.4246550677820337 ITERATION : 51, loss : 0.4246550677820337 ITERATION : 52, loss : 0.4246550677820337 ITERATION : 53, loss : 0.4246550677820337 ITERATION : 54, loss : 0.4246550677820337 ITERATION : 55, loss : 0.4246550677820337 ITERATION : 56, loss : 0.4246550677820337 ITERATION : 57, loss : 0.4246550677820337 ITERATION : 58, loss : 0.4246550677820337 ITERATION : 59, loss : 0.4246550677820337 ITERATION : 60, loss : 0.4246550677820337 ITERATION : 61, loss : 0.4246550677820337 ITERATION : 62, loss : 0.4246550677820337 ITERATION : 63, loss : 0.4246550677820337 ITERATION : 64, loss : 0.4246550677820337 ITERATION : 65, loss : 0.4246550677820337 ITERATION : 66, loss : 0.4246550677820337 ITERATION : 67, loss : 0.4246550677820337 ITERATION : 68, loss : 0.4246550677820337 ITERATION : 69, loss : 0.4246550677820337 ITERATION : 70, loss : 0.4246550677820337 ITERATION : 71, loss : 0.4246550677820337 ITERATION : 72, loss : 0.4246550677820337 ITERATION : 73, loss : 0.4246550677820337 ITERATION : 74, loss : 0.4246550677820337 ITERATION : 75, loss : 0.4246550677820337 ITERATION : 76, loss : 0.4246550677820337 ITERATION : 77, loss : 0.4246550677820337 ITERATION : 78, loss : 0.4246550677820337 ITERATION : 79, loss : 0.4246550677820337 ITERATION : 80, loss : 0.4246550677820337 ITERATION : 81, loss : 0.4246550677820337 ITERATION : 82, loss : 0.4246550677820337 ITERATION : 83, loss : 0.4246550677820337 ITERATION : 84, loss : 0.4246550677820337 ITERATION : 85, loss : 0.4246550677820337 ITERATION : 86, loss : 0.4246550677820337 ITERATION : 87, loss : 0.4246550677820337 ITERATION : 88, loss : 0.4246550677820337 ITERATION : 89, loss : 0.4246550677820337 ITERATION : 90, loss : 0.4246550677820337 ITERATION : 91, loss : 0.4246550677820337 ITERATION : 92, loss : 0.4246550677820337 ITERATION : 93, loss : 0.4246550677820337 ITERATION : 94, loss : 0.4246550677820337 ITERATION : 95, loss : 0.4246550677820337 ITERATION : 96, loss : 0.4246550677820337 ITERATION : 97, loss : 0.4246550677820337 ITERATION : 98, loss : 0.4246550677820337 ITERATION : 99, loss : 0.4246550677820337 ITERATION : 100, loss : 0.4246550677820337 
ITERATION : 1, loss : 0.24856501425531552 ITERATION : 2, loss : 0.24856501425531552 ITERATION : 3, loss : 0.24856501425531552 ITERATION : 4, loss : 0.24856501425531552 ITERATION : 5, loss : 0.24856501425531552 ITERATION : 6, loss : 0.24856501425531552 ITERATION : 7, loss : 0.24856501425531552 ITERATION : 8, loss : 0.24856501425531552 ITERATION : 9, loss : 0.24856501425531552 ITERATION : 10, loss : 0.24856501425531552 ITERATION : 11, loss : 0.24856501425531552 ITERATION : 12, loss : 0.24856501425531552 ITERATION : 13, loss : 0.24856501425531552 ITERATION : 14, loss : 0.24856501425531552 ITERATION : 15, loss : 0.24856501425531552 ITERATION : 16, loss : 0.24856501425531552 ITERATION : 17, loss : 0.24856501425531552 ITERATION : 18, loss : 0.24856501425531552 ITERATION : 19, loss : 0.24856501425531552 ITERATION : 20, loss : 0.24856501425531552 ITERATION : 21, loss : 0.24856501425531552 ITERATION : 22, loss : 0.24856501425531552 ITERATION : 23, loss : 0.24856501425531552 ITERATION : 24, loss : 0.24856501425531552 ITERATION : 25, loss : 0.24856501425531552 ITERATION : 26, loss : 0.24856501425531552 ITERATION : 27, loss : 0.24856501425531552 ITERATION : 28, loss : 0.24856501425531552 ITERATION : 29, loss : 0.24856501425531552 ITERATION : 30, loss : 0.24856501425531552 ITERATION : 31, loss : 0.24856501425531552 ITERATION : 32, loss : 0.24856501425531552 ITERATION : 33, loss : 0.24856501425531552 ITERATION : 34, loss : 0.24856501425531552 ITERATION : 35, loss : 0.24856501425531552 ITERATION : 36, loss : 0.24856501425531552 ITERATION : 37, loss : 0.24856501425531552 ITERATION : 38, loss : 0.24856501425531552 ITERATION : 39, loss : 0.24856501425531552 ITERATION : 40, loss : 0.24856501425531552 ITERATION : 41, loss : 0.24856501425531552 ITERATION : 42, loss : 0.24856501425531552 ITERATION : 43, loss : 0.24856501425531552 ITERATION : 44, loss : 0.24856501425531552 ITERATION : 45, loss : 0.24856501425531552 ITERATION : 46, loss : 0.24856501425531552 ITERATION : 47, loss : 0.24856501425531552 ITERATION : 48, loss : 0.24856501425531552 ITERATION : 49, loss : 0.24856501425531552 ITERATION : 50, loss : 0.24856501425531552 ITERATION : 51, loss : 0.24856501425531552 ITERATION : 52, loss : 0.24856501425531552 ITERATION : 53, loss : 0.24856501425531552 ITERATION : 54, loss : 0.24856501425531552 ITERATION : 55, loss : 0.24856501425531552 ITERATION : 56, loss : 0.24856501425531552 ITERATION : 57, loss : 0.24856501425531552 ITERATION : 58, loss : 0.24856501425531552 ITERATION : 59, loss : 0.24856501425531552 ITERATION : 60, loss : 0.24856501425531552 ITERATION : 61, loss : 0.24856501425531552 ITERATION : 62, loss : 0.24856501425531552 ITERATION : 63, loss : 0.24856501425531552 ITERATION : 64, loss : 0.24856501425531552 ITERATION : 65, loss : 0.24856501425531552 ITERATION : 66, loss : 0.24856501425531552 ITERATION : 67, loss : 0.24856501425531552 ITERATION : 68, loss : 0.24856501425531552 ITERATION : 69, loss : 0.24856501425531552 ITERATION : 70, loss : 0.24856501425531552 ITERATION : 71, loss : 0.24856501425531552 ITERATION : 72, loss : 0.24856501425531552 ITERATION : 73, loss : 0.24856501425531552 ITERATION : 74, loss : 0.24856501425531552 ITERATION : 75, loss : 0.24856501425531552 ITERATION : 76, loss : 0.24856501425531552 ITERATION : 77, loss : 0.24856501425531552 ITERATION : 78, loss : 0.24856501425531552 ITERATION : 79, loss : 0.24856501425531552 ITERATION : 80, loss : 0.24856501425531552 ITERATION : 81, loss : 0.24856501425531552 ITERATION : 82, loss : 0.24856501425531552 ITERATION : 83, loss : 0.24856501425531552 ITERATION : 84, loss : 0.24856501425531552 ITERATION : 85, loss : 0.24856501425531552 ITERATION : 86, loss : 0.24856501425531552 ITERATION : 87, loss : 0.24856501425531552 ITERATION : 88, loss : 0.24856501425531552 ITERATION : 89, loss : 0.24856501425531552 ITERATION : 90, loss : 0.24856501425531552 ITERATION : 91, loss : 0.24856501425531552 ITERATION : 92, loss : 0.24856501425531552 ITERATION : 93, loss : 0.24856501425531552 ITERATION : 94, loss : 0.24856501425531552 ITERATION : 95, loss : 0.24856501425531552 ITERATION : 96, loss : 0.24856501425531552 ITERATION : 97, loss : 0.24856501425531552 ITERATION : 98, loss : 0.24856501425531552 ITERATION : 99, loss : 0.24856501425531552 ITERATION : 100, loss : 0.24856501425531552 
ITERATION : 1, loss : 0.18403192291733594 ITERATION : 2, loss : 0.18403192291733594 ITERATION : 3, loss : 0.18403192291733594 ITERATION : 4, loss : 0.18403192291733594 ITERATION : 5, loss : 0.18403192291733594 ITERATION : 6, loss : 0.18403192291733594 ITERATION : 7, loss : 0.18403192291733594 ITERATION : 8, loss : 0.18403192291733594 ITERATION : 9, loss : 0.18403192291733594 ITERATION : 10, loss : 0.18403192291733594 ITERATION : 11, loss : 0.18403192291733594 ITERATION : 12, loss : 0.18403192291733594 ITERATION : 13, loss : 0.18403192291733594 ITERATION : 14, loss : 0.18403192291733594 ITERATION : 15, loss : 0.18403192291733594 ITERATION : 16, loss : 0.18403192291733594 ITERATION : 17, loss : 0.18403192291733594 ITERATION : 18, loss : 0.18403192291733594 ITERATION : 19, loss : 0.18403192291733594 ITERATION : 20, loss : 0.18403192291733594 ITERATION : 21, loss : 0.18403192291733594 ITERATION : 22, loss : 0.18403192291733594 ITERATION : 23, loss : 0.18403192291733594 ITERATION : 24, loss : 0.18403192291733594 ITERATION : 25, loss : 0.18403192291733594 ITERATION : 26, loss : 0.18403192291733594 ITERATION : 27, loss : 0.18403192291733594 ITERATION : 28, loss : 0.18403192291733594 ITERATION : 29, loss : 0.18403192291733594 ITERATION : 30, loss : 0.18403192291733594 ITERATION : 31, loss : 0.18403192291733594 ITERATION : 32, loss : 0.18403192291733594 ITERATION : 33, loss : 0.18403192291733594 ITERATION : 34, loss : 0.18403192291733594 ITERATION : 35, loss : 0.18403192291733594 ITERATION : 36, loss : 0.18403192291733594 ITERATION : 37, loss : 0.18403192291733594 ITERATION : 38, loss : 0.18403192291733594 ITERATION : 39, loss : 0.18403192291733594 ITERATION : 40, loss : 0.18403192291733594 ITERATION : 41, loss : 0.18403192291733594 ITERATION : 42, loss : 0.18403192291733594 ITERATION : 43, loss : 0.18403192291733594 ITERATION : 44, loss : 0.18403192291733594 ITERATION : 45, loss : 0.18403192291733594 ITERATION : 46, loss : 0.18403192291733594 ITERATION : 47, loss : 0.18403192291733594 ITERATION : 48, loss : 0.18403192291733594 ITERATION : 49, loss : 0.18403192291733594 ITERATION : 50, loss : 0.18403192291733594 ITERATION : 51, loss : 0.18403192291733594 ITERATION : 52, loss : 0.18403192291733594 ITERATION : 53, loss : 0.18403192291733594 ITERATION : 54, loss : 0.18403192291733594 ITERATION : 55, loss : 0.18403192291733594 ITERATION : 56, loss : 0.18403192291733594 ITERATION : 57, loss : 0.18403192291733594 ITERATION : 58, loss : 0.18403192291733594 ITERATION : 59, loss : 0.18403192291733594 ITERATION : 60, loss : 0.18403192291733594 ITERATION : 61, loss : 0.18403192291733594 ITERATION : 62, loss : 0.18403192291733594 ITERATION : 63, loss : 0.18403192291733594 ITERATION : 64, loss : 0.18403192291733594 ITERATION : 65, loss : 0.18403192291733594 ITERATION : 66, loss : 0.18403192291733594 ITERATION : 67, loss : 0.18403192291733594 ITERATION : 68, loss : 0.18403192291733594 ITERATION : 69, loss : 0.18403192291733594 ITERATION : 70, loss : 0.18403192291733594 ITERATION : 71, loss : 0.18403192291733594 ITERATION : 72, loss : 0.18403192291733594 ITERATION : 73, loss : 0.18403192291733594 ITERATION : 74, loss : 0.18403192291733594 ITERATION : 75, loss : 0.18403192291733594 ITERATION : 76, loss : 0.18403192291733594 ITERATION : 77, loss : 0.18403192291733594 ITERATION : 78, loss : 0.18403192291733594 ITERATION : 79, loss : 0.18403192291733594 ITERATION : 80, loss : 0.18403192291733594 ITERATION : 81, loss : 0.18403192291733594 ITERATION : 82, loss : 0.18403192291733594 ITERATION : 83, loss : 0.18403192291733594 ITERATION : 84, loss : 0.18403192291733594 ITERATION : 85, loss : 0.18403192291733594 ITERATION : 86, loss : 0.18403192291733594 ITERATION : 87, loss : 0.18403192291733594 ITERATION : 88, loss : 0.18403192291733594 ITERATION : 89, loss : 0.18403192291733594 ITERATION : 90, loss : 0.18403192291733594 ITERATION : 91, loss : 0.18403192291733594 ITERATION : 92, loss : 0.18403192291733594 ITERATION : 93, loss : 0.18403192291733594 ITERATION : 94, loss : 0.18403192291733594 ITERATION : 95, loss : 0.18403192291733594 ITERATION : 96, loss : 0.18403192291733594 ITERATION : 97, loss : 0.18403192291733594 ITERATION : 98, loss : 0.18403192291733594 ITERATION : 99, loss : 0.18403192291733594 ITERATION : 100, loss : 0.18403192291733594 
ITERATION : 1, loss : 0.3106720363274451 ITERATION : 2, loss : 0.3106720363274451 ITERATION : 3, loss : 0.3106720363274451 ITERATION : 4, loss : 0.3106720363274451 ITERATION : 5, loss : 0.3106720363274451 ITERATION : 6, loss : 0.3106720363274451 ITERATION : 7, loss : 0.3106720363274451 ITERATION : 8, loss : 0.3106720363274451 ITERATION : 9, loss : 0.3106720363274451 ITERATION : 10, loss : 0.3106720363274451 ITERATION : 11, loss : 0.3106720363274451 ITERATION : 12, loss : 0.3106720363274451 ITERATION : 13, loss : 0.3106720363274451 ITERATION : 14, loss : 0.3106720363274451 ITERATION : 15, loss : 0.3106720363274451 ITERATION : 16, loss : 0.3106720363274451 ITERATION : 17, loss : 0.3106720363274451 ITERATION : 18, loss : 0.3106720363274451 ITERATION : 19, loss : 0.3106720363274451 ITERATION : 20, loss : 0.3106720363274451 ITERATION : 21, loss : 0.3106720363274451 ITERATION : 22, loss : 0.3106720363274451 ITERATION : 23, loss : 0.3106720363274451 ITERATION : 24, loss : 0.3106720363274451 ITERATION : 25, loss : 0.3106720363274451 ITERATION : 26, loss : 0.3106720363274451 ITERATION : 27, loss : 0.3106720363274451 ITERATION : 28, loss : 0.3106720363274451 ITERATION : 29, loss : 0.3106720363274451 ITERATION : 30, loss : 0.3106720363274451 ITERATION : 31, loss : 0.3106720363274451 ITERATION : 32, loss : 0.3106720363274451 ITERATION : 33, loss : 0.3106720363274451 ITERATION : 34, loss : 0.3106720363274451 ITERATION : 35, loss : 0.3106720363274451 ITERATION : 36, loss : 0.3106720363274451 ITERATION : 37, loss : 0.3106720363274451 ITERATION : 38, loss : 0.3106720363274451 ITERATION : 39, loss : 0.3106720363274451 ITERATION : 40, loss : 0.3106720363274451 ITERATION : 41, loss : 0.3106720363274451 ITERATION : 42, loss : 0.3106720363274451 ITERATION : 43, loss : 0.3106720363274451 ITERATION : 44, loss : 0.3106720363274451 ITERATION : 45, loss : 0.3106720363274451 ITERATION : 46, loss : 0.3106720363274451 ITERATION : 47, loss : 0.3106720363274451 ITERATION : 48, loss : 0.3106720363274451 ITERATION : 49, loss : 0.3106720363274451 ITERATION : 50, loss : 0.3106720363274451 ITERATION : 51, loss : 0.3106720363274451 ITERATION : 52, loss : 0.3106720363274451 ITERATION : 53, loss : 0.3106720363274451 ITERATION : 54, loss : 0.3106720363274451 ITERATION : 55, loss : 0.3106720363274451 ITERATION : 56, loss : 0.3106720363274451 ITERATION : 57, loss : 0.3106720363274451 ITERATION : 58, loss : 0.3106720363274451 ITERATION : 59, loss : 0.3106720363274451 ITERATION : 60, loss : 0.3106720363274451 ITERATION : 61, loss : 0.3106720363274451 ITERATION : 62, loss : 0.3106720363274451 ITERATION : 63, loss : 0.3106720363274451 ITERATION : 64, loss : 0.3106720363274451 ITERATION : 65, loss : 0.3106720363274451 ITERATION : 66, loss : 0.3106720363274451 ITERATION : 67, loss : 0.3106720363274451 ITERATION : 68, loss : 0.3106720363274451 ITERATION : 69, loss : 0.3106720363274451 ITERATION : 70, loss : 0.3106720363274451 ITERATION : 71, loss : 0.3106720363274451 ITERATION : 72, loss : 0.3106720363274451 ITERATION : 73, loss : 0.3106720363274451 ITERATION : 74, loss : 0.3106720363274451 ITERATION : 75, loss : 0.3106720363274451 ITERATION : 76, loss : 0.3106720363274451 ITERATION : 77, loss : 0.3106720363274451 ITERATION : 78, loss : 0.3106720363274451 ITERATION : 79, loss : 0.3106720363274451 ITERATION : 80, loss : 0.3106720363274451 ITERATION : 81, loss : 0.3106720363274451 ITERATION : 82, loss : 0.3106720363274451 ITERATION : 83, loss : 0.3106720363274451 ITERATION : 84, loss : 0.3106720363274451 ITERATION : 85, loss : 0.3106720363274451 ITERATION : 86, loss : 0.3106720363274451 ITERATION : 87, loss : 0.3106720363274451 ITERATION : 88, loss : 0.3106720363274451 ITERATION : 89, loss : 0.3106720363274451 ITERATION : 90, loss : 0.3106720363274451 ITERATION : 91, loss : 0.3106720363274451 ITERATION : 92, loss : 0.3106720363274451 ITERATION : 93, loss : 0.3106720363274451 ITERATION : 94, loss : 0.3106720363274451 ITERATION : 95, loss : 0.3106720363274451 ITERATION : 96, loss : 0.3106720363274451 ITERATION : 97, loss : 0.3106720363274451 ITERATION : 98, loss : 0.3106720363274451 ITERATION : 99, loss : 0.3106720363274451 ITERATION : 100, loss : 0.3106720363274451 
ITERATION : 1, loss : 0.16044825163685716 ITERATION : 2, loss : 0.16044825163685716 ITERATION : 3, loss : 0.16044825163685716 ITERATION : 4, loss : 0.16044825163685716 ITERATION : 5, loss : 0.16044825163685716 ITERATION : 6, loss : 0.16044825163685716 ITERATION : 7, loss : 0.16044825163685716 ITERATION : 8, loss : 0.16044825163685716 ITERATION : 9, loss : 0.16044825163685716 ITERATION : 10, loss : 0.16044825163685716 ITERATION : 11, loss : 0.16044825163685716 ITERATION : 12, loss : 0.16044825163685716 ITERATION : 13, loss : 0.16044825163685716 ITERATION : 14, loss : 0.16044825163685716 ITERATION : 15, loss : 0.16044825163685716 ITERATION : 16, loss : 0.16044825163685716 ITERATION : 17, loss : 0.16044825163685716 ITERATION : 18, loss : 0.16044825163685716 ITERATION : 19, loss : 0.16044825163685716 ITERATION : 20, loss : 0.16044825163685716 ITERATION : 21, loss : 0.16044825163685716 ITERATION : 22, loss : 0.16044825163685716 ITERATION : 23, loss : 0.16044825163685716 ITERATION : 24, loss : 0.16044825163685716 ITERATION : 25, loss : 0.16044825163685716 ITERATION : 26, loss : 0.16044825163685716 ITERATION : 27, loss : 0.16044825163685716 ITERATION : 28, loss : 0.16044825163685716 ITERATION : 29, loss : 0.16044825163685716 ITERATION : 30, loss : 0.16044825163685716 ITERATION : 31, loss : 0.16044825163685716 ITERATION : 32, loss : 0.16044825163685716 ITERATION : 33, loss : 0.16044825163685716 ITERATION : 34, loss : 0.16044825163685716 ITERATION : 35, loss : 0.16044825163685716 ITERATION : 36, loss : 0.16044825163685716 ITERATION : 37, loss : 0.16044825163685716 ITERATION : 38, loss : 0.16044825163685716 ITERATION : 39, loss : 0.16044825163685716 ITERATION : 40, loss : 0.16044825163685716 ITERATION : 41, loss : 0.16044825163685716 ITERATION : 42, loss : 0.16044825163685716 ITERATION : 43, loss : 0.16044825163685716 ITERATION : 44, loss : 0.16044825163685716 ITERATION : 45, loss : 0.16044825163685716 ITERATION : 46, loss : 0.16044825163685716 ITERATION : 47, loss : 0.16044825163685716 ITERATION : 48, loss : 0.16044825163685716 ITERATION : 49, loss : 0.16044825163685716 ITERATION : 50, loss : 0.16044825163685716 ITERATION : 51, loss : 0.16044825163685716 ITERATION : 52, loss : 0.16044825163685716 ITERATION : 53, loss : 0.16044825163685716 ITERATION : 54, loss : 0.16044825163685716 ITERATION : 55, loss : 0.16044825163685716 ITERATION : 56, loss : 0.16044825163685716 ITERATION : 57, loss : 0.16044825163685716 ITERATION : 58, loss : 0.16044825163685716 ITERATION : 59, loss : 0.16044825163685716 ITERATION : 60, loss : 0.16044825163685716 ITERATION : 61, loss : 0.16044825163685716 ITERATION : 62, loss : 0.16044825163685716 ITERATION : 63, loss : 0.16044825163685716 ITERATION : 64, loss : 0.16044825163685716 ITERATION : 65, loss : 0.16044825163685716 ITERATION : 66, loss : 0.16044825163685716 ITERATION : 67, loss : 0.16044825163685716 ITERATION : 68, loss : 0.16044825163685716 ITERATION : 69, loss : 0.16044825163685716 ITERATION : 70, loss : 0.16044825163685716 ITERATION : 71, loss : 0.16044825163685716 ITERATION : 72, loss : 0.16044825163685716 ITERATION : 73, loss : 0.16044825163685716 ITERATION : 74, loss : 0.16044825163685716 ITERATION : 75, loss : 0.16044825163685716 ITERATION : 76, loss : 0.16044825163685716 ITERATION : 77, loss : 0.16044825163685716 ITERATION : 78, loss : 0.16044825163685716 ITERATION : 79, loss : 0.16044825163685716 ITERATION : 80, loss : 0.16044825163685716 ITERATION : 81, loss : 0.16044825163685716 ITERATION : 82, loss : 0.16044825163685716 ITERATION : 83, loss : 0.16044825163685716 ITERATION : 84, loss : 0.16044825163685716 ITERATION : 85, loss : 0.16044825163685716 ITERATION : 86, loss : 0.16044825163685716 ITERATION : 87, loss : 0.16044825163685716 ITERATION : 88, loss : 0.16044825163685716 ITERATION : 89, loss : 0.16044825163685716 ITERATION : 90, loss : 0.16044825163685716 ITERATION : 91, loss : 0.16044825163685716 ITERATION : 92, loss : 0.16044825163685716 ITERATION : 93, loss : 0.16044825163685716 ITERATION : 94, loss : 0.16044825163685716 ITERATION : 95, loss : 0.16044825163685716 ITERATION : 96, loss : 0.16044825163685716 ITERATION : 97, loss : 0.16044825163685716 ITERATION : 98, loss : 0.16044825163685716 ITERATION : 99, loss : 0.16044825163685716 ITERATION : 100, loss : 0.16044825163685716 
gradient norm in None layer : 39.6682068047542
gradient norm in None layer : 1.5548379288221585
gradient norm in None layer : 1.3869782603035017
gradient norm in None layer : 28.353820422588697
gradient norm in None layer : 1.4852648251366363
gradient norm in None layer : 1.2602900447868228
gradient norm in None layer : 7.992262907573277
gradient norm in None layer : 0.27868447153268
gradient norm in None layer : 0.28851869632892546
gradient norm in None layer : 6.823516469934009
gradient norm in None layer : 0.242651854416472
gradient norm in None layer : 0.25688958819313823
gradient norm in None layer : 2.4018930486019703
gradient norm in None layer : 0.07127630220825058
gradient norm in None layer : 0.0694029425195657
gradient norm in None layer : 2.1389341476601427
gradient norm in None layer : 0.07213964950119127
gradient norm in None layer : 0.0744213645015486
gradient norm in None layer : 2.5395725379002045
gradient norm in None layer : 0.07305344786056545
gradient norm in None layer : 6.154621230819208
gradient norm in None layer : 0.2585587447926656
gradient norm in None layer : 0.2626816175021684
gradient norm in None layer : 6.909706050585965
gradient norm in None layer : 0.3409128781950743
gradient norm in None layer : 0.5212288270632397
gradient norm in None layer : 9.407924487386989
gradient norm in None layer : 0.3464849487104763
gradient norm in None layer : 23.3590729035951
gradient norm in None layer : 1.2365614335993804
gradient norm in None layer : 1.1531312844708943
gradient norm in None layer : 19.574712166602858
gradient norm in None layer : 4.157380108069182
gradient norm in None layer : 5.049256198868785
gradient norm in None layer : 2.625685279034458
gradient norm in None layer : 0.7887377522236099
Total gradient norm: 60.579939848567506
invariance loss : 2009.396945815925, avg_den : 0.0, density loss : 0.1, mse loss : 0.37151282993701956, solver time : 0.8447785377502441 sec , total loss : 2.4809097757529446, running loss : 2.4809097757529446
Epoch 0/10 , batch 2/12500 
ITERATION : 1, loss : 0.1436637674753811 ITERATION : 2, loss : 0.1436637674753811 ITERATION : 3, loss : 0.1436637674753811 ITERATION : 4, loss : 0.1436637674753811 ITERATION : 5, loss : 0.1436637674753811 ITERATION : 6, loss : 0.1436637674753811 ITERATION : 7, loss : 0.1436637674753811 ITERATION : 8, loss : 0.1436637674753811 ITERATION : 9, loss : 0.1436637674753811 ITERATION : 10, loss : 0.1436637674753811 ITERATION : 11, loss : 0.1436637674753811 ITERATION : 12, loss : 0.1436637674753811 ITERATION : 13, loss : 0.1436637674753811 ITERATION : 14, loss : 0.1436637674753811 ITERATION : 15, loss : 0.1436637674753811 ITERATION : 16, loss : 0.1436637674753811 ITERATION : 17, loss : 0.1436637674753811 ITERATION : 18, loss : 0.1436637674753811 ITERATION : 19, loss : 0.1436637674753811 ITERATION : 20, loss : 0.1436637674753811 ITERATION : 21, loss : 0.1436637674753811 ITERATION : 22, loss : 0.1436637674753811 ITERATION : 23, loss : 0.1436637674753811 ITERATION : 24, loss : 0.1436637674753811 ITERATION : 25, loss : 0.1436637674753811 ITERATION : 26, loss : 0.1436637674753811 ITERATION : 27, loss : 0.1436637674753811 ITERATION : 28, loss : 0.1436637674753811 ITERATION : 29, loss : 0.1436637674753811 ITERATION : 30, loss : 0.1436637674753811 ITERATION : 31, loss : 0.1436637674753811 ITERATION : 32, loss : 0.1436637674753811 ITERATION : 33, loss : 0.1436637674753811 ITERATION : 34, loss : 0.1436637674753811 ITERATION : 35, loss : 0.1436637674753811 ITERATION : 36, loss : 0.1436637674753811 ITERATION : 37, loss : 0.1436637674753811 ITERATION : 38, loss : 0.1436637674753811 ITERATION : 39, loss : 0.1436637674753811 ITERATION : 40, loss : 0.1436637674753811 ITERATION : 41, loss : 0.1436637674753811 ITERATION : 42, loss : 0.1436637674753811 ITERATION : 43, loss : 0.1436637674753811 ITERATION : 44, loss : 0.1436637674753811 ITERATION : 45, loss : 0.1436637674753811 ITERATION : 46, loss : 0.1436637674753811 ITERATION : 47, loss : 0.1436637674753811 ITERATION : 48, loss : 0.1436637674753811 ITERATION : 49, loss : 0.1436637674753811 ITERATION : 50, loss : 0.1436637674753811 ITERATION : 51, loss : 0.1436637674753811 ITERATION : 52, loss : 0.1436637674753811 ITERATION : 53, loss : 0.1436637674753811 ITERATION : 54, loss : 0.1436637674753811 ITERATION : 55, loss : 0.1436637674753811 ITERATION : 56, loss : 0.1436637674753811 ITERATION : 57, loss : 0.1436637674753811 ITERATION : 58, loss : 0.1436637674753811 ITERATION : 59, loss : 0.1436637674753811 ITERATION : 60, loss : 0.1436637674753811 ITERATION : 61, loss : 0.1436637674753811 ITERATION : 62, loss : 0.1436637674753811 ITERATION : 63, loss : 0.1436637674753811 ITERATION : 64, loss : 0.1436637674753811 ITERATION : 65, loss : 0.1436637674753811 ITERATION : 66, loss : 0.1436637674753811 ITERATION : 67, loss : 0.1436637674753811 ITERATION : 68, loss : 0.1436637674753811 ITERATION : 69, loss : 0.1436637674753811 ITERATION : 70, loss : 0.1436637674753811 ITERATION : 71, loss : 0.1436637674753811 ITERATION : 72, loss : 0.1436637674753811 ITERATION : 73, loss : 0.1436637674753811 ITERATION : 74, loss : 0.1436637674753811 ITERATION : 75, loss : 0.1436637674753811 ITERATION : 76, loss : 0.1436637674753811 ITERATION : 77, loss : 0.1436637674753811 ITERATION : 78, loss : 0.1436637674753811 ITERATION : 79, loss : 0.1436637674753811 ITERATION : 80, loss : 0.1436637674753811 ITERATION : 81, loss : 0.1436637674753811 ITERATION : 82, loss : 0.1436637674753811 ITERATION : 83, loss : 0.1436637674753811 ITERATION : 84, loss : 0.1436637674753811 ITERATION : 85, loss : 0.1436637674753811 ITERATION : 86, loss : 0.1436637674753811 ITERATION : 87, loss : 0.1436637674753811 ITERATION : 88, loss : 0.1436637674753811 ITERATION : 89, loss : 0.1436637674753811 ITERATION : 90, loss : 0.1436637674753811 ITERATION : 91, loss : 0.1436637674753811 ITERATION : 92, loss : 0.1436637674753811 ITERATION : 93, loss : 0.1436637674753811 ITERATION : 94, loss : 0.1436637674753811 ITERATION : 95, loss : 0.1436637674753811 ITERATION : 96, loss : 0.1436637674753811 ITERATION : 97, loss : 0.1436637674753811 ITERATION : 98, loss : 0.1436637674753811 ITERATION : 99, loss : 0.1436637674753811 ITERATION : 100, loss : 0.1436637674753811 
ITERATION : 1, loss : 0.12384223334080828 ITERATION : 2, loss : 0.12384223334080828 ITERATION : 3, loss : 0.12384223334080828 ITERATION : 4, loss : 0.12384223334080828 ITERATION : 5, loss : 0.12384223334080828 ITERATION : 6, loss : 0.12384223334080828 ITERATION : 7, loss : 0.12384223334080828 ITERATION : 8, loss : 0.12384223334080828 ITERATION : 9, loss : 0.12384223334080828 ITERATION : 10, loss : 0.12384223334080828 ITERATION : 11, loss : 0.12384223334080828 ITERATION : 12, loss : 0.12384223334080828 ITERATION : 13, loss : 0.12384223334080828 ITERATION : 14, loss : 0.12384223334080828 ITERATION : 15, loss : 0.12384223334080828 ITERATION : 16, loss : 0.12384223334080828 ITERATION : 17, loss : 0.12384223334080828 ITERATION : 18, loss : 0.12384223334080828 ITERATION : 19, loss : 0.12384223334080828 ITERATION : 20, loss : 0.12384223334080828 ITERATION : 21, loss : 0.12384223334080828 ITERATION : 22, loss : 0.12384223334080828 ITERATION : 23, loss : 0.12384223334080828 ITERATION : 24, loss : 0.12384223334080828 ITERATION : 25, loss : 0.12384223334080828 ITERATION : 26, loss : 0.12384223334080828 ITERATION : 27, loss : 0.12384223334080828 ITERATION : 28, loss : 0.12384223334080828 ITERATION : 29, loss : 0.12384223334080828 ITERATION : 30, loss : 0.12384223334080828 ITERATION : 31, loss : 0.12384223334080828 ITERATION : 32, loss : 0.12384223334080828 ITERATION : 33, loss : 0.12384223334080828 ITERATION : 34, loss : 0.12384223334080828 ITERATION : 35, loss : 0.12384223334080828 ITERATION : 36, loss : 0.12384223334080828 ITERATION : 37, loss : 0.12384223334080828 ITERATION : 38, loss : 0.12384223334080828 ITERATION : 39, loss : 0.12384223334080828 ITERATION : 40, loss : 0.12384223334080828 ITERATION : 41, loss : 0.12384223334080828 ITERATION : 42, loss : 0.12384223334080828 ITERATION : 43, loss : 0.12384223334080828 ITERATION : 44, loss : 0.12384223334080828 ITERATION : 45, loss : 0.12384223334080828 ITERATION : 46, loss : 0.12384223334080828 ITERATION : 47, loss : 0.12384223334080828 ITERATION : 48, loss : 0.12384223334080828 ITERATION : 49, loss : 0.12384223334080828 ITERATION : 50, loss : 0.12384223334080828 ITERATION : 51, loss : 0.12384223334080828 ITERATION : 52, loss : 0.12384223334080828 ITERATION : 53, loss : 0.12384223334080828 ITERATION : 54, loss : 0.12384223334080828 ITERATION : 55, loss : 0.12384223334080828 ITERATION : 56, loss : 0.12384223334080828 ITERATION : 57, loss : 0.12384223334080828 ITERATION : 58, loss : 0.12384223334080828 ITERATION : 59, loss : 0.12384223334080828 ITERATION : 60, loss : 0.12384223334080828 ITERATION : 61, loss : 0.12384223334080828 ITERATION : 62, loss : 0.12384223334080828 ITERATION : 63, loss : 0.12384223334080828 ITERATION : 64, loss : 0.12384223334080828 ITERATION : 65, loss : 0.12384223334080828 ITERATION : 66, loss : 0.12384223334080828 ITERATION : 67, loss : 0.12384223334080828 ITERATION : 68, loss : 0.12384223334080828 ITERATION : 69, loss : 0.12384223334080828 ITERATION : 70, loss : 0.12384223334080828 ITERATION : 71, loss : 0.12384223334080828 ITERATION : 72, loss : 0.12384223334080828 ITERATION : 73, loss : 0.12384223334080828 ITERATION : 74, loss : 0.12384223334080828 ITERATION : 75, loss : 0.12384223334080828 ITERATION : 76, loss : 0.12384223334080828 ITERATION : 77, loss : 0.12384223334080828 ITERATION : 78, loss : 0.12384223334080828 ITERATION : 79, loss : 0.12384223334080828 ITERATION : 80, loss : 0.12384223334080828 ITERATION : 81, loss : 0.12384223334080828 ITERATION : 82, loss : 0.12384223334080828 ITERATION : 83, loss : 0.12384223334080828 ITERATION : 84, loss : 0.12384223334080828 ITERATION : 85, loss : 0.12384223334080828 ITERATION : 86, loss : 0.12384223334080828 ITERATION : 87, loss : 0.12384223334080828 ITERATION : 88, loss : 0.12384223334080828 ITERATION : 89, loss : 0.12384223334080828 ITERATION : 90, loss : 0.12384223334080828 ITERATION : 91, loss : 0.12384223334080828 ITERATION : 92, loss : 0.12384223334080828 ITERATION : 93, loss : 0.12384223334080828 ITERATION : 94, loss : 0.12384223334080828 ITERATION : 95, loss : 0.12384223334080828 ITERATION : 96, loss : 0.12384223334080828 ITERATION : 97, loss : 0.12384223334080828 ITERATION : 98, loss : 0.12384223334080828 ITERATION : 99, loss : 0.12384223334080828 ITERATION : 100, loss : 0.12384223334080828 
ITERATION : 1, loss : 0.44907673515592944 ITERATION : 2, loss : 0.44907673515592944 ITERATION : 3, loss : 0.44907673515592944 ITERATION : 4, loss : 0.44907673515592944 ITERATION : 5, loss : 0.44907673515592944 ITERATION : 6, loss : 0.44907673515592944 ITERATION : 7, loss : 0.44907673515592944 ITERATION : 8, loss : 0.44907673515592944 ITERATION : 9, loss : 0.44907673515592944 ITERATION : 10, loss : 0.44907673515592944 ITERATION : 11, loss : 0.44907673515592944 ITERATION : 12, loss : 0.44907673515592944 ITERATION : 13, loss : 0.44907673515592944 ITERATION : 14, loss : 0.44907673515592944 ITERATION : 15, loss : 0.44907673515592944 ITERATION : 16, loss : 0.44907673515592944 ITERATION : 17, loss : 0.44907673515592944 ITERATION : 18, loss : 0.44907673515592944 ITERATION : 19, loss : 0.44907673515592944 ITERATION : 20, loss : 0.44907673515592944 ITERATION : 21, loss : 0.44907673515592944 ITERATION : 22, loss : 0.44907673515592944 ITERATION : 23, loss : 0.44907673515592944 ITERATION : 24, loss : 0.44907673515592944 ITERATION : 25, loss : 0.44907673515592944 ITERATION : 26, loss : 0.44907673515592944 ITERATION : 27, loss : 0.44907673515592944 ITERATION : 28, loss : 0.44907673515592944 ITERATION : 29, loss : 0.44907673515592944 ITERATION : 30, loss : 0.44907673515592944 ITERATION : 31, loss : 0.44907673515592944 ITERATION : 32, loss : 0.44907673515592944 ITERATION : 33, loss : 0.44907673515592944 ITERATION : 34, loss : 0.44907673515592944 ITERATION : 35, loss : 0.44907673515592944 ITERATION : 36, loss : 0.44907673515592944 ITERATION : 37, loss : 0.44907673515592944 ITERATION : 38, loss : 0.44907673515592944 ITERATION : 39, loss : 0.44907673515592944 ITERATION : 40, loss : 0.44907673515592944 ITERATION : 41, loss : 0.44907673515592944 ITERATION : 42, loss : 0.44907673515592944 ITERATION : 43, loss : 0.44907673515592944 ITERATION : 44, loss : 0.44907673515592944 ITERATION : 45, loss : 0.44907673515592944 ITERATION : 46, loss : 0.44907673515592944 ITERATION : 47, loss : 0.44907673515592944 ITERATION : 48, loss : 0.44907673515592944 ITERATION : 49, loss : 0.44907673515592944 ITERATION : 50, loss : 0.44907673515592944 ITERATION : 51, loss : 0.44907673515592944 ITERATION : 52, loss : 0.44907673515592944 ITERATION : 53, loss : 0.44907673515592944 ITERATION : 54, loss : 0.44907673515592944 ITERATION : 55, loss : 0.44907673515592944 ITERATION : 56, loss : 0.44907673515592944 ITERATION : 57, loss : 0.44907673515592944 ITERATION : 58, loss : 0.44907673515592944 ITERATION : 59, loss : 0.44907673515592944 ITERATION : 60, loss : 0.44907673515592944 ITERATION : 61, loss : 0.44907673515592944 ITERATION : 62, loss : 0.44907673515592944 ITERATION : 63, loss : 0.44907673515592944 ITERATION : 64, loss : 0.44907673515592944 ITERATION : 65, loss : 0.44907673515592944 ITERATION : 66, loss : 0.44907673515592944 ITERATION : 67, loss : 0.44907673515592944 ITERATION : 68, loss : 0.44907673515592944 ITERATION : 69, loss : 0.44907673515592944 ITERATION : 70, loss : 0.44907673515592944 ITERATION : 71, loss : 0.44907673515592944 ITERATION : 72, loss : 0.44907673515592944 ITERATION : 73, loss : 0.44907673515592944 ITERATION : 74, loss : 0.44907673515592944 ITERATION : 75, loss : 0.44907673515592944 ITERATION : 76, loss : 0.44907673515592944 ITERATION : 77, loss : 0.44907673515592944 ITERATION : 78, loss : 0.44907673515592944 ITERATION : 79, loss : 0.44907673515592944 ITERATION : 80, loss : 0.44907673515592944 ITERATION : 81, loss : 0.44907673515592944 ITERATION : 82, loss : 0.44907673515592944 ITERATION : 83, loss : 0.44907673515592944 ITERATION : 84, loss : 0.44907673515592944 ITERATION : 85, loss : 0.44907673515592944 ITERATION : 86, loss : 0.44907673515592944 ITERATION : 87, loss : 0.44907673515592944 ITERATION : 88, loss : 0.44907673515592944 ITERATION : 89, loss : 0.44907673515592944 ITERATION : 90, loss : 0.44907673515592944 ITERATION : 91, loss : 0.44907673515592944 ITERATION : 92, loss : 0.44907673515592944 ITERATION : 93, loss : 0.44907673515592944 ITERATION : 94, loss : 0.44907673515592944 ITERATION : 95, loss : 0.44907673515592944 ITERATION : 96, loss : 0.44907673515592944 ITERATION : 97, loss : 0.44907673515592944 ITERATION : 98, loss : 0.44907673515592944 ITERATION : 99, loss : 0.44907673515592944 ITERATION : 100, loss : 0.44907673515592944 
ITERATION : 1, loss : 0.39896838785429295 ITERATION : 2, loss : 0.39896838785429295 ITERATION : 3, loss : 0.39896838785429295 ITERATION : 4, loss : 0.39896838785429295 ITERATION : 5, loss : 0.39896838785429295 ITERATION : 6, loss : 0.39896838785429295 ITERATION : 7, loss : 0.39896838785429295 ITERATION : 8, loss : 0.39896838785429295 ITERATION : 9, loss : 0.39896838785429295 ITERATION : 10, loss : 0.39896838785429295 ITERATION : 11, loss : 0.39896838785429295 ITERATION : 12, loss : 0.39896838785429295 ITERATION : 13, loss : 0.39896838785429295 ITERATION : 14, loss : 0.39896838785429295 ITERATION : 15, loss : 0.39896838785429295 ITERATION : 16, loss : 0.39896838785429295 ITERATION : 17, loss : 0.39896838785429295 ITERATION : 18, loss : 0.39896838785429295 ITERATION : 19, loss : 0.39896838785429295 ITERATION : 20, loss : 0.39896838785429295 ITERATION : 21, loss : 0.39896838785429295 ITERATION : 22, loss : 0.39896838785429295 ITERATION : 23, loss : 0.39896838785429295 ITERATION : 24, loss : 0.39896838785429295 ITERATION : 25, loss : 0.39896838785429295 ITERATION : 26, loss : 0.39896838785429295 ITERATION : 27, loss : 0.39896838785429295 ITERATION : 28, loss : 0.39896838785429295 ITERATION : 29, loss : 0.39896838785429295 ITERATION : 30, loss : 0.39896838785429295 ITERATION : 31, loss : 0.39896838785429295 ITERATION : 32, loss : 0.39896838785429295 ITERATION : 33, loss : 0.39896838785429295 ITERATION : 34, loss : 0.39896838785429295 ITERATION : 35, loss : 0.39896838785429295 ITERATION : 36, loss : 0.39896838785429295 ITERATION : 37, loss : 0.39896838785429295 ITERATION : 38, loss : 0.39896838785429295 ITERATION : 39, loss : 0.39896838785429295 ITERATION : 40, loss : 0.39896838785429295 ITERATION : 41, loss : 0.39896838785429295 ITERATION : 42, loss : 0.39896838785429295 ITERATION : 43, loss : 0.39896838785429295 ITERATION : 44, loss : 0.39896838785429295 ITERATION : 45, loss : 0.39896838785429295 ITERATION : 46, loss : 0.39896838785429295 ITERATION : 47, loss : 0.39896838785429295 ITERATION : 48, loss : 0.39896838785429295 ITERATION : 49, loss : 0.39896838785429295 ITERATION : 50, loss : 0.39896838785429295 ITERATION : 51, loss : 0.39896838785429295 ITERATION : 52, loss : 0.39896838785429295 ITERATION : 53, loss : 0.39896838785429295 ITERATION : 54, loss : 0.39896838785429295 ITERATION : 55, loss : 0.39896838785429295 ITERATION : 56, loss : 0.39896838785429295 ITERATION : 57, loss : 0.39896838785429295 ITERATION : 58, loss : 0.39896838785429295 ITERATION : 59, loss : 0.39896838785429295 ITERATION : 60, loss : 0.39896838785429295 ITERATION : 61, loss : 0.39896838785429295 ITERATION : 62, loss : 0.39896838785429295 ITERATION : 63, loss : 0.39896838785429295 ITERATION : 64, loss : 0.39896838785429295 ITERATION : 65, loss : 0.39896838785429295 ITERATION : 66, loss : 0.39896838785429295 ITERATION : 67, loss : 0.39896838785429295 ITERATION : 68, loss : 0.39896838785429295 ITERATION : 69, loss : 0.39896838785429295 ITERATION : 70, loss : 0.39896838785429295 ITERATION : 71, loss : 0.39896838785429295 ITERATION : 72, loss : 0.39896838785429295 ITERATION : 73, loss : 0.39896838785429295 ITERATION : 74, loss : 0.39896838785429295 ITERATION : 75, loss : 0.39896838785429295 ITERATION : 76, loss : 0.39896838785429295 ITERATION : 77, loss : 0.39896838785429295 ITERATION : 78, loss : 0.39896838785429295 ITERATION : 79, loss : 0.39896838785429295 ITERATION : 80, loss : 0.39896838785429295 ITERATION : 81, loss : 0.39896838785429295 ITERATION : 82, loss : 0.39896838785429295 ITERATION : 83, loss : 0.39896838785429295 ITERATION : 84, loss : 0.39896838785429295 ITERATION : 85, loss : 0.39896838785429295 ITERATION : 86, loss : 0.39896838785429295 ITERATION : 87, loss : 0.39896838785429295 ITERATION : 88, loss : 0.39896838785429295 ITERATION : 89, loss : 0.39896838785429295 ITERATION : 90, loss : 0.39896838785429295 ITERATION : 91, loss : 0.39896838785429295 ITERATION : 92, loss : 0.39896838785429295 ITERATION : 93, loss : 0.39896838785429295 ITERATION : 94, loss : 0.39896838785429295 ITERATION : 95, loss : 0.39896838785429295 ITERATION : 96, loss : 0.39896838785429295 ITERATION : 97, loss : 0.39896838785429295 ITERATION : 98, loss : 0.39896838785429295 ITERATION : 99, loss : 0.39896838785429295 ITERATION : 100, loss : 0.39896838785429295 
ITERATION : 1, loss : 0.2072247430579232 ITERATION : 2, loss : 0.2072247430579232 ITERATION : 3, loss : 0.2072247430579232 ITERATION : 4, loss : 0.2072247430579232 ITERATION : 5, loss : 0.2072247430579232 ITERATION : 6, loss : 0.2072247430579232 ITERATION : 7, loss : 0.2072247430579232 ITERATION : 8, loss : 0.2072247430579232 ITERATION : 9, loss : 0.2072247430579232 ITERATION : 10, loss : 0.2072247430579232 ITERATION : 11, loss : 0.2072247430579232 ITERATION : 12, loss : 0.2072247430579232 ITERATION : 13, loss : 0.2072247430579232 ITERATION : 14, loss : 0.2072247430579232 ITERATION : 15, loss : 0.2072247430579232 ITERATION : 16, loss : 0.2072247430579232 ITERATION : 17, loss : 0.2072247430579232 ITERATION : 18, loss : 0.2072247430579232 ITERATION : 19, loss : 0.2072247430579232 ITERATION : 20, loss : 0.2072247430579232 ITERATION : 21, loss : 0.2072247430579232 ITERATION : 22, loss : 0.2072247430579232 ITERATION : 23, loss : 0.2072247430579232 ITERATION : 24, loss : 0.2072247430579232 ITERATION : 25, loss : 0.2072247430579232 ITERATION : 26, loss : 0.2072247430579232 ITERATION : 27, loss : 0.2072247430579232 ITERATION : 28, loss : 0.2072247430579232 ITERATION : 29, loss : 0.2072247430579232 ITERATION : 30, loss : 0.2072247430579232 ITERATION : 31, loss : 0.2072247430579232 ITERATION : 32, loss : 0.2072247430579232 ITERATION : 33, loss : 0.2072247430579232 ITERATION : 34, loss : 0.2072247430579232 ITERATION : 35, loss : 0.2072247430579232 ITERATION : 36, loss : 0.2072247430579232 ITERATION : 37, loss : 0.2072247430579232 ITERATION : 38, loss : 0.2072247430579232 ITERATION : 39, loss : 0.2072247430579232 ITERATION : 40, loss : 0.2072247430579232 ITERATION : 41, loss : 0.2072247430579232 ITERATION : 42, loss : 0.2072247430579232 ITERATION : 43, loss : 0.2072247430579232 ITERATION : 44, loss : 0.2072247430579232 ITERATION : 45, loss : 0.2072247430579232 ITERATION : 46, loss : 0.2072247430579232 ITERATION : 47, loss : 0.2072247430579232 ITERATION : 48, loss : 0.2072247430579232 ITERATION : 49, loss : 0.2072247430579232 ITERATION : 50, loss : 0.2072247430579232 ITERATION : 51, loss : 0.2072247430579232 ITERATION : 52, loss : 0.2072247430579232 ITERATION : 53, loss : 0.2072247430579232 ITERATION : 54, loss : 0.2072247430579232 ITERATION : 55, loss : 0.2072247430579232 ITERATION : 56, loss : 0.2072247430579232 ITERATION : 57, loss : 0.2072247430579232 ITERATION : 58, loss : 0.2072247430579232 ITERATION : 59, loss : 0.2072247430579232 ITERATION : 60, loss : 0.2072247430579232 ITERATION : 61, loss : 0.2072247430579232 ITERATION : 62, loss : 0.2072247430579232 ITERATION : 63, loss : 0.2072247430579232 ITERATION : 64, loss : 0.2072247430579232 ITERATION : 65, loss : 0.2072247430579232 ITERATION : 66, loss : 0.2072247430579232 ITERATION : 67, loss : 0.2072247430579232 ITERATION : 68, loss : 0.2072247430579232 ITERATION : 69, loss : 0.2072247430579232 ITERATION : 70, loss : 0.2072247430579232 ITERATION : 71, loss : 0.2072247430579232 ITERATION : 72, loss : 0.2072247430579232 ITERATION : 73, loss : 0.2072247430579232 ITERATION : 74, loss : 0.2072247430579232 ITERATION : 75, loss : 0.2072247430579232 ITERATION : 76, loss : 0.2072247430579232 ITERATION : 77, loss : 0.2072247430579232 ITERATION : 78, loss : 0.2072247430579232 ITERATION : 79, loss : 0.2072247430579232 ITERATION : 80, loss : 0.2072247430579232 ITERATION : 81, loss : 0.2072247430579232 ITERATION : 82, loss : 0.2072247430579232 ITERATION : 83, loss : 0.2072247430579232 ITERATION : 84, loss : 0.2072247430579232 ITERATION : 85, loss : 0.2072247430579232 ITERATION : 86, loss : 0.2072247430579232 ITERATION : 87, loss : 0.2072247430579232 ITERATION : 88, loss : 0.2072247430579232 ITERATION : 89, loss : 0.2072247430579232 ITERATION : 90, loss : 0.2072247430579232 ITERATION : 91, loss : 0.2072247430579232 ITERATION : 92, loss : 0.2072247430579232 ITERATION : 93, loss : 0.2072247430579232 ITERATION : 94, loss : 0.2072247430579232 ITERATION : 95, loss : 0.2072247430579232 ITERATION : 96, loss : 0.2072247430579232 ITERATION : 97, loss : 0.2072247430579232 ITERATION : 98, loss : 0.2072247430579232 ITERATION : 99, loss : 0.2072247430579232 ITERATION : 100, loss : 0.2072247430579232 
ITERATION : 1, loss : 0.3353150315306748 ITERATION : 2, loss : 0.3353150315306748 ITERATION : 3, loss : 0.3353150315306748 ITERATION : 4, loss : 0.3353150315306748 ITERATION : 5, loss : 0.3353150315306748 ITERATION : 6, loss : 0.3353150315306748 ITERATION : 7, loss : 0.3353150315306748 ITERATION : 8, loss : 0.3353150315306748 ITERATION : 9, loss : 0.3353150315306748 ITERATION : 10, loss : 0.3353150315306748 ITERATION : 11, loss : 0.3353150315306748 ITERATION : 12, loss : 0.3353150315306748 ITERATION : 13, loss : 0.3353150315306748 ITERATION : 14, loss : 0.3353150315306748 ITERATION : 15, loss : 0.3353150315306748 ITERATION : 16, loss : 0.3353150315306748 ITERATION : 17, loss : 0.3353150315306748 ITERATION : 18, loss : 0.3353150315306748 ITERATION : 19, loss : 0.3353150315306748 ITERATION : 20, loss : 0.3353150315306748 ITERATION : 21, loss : 0.3353150315306748 ITERATION : 22, loss : 0.3353150315306748 ITERATION : 23, loss : 0.3353150315306748 ITERATION : 24, loss : 0.3353150315306748 ITERATION : 25, loss : 0.3353150315306748 ITERATION : 26, loss : 0.3353150315306748 ITERATION : 27, loss : 0.3353150315306748 ITERATION : 28, loss : 0.3353150315306748 ITERATION : 29, loss : 0.3353150315306748 ITERATION : 30, loss : 0.3353150315306748 ITERATION : 31, loss : 0.3353150315306748 ITERATION : 32, loss : 0.3353150315306748 ITERATION : 33, loss : 0.3353150315306748 ITERATION : 34, loss : 0.3353150315306748 ITERATION : 35, loss : 0.3353150315306748 ITERATION : 36, loss : 0.3353150315306748 ITERATION : 37, loss : 0.3353150315306748 ITERATION : 38, loss : 0.3353150315306748 ITERATION : 39, loss : 0.3353150315306748 ITERATION : 40, loss : 0.3353150315306748 ITERATION : 41, loss : 0.3353150315306748 ITERATION : 42, loss : 0.3353150315306748 ITERATION : 43, loss : 0.3353150315306748 ITERATION : 44, loss : 0.3353150315306748 ITERATION : 45, loss : 0.3353150315306748 ITERATION : 46, loss : 0.3353150315306748 ITERATION : 47, loss : 0.3353150315306748 ITERATION : 48, loss : 0.3353150315306748 ITERATION : 49, loss : 0.3353150315306748 ITERATION : 50, loss : 0.3353150315306748 ITERATION : 51, loss : 0.3353150315306748 ITERATION : 52, loss : 0.3353150315306748 ITERATION : 53, loss : 0.3353150315306748 ITERATION : 54, loss : 0.3353150315306748 ITERATION : 55, loss : 0.3353150315306748 ITERATION : 56, loss : 0.3353150315306748 ITERATION : 57, loss : 0.3353150315306748 ITERATION : 58, loss : 0.3353150315306748 ITERATION : 59, loss : 0.3353150315306748 ITERATION : 60, loss : 0.3353150315306748 ITERATION : 61, loss : 0.3353150315306748 ITERATION : 62, loss : 0.3353150315306748 ITERATION : 63, loss : 0.3353150315306748 ITERATION : 64, loss : 0.3353150315306748 ITERATION : 65, loss : 0.3353150315306748 ITERATION : 66, loss : 0.3353150315306748 ITERATION : 67, loss : 0.3353150315306748 ITERATION : 68, loss : 0.3353150315306748 ITERATION : 69, loss : 0.3353150315306748 ITERATION : 70, loss : 0.3353150315306748 ITERATION : 71, loss : 0.3353150315306748 ITERATION : 72, loss : 0.3353150315306748 ITERATION : 73, loss : 0.3353150315306748 ITERATION : 74, loss : 0.3353150315306748 ITERATION : 75, loss : 0.3353150315306748 ITERATION : 76, loss : 0.3353150315306748 ITERATION : 77, loss : 0.3353150315306748 ITERATION : 78, loss : 0.3353150315306748 ITERATION : 79, loss : 0.3353150315306748 ITERATION : 80, loss : 0.3353150315306748 ITERATION : 81, loss : 0.3353150315306748 ITERATION : 82, loss : 0.3353150315306748 ITERATION : 83, loss : 0.3353150315306748 ITERATION : 84, loss : 0.3353150315306748 ITERATION : 85, loss : 0.3353150315306748 ITERATION : 86, loss : 0.3353150315306748 ITERATION : 87, loss : 0.3353150315306748 ITERATION : 88, loss : 0.3353150315306748 ITERATION : 89, loss : 0.3353150315306748 ITERATION : 90, loss : 0.3353150315306748 ITERATION : 91, loss : 0.3353150315306748 ITERATION : 92, loss : 0.3353150315306748 ITERATION : 93, loss : 0.3353150315306748 ITERATION : 94, loss : 0.3353150315306748 ITERATION : 95, loss : 0.3353150315306748 ITERATION : 96, loss : 0.3353150315306748 ITERATION : 97, loss : 0.3353150315306748 ITERATION : 98, loss : 0.3353150315306748 ITERATION : 99, loss : 0.3353150315306748 ITERATION : 100, loss : 0.3353150315306748 
ITERATION : 1, loss : 0.327363776836232 ITERATION : 2, loss : 0.327363776836232 ITERATION : 3, loss : 0.327363776836232 ITERATION : 4, loss : 0.327363776836232 ITERATION : 5, loss : 0.327363776836232 ITERATION : 6, loss : 0.327363776836232 ITERATION : 7, loss : 0.327363776836232 ITERATION : 8, loss : 0.327363776836232 ITERATION : 9, loss : 0.327363776836232 ITERATION : 10, loss : 0.327363776836232 ITERATION : 11, loss : 0.327363776836232 ITERATION : 12, loss : 0.327363776836232 ITERATION : 13, loss : 0.327363776836232 ITERATION : 14, loss : 0.327363776836232 ITERATION : 15, loss : 0.327363776836232 ITERATION : 16, loss : 0.327363776836232 ITERATION : 17, loss : 0.327363776836232 ITERATION : 18, loss : 0.327363776836232 ITERATION : 19, loss : 0.327363776836232 ITERATION : 20, loss : 0.327363776836232 ITERATION : 21, loss : 0.327363776836232 ITERATION : 22, loss : 0.327363776836232 ITERATION : 23, loss : 0.327363776836232 ITERATION : 24, loss : 0.327363776836232 ITERATION : 25, loss : 0.327363776836232 ITERATION : 26, loss : 0.327363776836232 ITERATION : 27, loss : 0.327363776836232 ITERATION : 28, loss : 0.327363776836232 ITERATION : 29, loss : 0.327363776836232 ITERATION : 30, loss : 0.327363776836232 ITERATION : 31, loss : 0.327363776836232 ITERATION : 32, loss : 0.327363776836232 ITERATION : 33, loss : 0.327363776836232 ITERATION : 34, loss : 0.327363776836232 ITERATION : 35, loss : 0.327363776836232 ITERATION : 36, loss : 0.327363776836232 ITERATION : 37, loss : 0.327363776836232 ITERATION : 38, loss : 0.327363776836232 ITERATION : 39, loss : 0.327363776836232 ITERATION : 40, loss : 0.327363776836232 ITERATION : 41, loss : 0.327363776836232 ITERATION : 42, loss : 0.327363776836232 ITERATION : 43, loss : 0.327363776836232 ITERATION : 44, loss : 0.327363776836232 ITERATION : 45, loss : 0.327363776836232 ITERATION : 46, loss : 0.327363776836232 ITERATION : 47, loss : 0.327363776836232 ITERATION : 48, loss : 0.327363776836232 ITERATION : 49, loss : 0.327363776836232 ITERATION : 50, loss : 0.327363776836232 ITERATION : 51, loss : 0.327363776836232 ITERATION : 52, loss : 0.327363776836232 ITERATION : 53, loss : 0.327363776836232 ITERATION : 54, loss : 0.327363776836232 ITERATION : 55, loss : 0.327363776836232 ITERATION : 56, loss : 0.327363776836232 ITERATION : 57, loss : 0.327363776836232 ITERATION : 58, loss : 0.327363776836232 ITERATION : 59, loss : 0.327363776836232 ITERATION : 60, loss : 0.327363776836232 ITERATION : 61, loss : 0.327363776836232 ITERATION : 62, loss : 0.327363776836232 ITERATION : 63, loss : 0.327363776836232 ITERATION : 64, loss : 0.327363776836232 ITERATION : 65, loss : 0.327363776836232 ITERATION : 66, loss : 0.327363776836232 ITERATION : 67, loss : 0.327363776836232 ITERATION : 68, loss : 0.327363776836232 ITERATION : 69, loss : 0.327363776836232 ITERATION : 70, loss : 0.327363776836232 ITERATION : 71, loss : 0.327363776836232 ITERATION : 72, loss : 0.327363776836232 ITERATION : 73, loss : 0.327363776836232 ITERATION : 74, loss : 0.327363776836232 ITERATION : 75, loss : 0.327363776836232 ITERATION : 76, loss : 0.327363776836232 ITERATION : 77, loss : 0.327363776836232 ITERATION : 78, loss : 0.327363776836232 ITERATION : 79, loss : 0.327363776836232 ITERATION : 80, loss : 0.327363776836232 ITERATION : 81, loss : 0.327363776836232 ITERATION : 82, loss : 0.327363776836232 ITERATION : 83, loss : 0.327363776836232 ITERATION : 84, loss : 0.327363776836232 ITERATION : 85, loss : 0.327363776836232 ITERATION : 86, loss : 0.327363776836232 ITERATION : 87, loss : 0.327363776836232 ITERATION : 88, loss : 0.327363776836232 ITERATION : 89, loss : 0.327363776836232 ITERATION : 90, loss : 0.327363776836232 ITERATION : 91, loss : 0.327363776836232 ITERATION : 92, loss : 0.327363776836232 ITERATION : 93, loss : 0.327363776836232 ITERATION : 94, loss : 0.327363776836232 ITERATION : 95, loss : 0.327363776836232 ITERATION : 96, loss : 0.327363776836232 ITERATION : 97, loss : 0.327363776836232 ITERATION : 98, loss : 0.327363776836232 ITERATION : 99, loss : 0.327363776836232 ITERATION : 100, loss : 0.327363776836232 
ITERATION : 1, loss : 0.23870313646351332 ITERATION : 2, loss : 0.23870313646351332 ITERATION : 3, loss : 0.23870313646351332 ITERATION : 4, loss : 0.23870313646351332 ITERATION : 5, loss : 0.23870313646351332 ITERATION : 6, loss : 0.23870313646351332 ITERATION : 7, loss : 0.23870313646351332 ITERATION : 8, loss : 0.23870313646351332 ITERATION : 9, loss : 0.23870313646351332 ITERATION : 10, loss : 0.23870313646351332 ITERATION : 11, loss : 0.23870313646351332 ITERATION : 12, loss : 0.23870313646351332 ITERATION : 13, loss : 0.23870313646351332 ITERATION : 14, loss : 0.23870313646351332 ITERATION : 15, loss : 0.23870313646351332 ITERATION : 16, loss : 0.23870313646351332 ITERATION : 17, loss : 0.23870313646351332 ITERATION : 18, loss : 0.23870313646351332 ITERATION : 19, loss : 0.23870313646351332 ITERATION : 20, loss : 0.23870313646351332 ITERATION : 21, loss : 0.23870313646351332 ITERATION : 22, loss : 0.23870313646351332 ITERATION : 23, loss : 0.23870313646351332 ITERATION : 24, loss : 0.23870313646351332 ITERATION : 25, loss : 0.23870313646351332 ITERATION : 26, loss : 0.23870313646351332 ITERATION : 27, loss : 0.23870313646351332 ITERATION : 28, loss : 0.23870313646351332 ITERATION : 29, loss : 0.23870313646351332 ITERATION : 30, loss : 0.23870313646351332 ITERATION : 31, loss : 0.23870313646351332 ITERATION : 32, loss : 0.23870313646351332 ITERATION : 33, loss : 0.23870313646351332 ITERATION : 34, loss : 0.23870313646351332 ITERATION : 35, loss : 0.23870313646351332 ITERATION : 36, loss : 0.23870313646351332 ITERATION : 37, loss : 0.23870313646351332 ITERATION : 38, loss : 0.23870313646351332 ITERATION : 39, loss : 0.23870313646351332 ITERATION : 40, loss : 0.23870313646351332 ITERATION : 41, loss : 0.23870313646351332 ITERATION : 42, loss : 0.23870313646351332 ITERATION : 43, loss : 0.23870313646351332 ITERATION : 44, loss : 0.23870313646351332 ITERATION : 45, loss : 0.23870313646351332 ITERATION : 46, loss : 0.23870313646351332 ITERATION : 47, loss : 0.23870313646351332 ITERATION : 48, loss : 0.23870313646351332 ITERATION : 49, loss : 0.23870313646351332 ITERATION : 50, loss : 0.23870313646351332 ITERATION : 51, loss : 0.23870313646351332 ITERATION : 52, loss : 0.23870313646351332 ITERATION : 53, loss : 0.23870313646351332 ITERATION : 54, loss : 0.23870313646351332 ITERATION : 55, loss : 0.23870313646351332 ITERATION : 56, loss : 0.23870313646351332 ITERATION : 57, loss : 0.23870313646351332 ITERATION : 58, loss : 0.23870313646351332 ITERATION : 59, loss : 0.23870313646351332 ITERATION : 60, loss : 0.23870313646351332 ITERATION : 61, loss : 0.23870313646351332 ITERATION : 62, loss : 0.23870313646351332 ITERATION : 63, loss : 0.23870313646351332 ITERATION : 64, loss : 0.23870313646351332 ITERATION : 65, loss : 0.23870313646351332 ITERATION : 66, loss : 0.23870313646351332 ITERATION : 67, loss : 0.23870313646351332 ITERATION : 68, loss : 0.23870313646351332 ITERATION : 69, loss : 0.23870313646351332 ITERATION : 70, loss : 0.23870313646351332 ITERATION : 71, loss : 0.23870313646351332 ITERATION : 72, loss : 0.23870313646351332 ITERATION : 73, loss : 0.23870313646351332 ITERATION : 74, loss : 0.23870313646351332 ITERATION : 75, loss : 0.23870313646351332 ITERATION : 76, loss : 0.23870313646351332 ITERATION : 77, loss : 0.23870313646351332 ITERATION : 78, loss : 0.23870313646351332 ITERATION : 79, loss : 0.23870313646351332 ITERATION : 80, loss : 0.23870313646351332 ITERATION : 81, loss : 0.23870313646351332 ITERATION : 82, loss : 0.23870313646351332 ITERATION : 83, loss : 0.23870313646351332 ITERATION : 84, loss : 0.23870313646351332 ITERATION : 85, loss : 0.23870313646351332 ITERATION : 86, loss : 0.23870313646351332 ITERATION : 87, loss : 0.23870313646351332 ITERATION : 88, loss : 0.23870313646351332 ITERATION : 89, loss : 0.23870313646351332 ITERATION : 90, loss : 0.23870313646351332 ITERATION : 91, loss : 0.23870313646351332 ITERATION : 92, loss : 0.23870313646351332 ITERATION : 93, loss : 0.23870313646351332 ITERATION : 94, loss : 0.23870313646351332 ITERATION : 95, loss : 0.23870313646351332 ITERATION : 96, loss : 0.23870313646351332 ITERATION : 97, loss : 0.23870313646351332 ITERATION : 98, loss : 0.23870313646351332 ITERATION : 99, loss : 0.23870313646351332 ITERATION : 100, loss : 0.23870313646351332 
gradient norm in None layer : 1.2148063988798827
gradient norm in None layer : 0.11038300510674746
gradient norm in None layer : 0.11315126718625014
gradient norm in None layer : 1.6527675716189296
gradient norm in None layer : 0.06713831410617502
gradient norm in None layer : 0.08318569976869152
gradient norm in None layer : 0.5944012733407567
gradient norm in None layer : 0.024065011617381924
gradient norm in None layer : 0.02676159034819757
gradient norm in None layer : 0.5536156585818708
gradient norm in None layer : 0.019450195999719044
gradient norm in None layer : 0.02170398360664773
gradient norm in None layer : 0.14209931138545207
gradient norm in None layer : 0.0037925017736578828
gradient norm in None layer : 0.0037099083751519174
gradient norm in None layer : 0.12384754192298972
gradient norm in None layer : 0.004611421182078941
gradient norm in None layer : 0.0049940166500674265
gradient norm in None layer : 0.15751087783783874
gradient norm in None layer : 0.0024527151415902693
gradient norm in None layer : 0.4592855605351456
gradient norm in None layer : 0.021169193140207865
gradient norm in None layer : 0.021052429865678884
gradient norm in None layer : 0.4809790900846196
gradient norm in None layer : 0.024026582337628583
gradient norm in None layer : 0.027917375982981545
gradient norm in None layer : 0.6485409551569894
gradient norm in None layer : 0.008737097568088147
gradient norm in None layer : 1.1704886564274535
gradient norm in None layer : 0.08327571869891696
gradient norm in None layer : 0.0711230246036577
gradient norm in None layer : 1.1717511616043064
gradient norm in None layer : 0.2621174256427034
gradient norm in None layer : 0.39882960020307817
gradient norm in None layer : 0.18185797629977227
gradient norm in None layer : 0.06425458665986132
Total gradient norm: 2.9751305487246893
invariance loss : 395.96572487756225, avg_den : 0.0, density loss : 0.1, mse loss : 0.27801972646434436, solver time : 0.8277575969696045 sec , total loss : 0.7739854513419067, running loss : 1.6274476135474256
Epoch 0/10 , batch 3/12500 
ITERATION : 1, loss : 0.6583549852959748 ITERATION : 2, loss : 0.6583549852959748 ITERATION : 3, loss : 0.6583549852959748 ITERATION : 4, loss : 0.6583549852959748 ITERATION : 5, loss : 0.6583549852959748 ITERATION : 6, loss : 0.6583549852959748 ITERATION : 7, loss : 0.6583549852959748 ITERATION : 8, loss : 0.6583549852959748 ITERATION : 9, loss : 0.6583549852959748 ITERATION : 10, loss : 0.6583549852959748 ITERATION : 11, loss : 0.6583549852959748 ITERATION : 12, loss : 0.6583549852959748 ITERATION : 13, loss : 0.6583549852959748 ITERATION : 14, loss : 0.6583549852959748 ITERATION : 15, loss : 0.6583549852959748 ITERATION : 16, loss : 0.6583549852959748 ITERATION : 17, loss : 0.6583549852959748 ITERATION : 18, loss : 0.6583549852959748 ITERATION : 19, loss : 0.6583549852959748 ITERATION : 20, loss : 0.6583549852959748 ITERATION : 21, loss : 0.6583549852959748 ITERATION : 22, loss : 0.6583549852959748 ITERATION : 23, loss : 0.6583549852959748 ITERATION : 24, loss : 0.6583549852959748 ITERATION : 25, loss : 0.6583549852959748 ITERATION : 26, loss : 0.6583549852959748 ITERATION : 27, loss : 0.6583549852959748 ITERATION : 28, loss : 0.6583549852959748 ITERATION : 29, loss : 0.6583549852959748 ITERATION : 30, loss : 0.6583549852959748 ITERATION : 31, loss : 0.6583549852959748 ITERATION : 32, loss : 0.6583549852959748 ITERATION : 33, loss : 0.6583549852959748 ITERATION : 34, loss : 0.6583549852959748 ITERATION : 35, loss : 0.6583549852959748 ITERATION : 36, loss : 0.6583549852959748 ITERATION : 37, loss : 0.6583549852959748 ITERATION : 38, loss : 0.6583549852959748 ITERATION : 39, loss : 0.6583549852959748 ITERATION : 40, loss : 0.6583549852959748 ITERATION : 41, loss : 0.6583549852959748 ITERATION : 42, loss : 0.6583549852959748 ITERATION : 43, loss : 0.6583549852959748 ITERATION : 44, loss : 0.6583549852959748 ITERATION : 45, loss : 0.6583549852959748 ITERATION : 46, loss : 0.6583549852959748 ITERATION : 47, loss : 0.6583549852959748 ITERATION : 48, loss : 0.6583549852959748 ITERATION : 49, loss : 0.6583549852959748 ITERATION : 50, loss : 0.6583549852959748 ITERATION : 51, loss : 0.6583549852959748 ITERATION : 52, loss : 0.6583549852959748 ITERATION : 53, loss : 0.6583549852959748 ITERATION : 54, loss : 0.6583549852959748 ITERATION : 55, loss : 0.6583549852959748 ITERATION : 56, loss : 0.6583549852959748 ITERATION : 57, loss : 0.6583549852959748 ITERATION : 58, loss : 0.6583549852959748 ITERATION : 59, loss : 0.6583549852959748 ITERATION : 60, loss : 0.6583549852959748 ITERATION : 61, loss : 0.6583549852959748 ITERATION : 62, loss : 0.6583549852959748 ITERATION : 63, loss : 0.6583549852959748 ITERATION : 64, loss : 0.6583549852959748 ITERATION : 65, loss : 0.6583549852959748 ITERATION : 66, loss : 0.6583549852959748 ITERATION : 67, loss : 0.6583549852959748 ITERATION : 68, loss : 0.6583549852959748 ITERATION : 69, loss : 0.6583549852959748 ITERATION : 70, loss : 0.6583549852959748 ITERATION : 71, loss : 0.6583549852959748 ITERATION : 72, loss : 0.6583549852959748 ITERATION : 73, loss : 0.6583549852959748 ITERATION : 74, loss : 0.6583549852959748 ITERATION : 75, loss : 0.6583549852959748 ITERATION : 76, loss : 0.6583549852959748 ITERATION : 77, loss : 0.6583549852959748 ITERATION : 78, loss : 0.6583549852959748 ITERATION : 79, loss : 0.6583549852959748 ITERATION : 80, loss : 0.6583549852959748 ITERATION : 81, loss : 0.6583549852959748 ITERATION : 82, loss : 0.6583549852959748 ITERATION : 83, loss : 0.6583549852959748 ITERATION : 84, loss : 0.6583549852959748 ITERATION : 85, loss : 0.6583549852959748 ITERATION : 86, loss : 0.6583549852959748 ITERATION : 87, loss : 0.6583549852959748 ITERATION : 88, loss : 0.6583549852959748 ITERATION : 89, loss : 0.6583549852959748 ITERATION : 90, loss : 0.6583549852959748 ITERATION : 91, loss : 0.6583549852959748 ITERATION : 92, loss : 0.6583549852959748 ITERATION : 93, loss : 0.6583549852959748 ITERATION : 94, loss : 0.6583549852959748 ITERATION : 95, loss : 0.6583549852959748 ITERATION : 96, loss : 0.6583549852959748 ITERATION : 97, loss : 0.6583549852959748 ITERATION : 98, loss : 0.6583549852959748 ITERATION : 99, loss : 0.6583549852959748 ITERATION : 100, loss : 0.6583549852959748 
ITERATION : 1, loss : 0.31265566249847243 ITERATION : 2, loss : 0.31265566249847243 ITERATION : 3, loss : 0.31265566249847243 ITERATION : 4, loss : 0.31265566249847243 ITERATION : 5, loss : 0.31265566249847243 ITERATION : 6, loss : 0.31265566249847243 ITERATION : 7, loss : 0.31265566249847243 ITERATION : 8, loss : 0.31265566249847243 ITERATION : 9, loss : 0.31265566249847243 ITERATION : 10, loss : 0.31265566249847243 ITERATION : 11, loss : 0.31265566249847243 ITERATION : 12, loss : 0.31265566249847243 ITERATION : 13, loss : 0.31265566249847243 ITERATION : 14, loss : 0.31265566249847243 ITERATION : 15, loss : 0.31265566249847243 ITERATION : 16, loss : 0.31265566249847243 ITERATION : 17, loss : 0.31265566249847243 ITERATION : 18, loss : 0.31265566249847243 ITERATION : 19, loss : 0.31265566249847243 ITERATION : 20, loss : 0.31265566249847243 ITERATION : 21, loss : 0.31265566249847243 ITERATION : 22, loss : 0.31265566249847243 ITERATION : 23, loss : 0.31265566249847243 ITERATION : 24, loss : 0.31265566249847243 ITERATION : 25, loss : 0.31265566249847243 ITERATION : 26, loss : 0.31265566249847243 ITERATION : 27, loss : 0.31265566249847243 ITERATION : 28, loss : 0.31265566249847243 ITERATION : 29, loss : 0.31265566249847243 ITERATION : 30, loss : 0.31265566249847243 ITERATION : 31, loss : 0.31265566249847243 ITERATION : 32, loss : 0.31265566249847243 ITERATION : 33, loss : 0.31265566249847243 ITERATION : 34, loss : 0.31265566249847243 ITERATION : 35, loss : 0.31265566249847243 ITERATION : 36, loss : 0.31265566249847243 ITERATION : 37, loss : 0.31265566249847243 ITERATION : 38, loss : 0.31265566249847243 ITERATION : 39, loss : 0.31265566249847243 ITERATION : 40, loss : 0.31265566249847243 ITERATION : 41, loss : 0.31265566249847243 ITERATION : 42, loss : 0.31265566249847243 ITERATION : 43, loss : 0.31265566249847243 ITERATION : 44, loss : 0.31265566249847243 ITERATION : 45, loss : 0.31265566249847243 ITERATION : 46, loss : 0.31265566249847243 ITERATION : 47, loss : 0.31265566249847243 ITERATION : 48, loss : 0.31265566249847243 ITERATION : 49, loss : 0.31265566249847243 ITERATION : 50, loss : 0.31265566249847243 ITERATION : 51, loss : 0.31265566249847243 ITERATION : 52, loss : 0.31265566249847243 ITERATION : 53, loss : 0.31265566249847243 ITERATION : 54, loss : 0.31265566249847243 ITERATION : 55, loss : 0.31265566249847243 ITERATION : 56, loss : 0.31265566249847243 ITERATION : 57, loss : 0.31265566249847243 ITERATION : 58, loss : 0.31265566249847243 ITERATION : 59, loss : 0.31265566249847243 ITERATION : 60, loss : 0.31265566249847243 ITERATION : 61, loss : 0.31265566249847243 ITERATION : 62, loss : 0.31265566249847243 ITERATION : 63, loss : 0.31265566249847243 ITERATION : 64, loss : 0.31265566249847243 ITERATION : 65, loss : 0.31265566249847243 ITERATION : 66, loss : 0.31265566249847243 ITERATION : 67, loss : 0.31265566249847243 ITERATION : 68, loss : 0.31265566249847243 ITERATION : 69, loss : 0.31265566249847243 ITERATION : 70, loss : 0.31265566249847243 ITERATION : 71, loss : 0.31265566249847243 ITERATION : 72, loss : 0.31265566249847243 ITERATION : 73, loss : 0.31265566249847243 ITERATION : 74, loss : 0.31265566249847243 ITERATION : 75, loss : 0.31265566249847243 ITERATION : 76, loss : 0.31265566249847243 ITERATION : 77, loss : 0.31265566249847243 ITERATION : 78, loss : 0.31265566249847243 ITERATION : 79, loss : 0.31265566249847243 ITERATION : 80, loss : 0.31265566249847243 ITERATION : 81, loss : 0.31265566249847243 ITERATION : 82, loss : 0.31265566249847243 ITERATION : 83, loss : 0.31265566249847243 ITERATION : 84, loss : 0.31265566249847243 ITERATION : 85, loss : 0.31265566249847243 ITERATION : 86, loss : 0.31265566249847243 ITERATION : 87, loss : 0.31265566249847243 ITERATION : 88, loss : 0.31265566249847243 ITERATION : 89, loss : 0.31265566249847243 ITERATION : 90, loss : 0.31265566249847243 ITERATION : 91, loss : 0.31265566249847243 ITERATION : 92, loss : 0.31265566249847243 ITERATION : 93, loss : 0.31265566249847243 ITERATION : 94, loss : 0.31265566249847243 ITERATION : 95, loss : 0.31265566249847243 ITERATION : 96, loss : 0.31265566249847243 ITERATION : 97, loss : 0.31265566249847243 ITERATION : 98, loss : 0.31265566249847243 ITERATION : 99, loss : 0.31265566249847243 ITERATION : 100, loss : 0.31265566249847243 
ITERATION : 1, loss : 0.23653009341874298 ITERATION : 2, loss : 0.23653009341874298 ITERATION : 3, loss : 0.23653009341874298 ITERATION : 4, loss : 0.23653009341874298 ITERATION : 5, loss : 0.23653009341874298 ITERATION : 6, loss : 0.23653009341874298 ITERATION : 7, loss : 0.23653009341874298 ITERATION : 8, loss : 0.23653009341874298 ITERATION : 9, loss : 0.23653009341874298 ITERATION : 10, loss : 0.23653009341874298 ITERATION : 11, loss : 0.23653009341874298 ITERATION : 12, loss : 0.23653009341874298 ITERATION : 13, loss : 0.23653009341874298 ITERATION : 14, loss : 0.23653009341874298 ITERATION : 15, loss : 0.23653009341874298 ITERATION : 16, loss : 0.23653009341874298 ITERATION : 17, loss : 0.23653009341874298 ITERATION : 18, loss : 0.23653009341874298 ITERATION : 19, loss : 0.23653009341874298 ITERATION : 20, loss : 0.23653009341874298 ITERATION : 21, loss : 0.23653009341874298 ITERATION : 22, loss : 0.23653009341874298 ITERATION : 23, loss : 0.23653009341874298 ITERATION : 24, loss : 0.23653009341874298 ITERATION : 25, loss : 0.23653009341874298 ITERATION : 26, loss : 0.23653009341874298 ITERATION : 27, loss : 0.23653009341874298 ITERATION : 28, loss : 0.23653009341874298 ITERATION : 29, loss : 0.23653009341874298 ITERATION : 30, loss : 0.23653009341874298 ITERATION : 31, loss : 0.23653009341874298 ITERATION : 32, loss : 0.23653009341874298 ITERATION : 33, loss : 0.23653009341874298 ITERATION : 34, loss : 0.23653009341874298 ITERATION : 35, loss : 0.23653009341874298 ITERATION : 36, loss : 0.23653009341874298 ITERATION : 37, loss : 0.23653009341874298 ITERATION : 38, loss : 0.23653009341874298 ITERATION : 39, loss : 0.23653009341874298 ITERATION : 40, loss : 0.23653009341874298 ITERATION : 41, loss : 0.23653009341874298 ITERATION : 42, loss : 0.23653009341874298 ITERATION : 43, loss : 0.23653009341874298 ITERATION : 44, loss : 0.23653009341874298 ITERATION : 45, loss : 0.23653009341874298 ITERATION : 46, loss : 0.23653009341874298 ITERATION : 47, loss : 0.23653009341874298 ITERATION : 48, loss : 0.23653009341874298 ITERATION : 49, loss : 0.23653009341874298 ITERATION : 50, loss : 0.23653009341874298 ITERATION : 51, loss : 0.23653009341874298 ITERATION : 52, loss : 0.23653009341874298 ITERATION : 53, loss : 0.23653009341874298 ITERATION : 54, loss : 0.23653009341874298 ITERATION : 55, loss : 0.23653009341874298 ITERATION : 56, loss : 0.23653009341874298 ITERATION : 57, loss : 0.23653009341874298 ITERATION : 58, loss : 0.23653009341874298 ITERATION : 59, loss : 0.23653009341874298 ITERATION : 60, loss : 0.23653009341874298 ITERATION : 61, loss : 0.23653009341874298 ITERATION : 62, loss : 0.23653009341874298 ITERATION : 63, loss : 0.23653009341874298 ITERATION : 64, loss : 0.23653009341874298 ITERATION : 65, loss : 0.23653009341874298 ITERATION : 66, loss : 0.23653009341874298 ITERATION : 67, loss : 0.23653009341874298 ITERATION : 68, loss : 0.23653009341874298 ITERATION : 69, loss : 0.23653009341874298 ITERATION : 70, loss : 0.23653009341874298 ITERATION : 71, loss : 0.23653009341874298 ITERATION : 72, loss : 0.23653009341874298 ITERATION : 73, loss : 0.23653009341874298 ITERATION : 74, loss : 0.23653009341874298 ITERATION : 75, loss : 0.23653009341874298 ITERATION : 76, loss : 0.23653009341874298 ITERATION : 77, loss : 0.23653009341874298 ITERATION : 78, loss : 0.23653009341874298 ITERATION : 79, loss : 0.23653009341874298 ITERATION : 80, loss : 0.23653009341874298 ITERATION : 81, loss : 0.23653009341874298 ITERATION : 82, loss : 0.23653009341874298 ITERATION : 83, loss : 0.23653009341874298 ITERATION : 84, loss : 0.23653009341874298 ITERATION : 85, loss : 0.23653009341874298 ITERATION : 86, loss : 0.23653009341874298 ITERATION : 87, loss : 0.23653009341874298 ITERATION : 88, loss : 0.23653009341874298 ITERATION : 89, loss : 0.23653009341874298 ITERATION : 90, loss : 0.23653009341874298 ITERATION : 91, loss : 0.23653009341874298 ITERATION : 92, loss : 0.23653009341874298 ITERATION : 93, loss : 0.23653009341874298 ITERATION : 94, loss : 0.23653009341874298 ITERATION : 95, loss : 0.23653009341874298 ITERATION : 96, loss : 0.23653009341874298 ITERATION : 97, loss : 0.23653009341874298 ITERATION : 98, loss : 0.23653009341874298 ITERATION : 99, loss : 0.23653009341874298 ITERATION : 100, loss : 0.23653009341874298 
ITERATION : 1, loss : 0.1217012770142853 ITERATION : 2, loss : 0.1217012770142853 ITERATION : 3, loss : 0.1217012770142853 ITERATION : 4, loss : 0.1217012770142853 ITERATION : 5, loss : 0.1217012770142853 ITERATION : 6, loss : 0.1217012770142853 ITERATION : 7, loss : 0.1217012770142853 ITERATION : 8, loss : 0.1217012770142853 ITERATION : 9, loss : 0.1217012770142853 ITERATION : 10, loss : 0.1217012770142853 ITERATION : 11, loss : 0.1217012770142853 ITERATION : 12, loss : 0.1217012770142853 ITERATION : 13, loss : 0.1217012770142853 ITERATION : 14, loss : 0.1217012770142853 ITERATION : 15, loss : 0.1217012770142853 ITERATION : 16, loss : 0.1217012770142853 ITERATION : 17, loss : 0.1217012770142853 ITERATION : 18, loss : 0.1217012770142853 ITERATION : 19, loss : 0.1217012770142853 ITERATION : 20, loss : 0.1217012770142853 ITERATION : 21, loss : 0.1217012770142853 ITERATION : 22, loss : 0.1217012770142853 ITERATION : 23, loss : 0.1217012770142853 ITERATION : 24, loss : 0.1217012770142853 ITERATION : 25, loss : 0.1217012770142853 ITERATION : 26, loss : 0.1217012770142853 ITERATION : 27, loss : 0.1217012770142853 ITERATION : 28, loss : 0.1217012770142853 ITERATION : 29, loss : 0.1217012770142853 ITERATION : 30, loss : 0.1217012770142853 ITERATION : 31, loss : 0.1217012770142853 ITERATION : 32, loss : 0.1217012770142853 ITERATION : 33, loss : 0.1217012770142853 ITERATION : 34, loss : 0.1217012770142853 ITERATION : 35, loss : 0.1217012770142853 ITERATION : 36, loss : 0.1217012770142853 ITERATION : 37, loss : 0.1217012770142853 ITERATION : 38, loss : 0.1217012770142853 ITERATION : 39, loss : 0.1217012770142853 ITERATION : 40, loss : 0.1217012770142853 ITERATION : 41, loss : 0.1217012770142853 ITERATION : 42, loss : 0.1217012770142853 ITERATION : 43, loss : 0.1217012770142853 ITERATION : 44, loss : 0.1217012770142853 ITERATION : 45, loss : 0.1217012770142853 ITERATION : 46, loss : 0.1217012770142853 ITERATION : 47, loss : 0.1217012770142853 ITERATION : 48, loss : 0.1217012770142853 ITERATION : 49, loss : 0.1217012770142853 ITERATION : 50, loss : 0.1217012770142853 ITERATION : 51, loss : 0.1217012770142853 ITERATION : 52, loss : 0.1217012770142853 ITERATION : 53, loss : 0.1217012770142853 ITERATION : 54, loss : 0.1217012770142853 ITERATION : 55, loss : 0.1217012770142853 ITERATION : 56, loss : 0.1217012770142853 ITERATION : 57, loss : 0.1217012770142853 ITERATION : 58, loss : 0.1217012770142853 ITERATION : 59, loss : 0.1217012770142853 ITERATION : 60, loss : 0.1217012770142853 ITERATION : 61, loss : 0.1217012770142853 ITERATION : 62, loss : 0.1217012770142853 ITERATION : 63, loss : 0.1217012770142853 ITERATION : 64, loss : 0.1217012770142853 ITERATION : 65, loss : 0.1217012770142853 ITERATION : 66, loss : 0.1217012770142853 ITERATION : 67, loss : 0.1217012770142853 ITERATION : 68, loss : 0.1217012770142853 ITERATION : 69, loss : 0.1217012770142853 ITERATION : 70, loss : 0.1217012770142853 ITERATION : 71, loss : 0.1217012770142853 ITERATION : 72, loss : 0.1217012770142853 ITERATION : 73, loss : 0.1217012770142853 ITERATION : 74, loss : 0.1217012770142853 ITERATION : 75, loss : 0.1217012770142853 ITERATION : 76, loss : 0.1217012770142853 ITERATION : 77, loss : 0.1217012770142853 ITERATION : 78, loss : 0.1217012770142853 ITERATION : 79, loss : 0.1217012770142853 ITERATION : 80, loss : 0.1217012770142853 ITERATION : 81, loss : 0.1217012770142853 ITERATION : 82, loss : 0.1217012770142853 ITERATION : 83, loss : 0.1217012770142853 ITERATION : 84, loss : 0.1217012770142853 ITERATION : 85, loss : 0.1217012770142853 ITERATION : 86, loss : 0.1217012770142853 ITERATION : 87, loss : 0.1217012770142853 ITERATION : 88, loss : 0.1217012770142853 ITERATION : 89, loss : 0.1217012770142853 ITERATION : 90, loss : 0.1217012770142853 ITERATION : 91, loss : 0.1217012770142853 ITERATION : 92, loss : 0.1217012770142853 ITERATION : 93, loss : 0.1217012770142853 ITERATION : 94, loss : 0.1217012770142853 ITERATION : 95, loss : 0.1217012770142853 ITERATION : 96, loss : 0.1217012770142853 ITERATION : 97, loss : 0.1217012770142853 ITERATION : 98, loss : 0.1217012770142853 ITERATION : 99, loss : 0.1217012770142853 ITERATION : 100, loss : 0.1217012770142853 
ITERATION : 1, loss : 0.27753406347132686 ITERATION : 2, loss : 0.27753406347132686 ITERATION : 3, loss : 0.27753406347132686 ITERATION : 4, loss : 0.27753406347132686 ITERATION : 5, loss : 0.27753406347132686 ITERATION : 6, loss : 0.27753406347132686 ITERATION : 7, loss : 0.27753406347132686 ITERATION : 8, loss : 0.27753406347132686 ITERATION : 9, loss : 0.27753406347132686 ITERATION : 10, loss : 0.27753406347132686 ITERATION : 11, loss : 0.27753406347132686 ITERATION : 12, loss : 0.27753406347132686 ITERATION : 13, loss : 0.27753406347132686 ITERATION : 14, loss : 0.27753406347132686 ITERATION : 15, loss : 0.27753406347132686 ITERATION : 16, loss : 0.27753406347132686 ITERATION : 17, loss : 0.27753406347132686 ITERATION : 18, loss : 0.27753406347132686 ITERATION : 19, loss : 0.27753406347132686 ITERATION : 20, loss : 0.27753406347132686 ITERATION : 21, loss : 0.27753406347132686 ITERATION : 22, loss : 0.27753406347132686 ITERATION : 23, loss : 0.27753406347132686 ITERATION : 24, loss : 0.27753406347132686 ITERATION : 25, loss : 0.27753406347132686 ITERATION : 26, loss : 0.27753406347132686 ITERATION : 27, loss : 0.27753406347132686 ITERATION : 28, loss : 0.27753406347132686 ITERATION : 29, loss : 0.27753406347132686 ITERATION : 30, loss : 0.27753406347132686 ITERATION : 31, loss : 0.27753406347132686 ITERATION : 32, loss : 0.27753406347132686 ITERATION : 33, loss : 0.27753406347132686 ITERATION : 34, loss : 0.27753406347132686 ITERATION : 35, loss : 0.27753406347132686 ITERATION : 36, loss : 0.27753406347132686 ITERATION : 37, loss : 0.27753406347132686 ITERATION : 38, loss : 0.27753406347132686 ITERATION : 39, loss : 0.27753406347132686 ITERATION : 40, loss : 0.27753406347132686 ITERATION : 41, loss : 0.27753406347132686 ITERATION : 42, loss : 0.27753406347132686 ITERATION : 43, loss : 0.27753406347132686 ITERATION : 44, loss : 0.27753406347132686 ITERATION : 45, loss : 0.27753406347132686 ITERATION : 46, loss : 0.27753406347132686 ITERATION : 47, loss : 0.27753406347132686 ITERATION : 48, loss : 0.27753406347132686 ITERATION : 49, loss : 0.27753406347132686 ITERATION : 50, loss : 0.27753406347132686 ITERATION : 51, loss : 0.27753406347132686 ITERATION : 52, loss : 0.27753406347132686 ITERATION : 53, loss : 0.27753406347132686 ITERATION : 54, loss : 0.27753406347132686 ITERATION : 55, loss : 0.27753406347132686 ITERATION : 56, loss : 0.27753406347132686 ITERATION : 57, loss : 0.27753406347132686 ITERATION : 58, loss : 0.27753406347132686 ITERATION : 59, loss : 0.27753406347132686 ITERATION : 60, loss : 0.27753406347132686 ITERATION : 61, loss : 0.27753406347132686 ITERATION : 62, loss : 0.27753406347132686 ITERATION : 63, loss : 0.27753406347132686 ITERATION : 64, loss : 0.27753406347132686 ITERATION : 65, loss : 0.27753406347132686 ITERATION : 66, loss : 0.27753406347132686 ITERATION : 67, loss : 0.27753406347132686 ITERATION : 68, loss : 0.27753406347132686 ITERATION : 69, loss : 0.27753406347132686 ITERATION : 70, loss : 0.27753406347132686 ITERATION : 71, loss : 0.27753406347132686 ITERATION : 72, loss : 0.27753406347132686 ITERATION : 73, loss : 0.27753406347132686 ITERATION : 74, loss : 0.27753406347132686 ITERATION : 75, loss : 0.27753406347132686 ITERATION : 76, loss : 0.27753406347132686 ITERATION : 77, loss : 0.27753406347132686 ITERATION : 78, loss : 0.27753406347132686 ITERATION : 79, loss : 0.27753406347132686 ITERATION : 80, loss : 0.27753406347132686 ITERATION : 81, loss : 0.27753406347132686 ITERATION : 82, loss : 0.27753406347132686 ITERATION : 83, loss : 0.27753406347132686 ITERATION : 84, loss : 0.27753406347132686 ITERATION : 85, loss : 0.27753406347132686 ITERATION : 86, loss : 0.27753406347132686 ITERATION : 87, loss : 0.27753406347132686 ITERATION : 88, loss : 0.27753406347132686 ITERATION : 89, loss : 0.27753406347132686 ITERATION : 90, loss : 0.27753406347132686 ITERATION : 91, loss : 0.27753406347132686 ITERATION : 92, loss : 0.27753406347132686 ITERATION : 93, loss : 0.27753406347132686 ITERATION : 94, loss : 0.27753406347132686 ITERATION : 95, loss : 0.27753406347132686 ITERATION : 96, loss : 0.27753406347132686 ITERATION : 97, loss : 0.27753406347132686 ITERATION : 98, loss : 0.27753406347132686 ITERATION : 99, loss : 0.27753406347132686 ITERATION : 100, loss : 0.27753406347132686 
ITERATION : 1, loss : 0.2589562279178666 ITERATION : 2, loss : 0.2589562279178666 ITERATION : 3, loss : 0.2589562279178666 ITERATION : 4, loss : 0.2589562279178666 ITERATION : 5, loss : 0.2589562279178666 ITERATION : 6, loss : 0.2589562279178666 ITERATION : 7, loss : 0.2589562279178666 ITERATION : 8, loss : 0.2589562279178666 ITERATION : 9, loss : 0.2589562279178666 ITERATION : 10, loss : 0.2589562279178666 ITERATION : 11, loss : 0.2589562279178666 ITERATION : 12, loss : 0.2589562279178666 ITERATION : 13, loss : 0.2589562279178666 ITERATION : 14, loss : 0.2589562279178666 ITERATION : 15, loss : 0.2589562279178666 ITERATION : 16, loss : 0.2589562279178666 ITERATION : 17, loss : 0.2589562279178666 ITERATION : 18, loss : 0.2589562279178666 ITERATION : 19, loss : 0.2589562279178666 ITERATION : 20, loss : 0.2589562279178666 ITERATION : 21, loss : 0.2589562279178666 ITERATION : 22, loss : 0.2589562279178666 ITERATION : 23, loss : 0.2589562279178666 ITERATION : 24, loss : 0.2589562279178666 ITERATION : 25, loss : 0.2589562279178666 ITERATION : 26, loss : 0.2589562279178666 ITERATION : 27, loss : 0.2589562279178666 ITERATION : 28, loss : 0.2589562279178666 ITERATION : 29, loss : 0.2589562279178666 ITERATION : 30, loss : 0.2589562279178666 ITERATION : 31, loss : 0.2589562279178666 ITERATION : 32, loss : 0.2589562279178666 ITERATION : 33, loss : 0.2589562279178666 ITERATION : 34, loss : 0.2589562279178666 ITERATION : 35, loss : 0.2589562279178666 ITERATION : 36, loss : 0.2589562279178666 ITERATION : 37, loss : 0.2589562279178666 ITERATION : 38, loss : 0.2589562279178666 ITERATION : 39, loss : 0.2589562279178666 ITERATION : 40, loss : 0.2589562279178666 ITERATION : 41, loss : 0.2589562279178666 ITERATION : 42, loss : 0.2589562279178666 ITERATION : 43, loss : 0.2589562279178666 ITERATION : 44, loss : 0.2589562279178666 ITERATION : 45, loss : 0.2589562279178666 ITERATION : 46, loss : 0.2589562279178666 ITERATION : 47, loss : 0.2589562279178666 ITERATION : 48, loss : 0.2589562279178666 ITERATION : 49, loss : 0.2589562279178666 ITERATION : 50, loss : 0.2589562279178666 ITERATION : 51, loss : 0.2589562279178666 ITERATION : 52, loss : 0.2589562279178666 ITERATION : 53, loss : 0.2589562279178666 ITERATION : 54, loss : 0.2589562279178666 ITERATION : 55, loss : 0.2589562279178666 ITERATION : 56, loss : 0.2589562279178666 ITERATION : 57, loss : 0.2589562279178666 ITERATION : 58, loss : 0.2589562279178666 ITERATION : 59, loss : 0.2589562279178666 ITERATION : 60, loss : 0.2589562279178666 ITERATION : 61, loss : 0.2589562279178666 ITERATION : 62, loss : 0.2589562279178666 ITERATION : 63, loss : 0.2589562279178666 ITERATION : 64, loss : 0.2589562279178666 ITERATION : 65, loss : 0.2589562279178666 ITERATION : 66, loss : 0.2589562279178666 ITERATION : 67, loss : 0.2589562279178666 ITERATION : 68, loss : 0.2589562279178666 ITERATION : 69, loss : 0.2589562279178666 ITERATION : 70, loss : 0.2589562279178666 ITERATION : 71, loss : 0.2589562279178666 ITERATION : 72, loss : 0.2589562279178666 ITERATION : 73, loss : 0.2589562279178666 ITERATION : 74, loss : 0.2589562279178666 ITERATION : 75, loss : 0.2589562279178666 ITERATION : 76, loss : 0.2589562279178666 ITERATION : 77, loss : 0.2589562279178666 ITERATION : 78, loss : 0.2589562279178666 ITERATION : 79, loss : 0.2589562279178666 ITERATION : 80, loss : 0.2589562279178666 ITERATION : 81, loss : 0.2589562279178666 ITERATION : 82, loss : 0.2589562279178666 ITERATION : 83, loss : 0.2589562279178666 ITERATION : 84, loss : 0.2589562279178666 ITERATION : 85, loss : 0.2589562279178666 ITERATION : 86, loss : 0.2589562279178666 ITERATION : 87, loss : 0.2589562279178666 ITERATION : 88, loss : 0.2589562279178666 ITERATION : 89, loss : 0.2589562279178666 ITERATION : 90, loss : 0.2589562279178666 ITERATION : 91, loss : 0.2589562279178666 ITERATION : 92, loss : 0.2589562279178666 ITERATION : 93, loss : 0.2589562279178666 ITERATION : 94, loss : 0.2589562279178666 ITERATION : 95, loss : 0.2589562279178666 ITERATION : 96, loss : 0.2589562279178666 ITERATION : 97, loss : 0.2589562279178666 ITERATION : 98, loss : 0.2589562279178666 ITERATION : 99, loss : 0.2589562279178666 ITERATION : 100, loss : 0.2589562279178666 
ITERATION : 1, loss : 0.20568280772590275 ITERATION : 2, loss : 0.20568280772590275 ITERATION : 3, loss : 0.20568280772590275 ITERATION : 4, loss : 0.20568280772590275 ITERATION : 5, loss : 0.20568280772590275 ITERATION : 6, loss : 0.20568280772590275 ITERATION : 7, loss : 0.20568280772590275 ITERATION : 8, loss : 0.20568280772590275 ITERATION : 9, loss : 0.20568280772590275 ITERATION : 10, loss : 0.20568280772590275 ITERATION : 11, loss : 0.20568280772590275 ITERATION : 12, loss : 0.20568280772590275 ITERATION : 13, loss : 0.20568280772590275 ITERATION : 14, loss : 0.20568280772590275 ITERATION : 15, loss : 0.20568280772590275 ITERATION : 16, loss : 0.20568280772590275 ITERATION : 17, loss : 0.20568280772590275 ITERATION : 18, loss : 0.20568280772590275 ITERATION : 19, loss : 0.20568280772590275 ITERATION : 20, loss : 0.20568280772590275 ITERATION : 21, loss : 0.20568280772590275 ITERATION : 22, loss : 0.20568280772590275 ITERATION : 23, loss : 0.20568280772590275 ITERATION : 24, loss : 0.20568280772590275 ITERATION : 25, loss : 0.20568280772590275 ITERATION : 26, loss : 0.20568280772590275 ITERATION : 27, loss : 0.20568280772590275 ITERATION : 28, loss : 0.20568280772590275 ITERATION : 29, loss : 0.20568280772590275 ITERATION : 30, loss : 0.20568280772590275 ITERATION : 31, loss : 0.20568280772590275 ITERATION : 32, loss : 0.20568280772590275 ITERATION : 33, loss : 0.20568280772590275 ITERATION : 34, loss : 0.20568280772590275 ITERATION : 35, loss : 0.20568280772590275 ITERATION : 36, loss : 0.20568280772590275 ITERATION : 37, loss : 0.20568280772590275 ITERATION : 38, loss : 0.20568280772590275 ITERATION : 39, loss : 0.20568280772590275 ITERATION : 40, loss : 0.20568280772590275 ITERATION : 41, loss : 0.20568280772590275 ITERATION : 42, loss : 0.20568280772590275 ITERATION : 43, loss : 0.20568280772590275 ITERATION : 44, loss : 0.20568280772590275 ITERATION : 45, loss : 0.20568280772590275 ITERATION : 46, loss : 0.20568280772590275 ITERATION : 47, loss : 0.20568280772590275 ITERATION : 48, loss : 0.20568280772590275 ITERATION : 49, loss : 0.20568280772590275 ITERATION : 50, loss : 0.20568280772590275 ITERATION : 51, loss : 0.20568280772590275 ITERATION : 52, loss : 0.20568280772590275 ITERATION : 53, loss : 0.20568280772590275 ITERATION : 54, loss : 0.20568280772590275 ITERATION : 55, loss : 0.20568280772590275 ITERATION : 56, loss : 0.20568280772590275 ITERATION : 57, loss : 0.20568280772590275 ITERATION : 58, loss : 0.20568280772590275 ITERATION : 59, loss : 0.20568280772590275 ITERATION : 60, loss : 0.20568280772590275 ITERATION : 61, loss : 0.20568280772590275 ITERATION : 62, loss : 0.20568280772590275 ITERATION : 63, loss : 0.20568280772590275 ITERATION : 64, loss : 0.20568280772590275 ITERATION : 65, loss : 0.20568280772590275 ITERATION : 66, loss : 0.20568280772590275 ITERATION : 67, loss : 0.20568280772590275 ITERATION : 68, loss : 0.20568280772590275 ITERATION : 69, loss : 0.20568280772590275 ITERATION : 70, loss : 0.20568280772590275 ITERATION : 71, loss : 0.20568280772590275 ITERATION : 72, loss : 0.20568280772590275 ITERATION : 73, loss : 0.20568280772590275 ITERATION : 74, loss : 0.20568280772590275 ITERATION : 75, loss : 0.20568280772590275 ITERATION : 76, loss : 0.20568280772590275 ITERATION : 77, loss : 0.20568280772590275 ITERATION : 78, loss : 0.20568280772590275 ITERATION : 79, loss : 0.20568280772590275 ITERATION : 80, loss : 0.20568280772590275 ITERATION : 81, loss : 0.20568280772590275 ITERATION : 82, loss : 0.20568280772590275 ITERATION : 83, loss : 0.20568280772590275 ITERATION : 84, loss : 0.20568280772590275 ITERATION : 85, loss : 0.20568280772590275 ITERATION : 86, loss : 0.20568280772590275 ITERATION : 87, loss : 0.20568280772590275 ITERATION : 88, loss : 0.20568280772590275 ITERATION : 89, loss : 0.20568280772590275 ITERATION : 90, loss : 0.20568280772590275 ITERATION : 91, loss : 0.20568280772590275 ITERATION : 92, loss : 0.20568280772590275 ITERATION : 93, loss : 0.20568280772590275 ITERATION : 94, loss : 0.20568280772590275 ITERATION : 95, loss : 0.20568280772590275 ITERATION : 96, loss : 0.20568280772590275 ITERATION : 97, loss : 0.20568280772590275 ITERATION : 98, loss : 0.20568280772590275 ITERATION : 99, loss : 0.20568280772590275 ITERATION : 100, loss : 0.20568280772590275 
ITERATION : 1, loss : 0.27685364833059334 ITERATION : 2, loss : 0.27685364833059334 ITERATION : 3, loss : 0.27685364833059334 ITERATION : 4, loss : 0.27685364833059334 ITERATION : 5, loss : 0.27685364833059334 ITERATION : 6, loss : 0.27685364833059334 ITERATION : 7, loss : 0.27685364833059334 ITERATION : 8, loss : 0.27685364833059334 ITERATION : 9, loss : 0.27685364833059334 ITERATION : 10, loss : 0.27685364833059334 ITERATION : 11, loss : 0.27685364833059334 ITERATION : 12, loss : 0.27685364833059334 ITERATION : 13, loss : 0.27685364833059334 ITERATION : 14, loss : 0.27685364833059334 ITERATION : 15, loss : 0.27685364833059334 ITERATION : 16, loss : 0.27685364833059334 ITERATION : 17, loss : 0.27685364833059334 ITERATION : 18, loss : 0.27685364833059334 ITERATION : 19, loss : 0.27685364833059334 ITERATION : 20, loss : 0.27685364833059334 ITERATION : 21, loss : 0.27685364833059334 ITERATION : 22, loss : 0.27685364833059334 ITERATION : 23, loss : 0.27685364833059334 ITERATION : 24, loss : 0.27685364833059334 ITERATION : 25, loss : 0.27685364833059334 ITERATION : 26, loss : 0.27685364833059334 ITERATION : 27, loss : 0.27685364833059334 ITERATION : 28, loss : 0.27685364833059334 ITERATION : 29, loss : 0.27685364833059334 ITERATION : 30, loss : 0.27685364833059334 ITERATION : 31, loss : 0.27685364833059334 ITERATION : 32, loss : 0.27685364833059334 ITERATION : 33, loss : 0.27685364833059334 ITERATION : 34, loss : 0.27685364833059334 ITERATION : 35, loss : 0.27685364833059334 ITERATION : 36, loss : 0.27685364833059334 ITERATION : 37, loss : 0.27685364833059334 ITERATION : 38, loss : 0.27685364833059334 ITERATION : 39, loss : 0.27685364833059334 ITERATION : 40, loss : 0.27685364833059334 ITERATION : 41, loss : 0.27685364833059334 ITERATION : 42, loss : 0.27685364833059334 ITERATION : 43, loss : 0.27685364833059334 ITERATION : 44, loss : 0.27685364833059334 ITERATION : 45, loss : 0.27685364833059334 ITERATION : 46, loss : 0.27685364833059334 ITERATION : 47, loss : 0.27685364833059334 ITERATION : 48, loss : 0.27685364833059334 ITERATION : 49, loss : 0.27685364833059334 ITERATION : 50, loss : 0.27685364833059334 ITERATION : 51, loss : 0.27685364833059334 ITERATION : 52, loss : 0.27685364833059334 ITERATION : 53, loss : 0.27685364833059334 ITERATION : 54, loss : 0.27685364833059334 ITERATION : 55, loss : 0.27685364833059334 ITERATION : 56, loss : 0.27685364833059334 ITERATION : 57, loss : 0.27685364833059334 ITERATION : 58, loss : 0.27685364833059334 ITERATION : 59, loss : 0.27685364833059334 ITERATION : 60, loss : 0.27685364833059334 ITERATION : 61, loss : 0.27685364833059334 ITERATION : 62, loss : 0.27685364833059334 ITERATION : 63, loss : 0.27685364833059334 ITERATION : 64, loss : 0.27685364833059334 ITERATION : 65, loss : 0.27685364833059334 ITERATION : 66, loss : 0.27685364833059334 ITERATION : 67, loss : 0.27685364833059334 ITERATION : 68, loss : 0.27685364833059334 ITERATION : 69, loss : 0.27685364833059334 ITERATION : 70, loss : 0.27685364833059334 ITERATION : 71, loss : 0.27685364833059334 ITERATION : 72, loss : 0.27685364833059334 ITERATION : 73, loss : 0.27685364833059334 ITERATION : 74, loss : 0.27685364833059334 ITERATION : 75, loss : 0.27685364833059334 ITERATION : 76, loss : 0.27685364833059334 ITERATION : 77, loss : 0.27685364833059334 ITERATION : 78, loss : 0.27685364833059334 ITERATION : 79, loss : 0.27685364833059334 ITERATION : 80, loss : 0.27685364833059334 ITERATION : 81, loss : 0.27685364833059334 ITERATION : 82, loss : 0.27685364833059334 ITERATION : 83, loss : 0.27685364833059334 ITERATION : 84, loss : 0.27685364833059334 ITERATION : 85, loss : 0.27685364833059334 ITERATION : 86, loss : 0.27685364833059334 ITERATION : 87, loss : 0.27685364833059334 ITERATION : 88, loss : 0.27685364833059334 ITERATION : 89, loss : 0.27685364833059334 ITERATION : 90, loss : 0.27685364833059334 ITERATION : 91, loss : 0.27685364833059334 ITERATION : 92, loss : 0.27685364833059334 ITERATION : 93, loss : 0.27685364833059334 ITERATION : 94, loss : 0.27685364833059334 ITERATION : 95, loss : 0.27685364833059334 ITERATION : 96, loss : 0.27685364833059334 ITERATION : 97, loss : 0.27685364833059334 ITERATION : 98, loss : 0.27685364833059334 ITERATION : 99, loss : 0.27685364833059334 ITERATION : 100, loss : 0.27685364833059334 
gradient norm in None layer : 1.3812836668397954
gradient norm in None layer : 0.04056934572800317
gradient norm in None layer : 0.04154484771086136
gradient norm in None layer : 0.6321211868078178
gradient norm in None layer : 0.032973076450209256
gradient norm in None layer : 0.03842821370957484
gradient norm in None layer : 0.1719092810684799
gradient norm in None layer : 0.006452364903663939
gradient norm in None layer : 0.005917203107661401
gradient norm in None layer : 0.14008470837897394
gradient norm in None layer : 0.006706238884105801
gradient norm in None layer : 0.005998517767532375
gradient norm in None layer : 0.05267804177726641
gradient norm in None layer : 0.001431083566569102
gradient norm in None layer : 0.0010573630902707017
gradient norm in None layer : 0.04743866307389296
gradient norm in None layer : 0.0015820289393353633
gradient norm in None layer : 0.0013159624447353776
gradient norm in None layer : 0.06008712311654386
gradient norm in None layer : 0.0006999579953368623
gradient norm in None layer : 0.15009238936454322
gradient norm in None layer : 0.00840433586764991
gradient norm in None layer : 0.00590745536134383
gradient norm in None layer : 0.16600153681230587
gradient norm in None layer : 0.01036787840795933
gradient norm in None layer : 0.009896235218669428
gradient norm in None layer : 0.2383407956088991
gradient norm in None layer : 0.0026575602819750546
gradient norm in None layer : 0.5289962296257981
gradient norm in None layer : 0.04634516603840963
gradient norm in None layer : 0.033927879155090004
gradient norm in None layer : 0.6662456097573805
gradient norm in None layer : 0.12263836418708753
gradient norm in None layer : 0.1944139697777271
gradient norm in None layer : 0.08658072272470839
gradient norm in None layer : 0.031111996527398534
Total gradient norm: 1.8074745846260272
invariance loss : 283.578669865092, avg_den : 0.0, density loss : 0.1, mse loss : 0.2935335957091456, solver time : 0.8207528591156006 sec , total loss : 0.6771122655742376, running loss : 1.3106691642230297
Epoch 0/10 , batch 4/12500 
ITERATION : 1, loss : 0.4050662827426874 ITERATION : 2, loss : 0.4050662827426874 ITERATION : 3, loss : 0.4050662827426874 ITERATION : 4, loss : 0.4050662827426874 ITERATION : 5, loss : 0.4050662827426874 ITERATION : 6, loss : 0.4050662827426874 ITERATION : 7, loss : 0.4050662827426874 ITERATION : 8, loss : 0.4050662827426874 ITERATION : 9, loss : 0.4050662827426874 ITERATION : 10, loss : 0.4050662827426874 ITERATION : 11, loss : 0.4050662827426874 ITERATION : 12, loss : 0.4050662827426874 ITERATION : 13, loss : 0.4050662827426874 ITERATION : 14, loss : 0.4050662827426874 ITERATION : 15, loss : 0.4050662827426874 ITERATION : 16, loss : 0.4050662827426874 ITERATION : 17, loss : 0.4050662827426874 ITERATION : 18, loss : 0.4050662827426874 ITERATION : 19, loss : 0.4050662827426874 ITERATION : 20, loss : 0.4050662827426874 ITERATION : 21, loss : 0.4050662827426874 ITERATION : 22, loss : 0.4050662827426874 ITERATION : 23, loss : 0.4050662827426874 ITERATION : 24, loss : 0.4050662827426874 ITERATION : 25, loss : 0.4050662827426874 ITERATION : 26, loss : 0.4050662827426874 ITERATION : 27, loss : 0.4050662827426874 ITERATION : 28, loss : 0.4050662827426874 ITERATION : 29, loss : 0.4050662827426874 ITERATION : 30, loss : 0.4050662827426874 ITERATION : 31, loss : 0.4050662827426874 ITERATION : 32, loss : 0.4050662827426874 ITERATION : 33, loss : 0.4050662827426874 ITERATION : 34, loss : 0.4050662827426874 ITERATION : 35, loss : 0.4050662827426874 ITERATION : 36, loss : 0.4050662827426874 ITERATION : 37, loss : 0.4050662827426874 ITERATION : 38, loss : 0.4050662827426874 ITERATION : 39, loss : 0.4050662827426874 ITERATION : 40, loss : 0.4050662827426874 ITERATION : 41, loss : 0.4050662827426874 ITERATION : 42, loss : 0.4050662827426874 ITERATION : 43, loss : 0.4050662827426874 ITERATION : 44, loss : 0.4050662827426874 ITERATION : 45, loss : 0.4050662827426874 ITERATION : 46, loss : 0.4050662827426874 ITERATION : 47, loss : 0.4050662827426874 ITERATION : 48, loss : 0.4050662827426874 ITERATION : 49, loss : 0.4050662827426874 ITERATION : 50, loss : 0.4050662827426874 ITERATION : 51, loss : 0.4050662827426874 ITERATION : 52, loss : 0.4050662827426874 ITERATION : 53, loss : 0.4050662827426874 ITERATION : 54, loss : 0.4050662827426874 ITERATION : 55, loss : 0.4050662827426874 ITERATION : 56, loss : 0.4050662827426874 ITERATION : 57, loss : 0.4050662827426874 ITERATION : 58, loss : 0.4050662827426874 ITERATION : 59, loss : 0.4050662827426874 ITERATION : 60, loss : 0.4050662827426874 ITERATION : 61, loss : 0.4050662827426874 ITERATION : 62, loss : 0.4050662827426874 ITERATION : 63, loss : 0.4050662827426874 ITERATION : 64, loss : 0.4050662827426874 ITERATION : 65, loss : 0.4050662827426874 ITERATION : 66, loss : 0.4050662827426874 ITERATION : 67, loss : 0.4050662827426874 ITERATION : 68, loss : 0.4050662827426874 ITERATION : 69, loss : 0.4050662827426874 ITERATION : 70, loss : 0.4050662827426874 ITERATION : 71, loss : 0.4050662827426874 ITERATION : 72, loss : 0.4050662827426874 ITERATION : 73, loss : 0.4050662827426874 ITERATION : 74, loss : 0.4050662827426874 ITERATION : 75, loss : 0.4050662827426874 ITERATION : 76, loss : 0.4050662827426874 ITERATION : 77, loss : 0.4050662827426874 ITERATION : 78, loss : 0.4050662827426874 ITERATION : 79, loss : 0.4050662827426874 ITERATION : 80, loss : 0.4050662827426874 ITERATION : 81, loss : 0.4050662827426874 ITERATION : 82, loss : 0.4050662827426874 ITERATION : 83, loss : 0.4050662827426874 ITERATION : 84, loss : 0.4050662827426874 ITERATION : 85, loss : 0.4050662827426874 ITERATION : 86, loss : 0.4050662827426874 ITERATION : 87, loss : 0.4050662827426874 ITERATION : 88, loss : 0.4050662827426874 ITERATION : 89, loss : 0.4050662827426874 ITERATION : 90, loss : 0.4050662827426874 ITERATION : 91, loss : 0.4050662827426874 ITERATION : 92, loss : 0.4050662827426874 ITERATION : 93, loss : 0.4050662827426874 ITERATION : 94, loss : 0.4050662827426874 ITERATION : 95, loss : 0.4050662827426874 ITERATION : 96, loss : 0.4050662827426874 ITERATION : 97, loss : 0.4050662827426874 ITERATION : 98, loss : 0.4050662827426874 ITERATION : 99, loss : 0.4050662827426874 ITERATION : 100, loss : 0.4050662827426874 
ITERATION : 1, loss : 0.17539970546270986 ITERATION : 2, loss : 0.17539970546270986 ITERATION : 3, loss : 0.17539970546270986 ITERATION : 4, loss : 0.17539970546270986 ITERATION : 5, loss : 0.17539970546270986 ITERATION : 6, loss : 0.17539970546270986 ITERATION : 7, loss : 0.17539970546270986 ITERATION : 8, loss : 0.17539970546270986 ITERATION : 9, loss : 0.17539970546270986 ITERATION : 10, loss : 0.17539970546270986 ITERATION : 11, loss : 0.17539970546270986 ITERATION : 12, loss : 0.17539970546270986 ITERATION : 13, loss : 0.17539970546270986 ITERATION : 14, loss : 0.17539970546270986 ITERATION : 15, loss : 0.17539970546270986 ITERATION : 16, loss : 0.17539970546270986 ITERATION : 17, loss : 0.17539970546270986 ITERATION : 18, loss : 0.17539970546270986 ITERATION : 19, loss : 0.17539970546270986 ITERATION : 20, loss : 0.17539970546270986 ITERATION : 21, loss : 0.17539970546270986 ITERATION : 22, loss : 0.17539970546270986 ITERATION : 23, loss : 0.17539970546270986 ITERATION : 24, loss : 0.17539970546270986 ITERATION : 25, loss : 0.17539970546270986 ITERATION : 26, loss : 0.17539970546270986 ITERATION : 27, loss : 0.17539970546270986 ITERATION : 28, loss : 0.17539970546270986 ITERATION : 29, loss : 0.17539970546270986 ITERATION : 30, loss : 0.17539970546270986 ITERATION : 31, loss : 0.17539970546270986 ITERATION : 32, loss : 0.17539970546270986 ITERATION : 33, loss : 0.17539970546270986 ITERATION : 34, loss : 0.17539970546270986 ITERATION : 35, loss : 0.17539970546270986 ITERATION : 36, loss : 0.17539970546270986 ITERATION : 37, loss : 0.17539970546270986 ITERATION : 38, loss : 0.17539970546270986 ITERATION : 39, loss : 0.17539970546270986 ITERATION : 40, loss : 0.17539970546270986 ITERATION : 41, loss : 0.17539970546270986 ITERATION : 42, loss : 0.17539970546270986 ITERATION : 43, loss : 0.17539970546270986 ITERATION : 44, loss : 0.17539970546270986 ITERATION : 45, loss : 0.17539970546270986 ITERATION : 46, loss : 0.17539970546270986 ITERATION : 47, loss : 0.17539970546270986 ITERATION : 48, loss : 0.17539970546270986 ITERATION : 49, loss : 0.17539970546270986 ITERATION : 50, loss : 0.17539970546270986 ITERATION : 51, loss : 0.17539970546270986 ITERATION : 52, loss : 0.17539970546270986 ITERATION : 53, loss : 0.17539970546270986 ITERATION : 54, loss : 0.17539970546270986 ITERATION : 55, loss : 0.17539970546270986 ITERATION : 56, loss : 0.17539970546270986 ITERATION : 57, loss : 0.17539970546270986 ITERATION : 58, loss : 0.17539970546270986 ITERATION : 59, loss : 0.17539970546270986 ITERATION : 60, loss : 0.17539970546270986 ITERATION : 61, loss : 0.17539970546270986 ITERATION : 62, loss : 0.17539970546270986 ITERATION : 63, loss : 0.17539970546270986 ITERATION : 64, loss : 0.17539970546270986 ITERATION : 65, loss : 0.17539970546270986 ITERATION : 66, loss : 0.17539970546270986 ITERATION : 67, loss : 0.17539970546270986 ITERATION : 68, loss : 0.17539970546270986 ITERATION : 69, loss : 0.17539970546270986 ITERATION : 70, loss : 0.17539970546270986 ITERATION : 71, loss : 0.17539970546270986 ITERATION : 72, loss : 0.17539970546270986 ITERATION : 73, loss : 0.17539970546270986 ITERATION : 74, loss : 0.17539970546270986 ITERATION : 75, loss : 0.17539970546270986 ITERATION : 76, loss : 0.17539970546270986 ITERATION : 77, loss : 0.17539970546270986 ITERATION : 78, loss : 0.17539970546270986 ITERATION : 79, loss : 0.17539970546270986 ITERATION : 80, loss : 0.17539970546270986 ITERATION : 81, loss : 0.17539970546270986 ITERATION : 82, loss : 0.17539970546270986 ITERATION : 83, loss : 0.17539970546270986 ITERATION : 84, loss : 0.17539970546270986 ITERATION : 85, loss : 0.17539970546270986 ITERATION : 86, loss : 0.17539970546270986 ITERATION : 87, loss : 0.17539970546270986 ITERATION : 88, loss : 0.17539970546270986 ITERATION : 89, loss : 0.17539970546270986 ITERATION : 90, loss : 0.17539970546270986 ITERATION : 91, loss : 0.17539970546270986 ITERATION : 92, loss : 0.17539970546270986 ITERATION : 93, loss : 0.17539970546270986 ITERATION : 94, loss : 0.17539970546270986 ITERATION : 95, loss : 0.17539970546270986 ITERATION : 96, loss : 0.17539970546270986 ITERATION : 97, loss : 0.17539970546270986 ITERATION : 98, loss : 0.17539970546270986 ITERATION : 99, loss : 0.17539970546270986 ITERATION : 100, loss : 0.17539970546270986 
ITERATION : 1, loss : 0.4034758419296914 ITERATION : 2, loss : 0.4034758419296914 ITERATION : 3, loss : 0.4034758419296914 ITERATION : 4, loss : 0.4034758419296914 ITERATION : 5, loss : 0.4034758419296914 ITERATION : 6, loss : 0.4034758419296914 ITERATION : 7, loss : 0.4034758419296914 ITERATION : 8, loss : 0.4034758419296914 ITERATION : 9, loss : 0.4034758419296914 ITERATION : 10, loss : 0.4034758419296914 ITERATION : 11, loss : 0.4034758419296914 ITERATION : 12, loss : 0.4034758419296914 ITERATION : 13, loss : 0.4034758419296914 ITERATION : 14, loss : 0.4034758419296914 ITERATION : 15, loss : 0.4034758419296914 ITERATION : 16, loss : 0.4034758419296914 ITERATION : 17, loss : 0.4034758419296914 ITERATION : 18, loss : 0.4034758419296914 ITERATION : 19, loss : 0.4034758419296914 ITERATION : 20, loss : 0.4034758419296914 ITERATION : 21, loss : 0.4034758419296914 ITERATION : 22, loss : 0.4034758419296914 ITERATION : 23, loss : 0.4034758419296914 ITERATION : 24, loss : 0.4034758419296914 ITERATION : 25, loss : 0.4034758419296914 ITERATION : 26, loss : 0.4034758419296914 ITERATION : 27, loss : 0.4034758419296914 ITERATION : 28, loss : 0.4034758419296914 ITERATION : 29, loss : 0.4034758419296914 ITERATION : 30, loss : 0.4034758419296914 ITERATION : 31, loss : 0.4034758419296914 ITERATION : 32, loss : 0.4034758419296914 ITERATION : 33, loss : 0.4034758419296914 ITERATION : 34, loss : 0.4034758419296914 ITERATION : 35, loss : 0.4034758419296914 ITERATION : 36, loss : 0.4034758419296914 ITERATION : 37, loss : 0.4034758419296914 ITERATION : 38, loss : 0.4034758419296914 ITERATION : 39, loss : 0.4034758419296914 ITERATION : 40, loss : 0.4034758419296914 ITERATION : 41, loss : 0.4034758419296914 ITERATION : 42, loss : 0.4034758419296914 ITERATION : 43, loss : 0.4034758419296914 ITERATION : 44, loss : 0.4034758419296914 ITERATION : 45, loss : 0.4034758419296914 ITERATION : 46, loss : 0.4034758419296914 ITERATION : 47, loss : 0.4034758419296914 ITERATION : 48, loss : 0.4034758419296914 ITERATION : 49, loss : 0.4034758419296914 ITERATION : 50, loss : 0.4034758419296914 ITERATION : 51, loss : 0.4034758419296914 ITERATION : 52, loss : 0.4034758419296914 ITERATION : 53, loss : 0.4034758419296914 ITERATION : 54, loss : 0.4034758419296914 ITERATION : 55, loss : 0.4034758419296914 ITERATION : 56, loss : 0.4034758419296914 ITERATION : 57, loss : 0.4034758419296914 ITERATION : 58, loss : 0.4034758419296914 ITERATION : 59, loss : 0.4034758419296914 ITERATION : 60, loss : 0.4034758419296914 ITERATION : 61, loss : 0.4034758419296914 ITERATION : 62, loss : 0.4034758419296914 ITERATION : 63, loss : 0.4034758419296914 ITERATION : 64, loss : 0.4034758419296914 ITERATION : 65, loss : 0.4034758419296914 ITERATION : 66, loss : 0.4034758419296914 ITERATION : 67, loss : 0.4034758419296914 ITERATION : 68, loss : 0.4034758419296914 ITERATION : 69, loss : 0.4034758419296914 ITERATION : 70, loss : 0.4034758419296914 ITERATION : 71, loss : 0.4034758419296914 ITERATION : 72, loss : 0.4034758419296914 ITERATION : 73, loss : 0.4034758419296914 ITERATION : 74, loss : 0.4034758419296914 ITERATION : 75, loss : 0.4034758419296914 ITERATION : 76, loss : 0.4034758419296914 ITERATION : 77, loss : 0.4034758419296914 ITERATION : 78, loss : 0.4034758419296914 ITERATION : 79, loss : 0.4034758419296914 ITERATION : 80, loss : 0.4034758419296914 ITERATION : 81, loss : 0.4034758419296914 ITERATION : 82, loss : 0.4034758419296914 ITERATION : 83, loss : 0.4034758419296914 ITERATION : 84, loss : 0.4034758419296914 ITERATION : 85, loss : 0.4034758419296914 ITERATION : 86, loss : 0.4034758419296914 ITERATION : 87, loss : 0.4034758419296914 ITERATION : 88, loss : 0.4034758419296914 ITERATION : 89, loss : 0.4034758419296914 ITERATION : 90, loss : 0.4034758419296914 ITERATION : 91, loss : 0.4034758419296914 ITERATION : 92, loss : 0.4034758419296914 ITERATION : 93, loss : 0.4034758419296914 ITERATION : 94, loss : 0.4034758419296914 ITERATION : 95, loss : 0.4034758419296914 ITERATION : 96, loss : 0.4034758419296914 ITERATION : 97, loss : 0.4034758419296914 ITERATION : 98, loss : 0.4034758419296914 ITERATION : 99, loss : 0.4034758419296914 ITERATION : 100, loss : 0.4034758419296914 
ITERATION : 1, loss : 0.2809296799519505 ITERATION : 2, loss : 0.2809296799519505 ITERATION : 3, loss : 0.2809296799519505 ITERATION : 4, loss : 0.2809296799519505 ITERATION : 5, loss : 0.2809296799519505 ITERATION : 6, loss : 0.2809296799519505 ITERATION : 7, loss : 0.2809296799519505 ITERATION : 8, loss : 0.2809296799519505 ITERATION : 9, loss : 0.2809296799519505 ITERATION : 10, loss : 0.2809296799519505 ITERATION : 11, loss : 0.2809296799519505 ITERATION : 12, loss : 0.2809296799519505 ITERATION : 13, loss : 0.2809296799519505 ITERATION : 14, loss : 0.2809296799519505 ITERATION : 15, loss : 0.2809296799519505 ITERATION : 16, loss : 0.2809296799519505 ITERATION : 17, loss : 0.2809296799519505 ITERATION : 18, loss : 0.2809296799519505 ITERATION : 19, loss : 0.2809296799519505 ITERATION : 20, loss : 0.2809296799519505 ITERATION : 21, loss : 0.2809296799519505 ITERATION : 22, loss : 0.2809296799519505 ITERATION : 23, loss : 0.2809296799519505 ITERATION : 24, loss : 0.2809296799519505 ITERATION : 25, loss : 0.2809296799519505 ITERATION : 26, loss : 0.2809296799519505 ITERATION : 27, loss : 0.2809296799519505 ITERATION : 28, loss : 0.2809296799519505 ITERATION : 29, loss : 0.2809296799519505 ITERATION : 30, loss : 0.2809296799519505 ITERATION : 31, loss : 0.2809296799519505 ITERATION : 32, loss : 0.2809296799519505 ITERATION : 33, loss : 0.2809296799519505 ITERATION : 34, loss : 0.2809296799519505 ITERATION : 35, loss : 0.2809296799519505 ITERATION : 36, loss : 0.2809296799519505 ITERATION : 37, loss : 0.2809296799519505 ITERATION : 38, loss : 0.2809296799519505 ITERATION : 39, loss : 0.2809296799519505 ITERATION : 40, loss : 0.2809296799519505 ITERATION : 41, loss : 0.2809296799519505 ITERATION : 42, loss : 0.2809296799519505 ITERATION : 43, loss : 0.2809296799519505 ITERATION : 44, loss : 0.2809296799519505 ITERATION : 45, loss : 0.2809296799519505 ITERATION : 46, loss : 0.2809296799519505 ITERATION : 47, loss : 0.2809296799519505 ITERATION : 48, loss : 0.2809296799519505 ITERATION : 49, loss : 0.2809296799519505 ITERATION : 50, loss : 0.2809296799519505 ITERATION : 51, loss : 0.2809296799519505 ITERATION : 52, loss : 0.2809296799519505 ITERATION : 53, loss : 0.2809296799519505 ITERATION : 54, loss : 0.2809296799519505 ITERATION : 55, loss : 0.2809296799519505 ITERATION : 56, loss : 0.2809296799519505 ITERATION : 57, loss : 0.2809296799519505 ITERATION : 58, loss : 0.2809296799519505 ITERATION : 59, loss : 0.2809296799519505 ITERATION : 60, loss : 0.2809296799519505 ITERATION : 61, loss : 0.2809296799519505 ITERATION : 62, loss : 0.2809296799519505 ITERATION : 63, loss : 0.2809296799519505 ITERATION : 64, loss : 0.2809296799519505 ITERATION : 65, loss : 0.2809296799519505 ITERATION : 66, loss : 0.2809296799519505 ITERATION : 67, loss : 0.2809296799519505 ITERATION : 68, loss : 0.2809296799519505 ITERATION : 69, loss : 0.2809296799519505 ITERATION : 70, loss : 0.2809296799519505 ITERATION : 71, loss : 0.2809296799519505 ITERATION : 72, loss : 0.2809296799519505 ITERATION : 73, loss : 0.2809296799519505 ITERATION : 74, loss : 0.2809296799519505 ITERATION : 75, loss : 0.2809296799519505 ITERATION : 76, loss : 0.2809296799519505 ITERATION : 77, loss : 0.2809296799519505 ITERATION : 78, loss : 0.2809296799519505 ITERATION : 79, loss : 0.2809296799519505 ITERATION : 80, loss : 0.2809296799519505 ITERATION : 81, loss : 0.2809296799519505 ITERATION : 82, loss : 0.2809296799519505 ITERATION : 83, loss : 0.2809296799519505 ITERATION : 84, loss : 0.2809296799519505 ITERATION : 85, loss : 0.2809296799519505 ITERATION : 86, loss : 0.2809296799519505 ITERATION : 87, loss : 0.2809296799519505 ITERATION : 88, loss : 0.2809296799519505 ITERATION : 89, loss : 0.2809296799519505 ITERATION : 90, loss : 0.2809296799519505 ITERATION : 91, loss : 0.2809296799519505 ITERATION : 92, loss : 0.2809296799519505 ITERATION : 93, loss : 0.2809296799519505 ITERATION : 94, loss : 0.2809296799519505 ITERATION : 95, loss : 0.2809296799519505 ITERATION : 96, loss : 0.2809296799519505 ITERATION : 97, loss : 0.2809296799519505 ITERATION : 98, loss : 0.2809296799519505 ITERATION : 99, loss : 0.2809296799519505 ITERATION : 100, loss : 0.2809296799519505 
ITERATION : 1, loss : 0.20552546334657643 ITERATION : 2, loss : 0.20552546334657643 ITERATION : 3, loss : 0.20552546334657643 ITERATION : 4, loss : 0.20552546334657643 ITERATION : 5, loss : 0.20552546334657643 ITERATION : 6, loss : 0.20552546334657643 ITERATION : 7, loss : 0.20552546334657643 ITERATION : 8, loss : 0.20552546334657643 ITERATION : 9, loss : 0.20552546334657643 ITERATION : 10, loss : 0.20552546334657643 ITERATION : 11, loss : 0.20552546334657643 ITERATION : 12, loss : 0.20552546334657643 ITERATION : 13, loss : 0.20552546334657643 ITERATION : 14, loss : 0.20552546334657643 ITERATION : 15, loss : 0.20552546334657643 ITERATION : 16, loss : 0.20552546334657643 ITERATION : 17, loss : 0.20552546334657643 ITERATION : 18, loss : 0.20552546334657643 ITERATION : 19, loss : 0.20552546334657643 ITERATION : 20, loss : 0.20552546334657643 ITERATION : 21, loss : 0.20552546334657643 ITERATION : 22, loss : 0.20552546334657643 ITERATION : 23, loss : 0.20552546334657643 ITERATION : 24, loss : 0.20552546334657643 ITERATION : 25, loss : 0.20552546334657643 ITERATION : 26, loss : 0.20552546334657643 ITERATION : 27, loss : 0.20552546334657643 ITERATION : 28, loss : 0.20552546334657643 ITERATION : 29, loss : 0.20552546334657643 ITERATION : 30, loss : 0.20552546334657643 ITERATION : 31, loss : 0.20552546334657643 ITERATION : 32, loss : 0.20552546334657643 ITERATION : 33, loss : 0.20552546334657643 ITERATION : 34, loss : 0.20552546334657643 ITERATION : 35, loss : 0.20552546334657643 ITERATION : 36, loss : 0.20552546334657643 ITERATION : 37, loss : 0.20552546334657643 ITERATION : 38, loss : 0.20552546334657643 ITERATION : 39, loss : 0.20552546334657643 ITERATION : 40, loss : 0.20552546334657643 ITERATION : 41, loss : 0.20552546334657643 ITERATION : 42, loss : 0.20552546334657643 ITERATION : 43, loss : 0.20552546334657643 ITERATION : 44, loss : 0.20552546334657643 ITERATION : 45, loss : 0.20552546334657643 ITERATION : 46, loss : 0.20552546334657643 ITERATION : 47, loss : 0.20552546334657643 ITERATION : 48, loss : 0.20552546334657643 ITERATION : 49, loss : 0.20552546334657643 ITERATION : 50, loss : 0.20552546334657643 ITERATION : 51, loss : 0.20552546334657643 ITERATION : 52, loss : 0.20552546334657643 ITERATION : 53, loss : 0.20552546334657643 ITERATION : 54, loss : 0.20552546334657643 ITERATION : 55, loss : 0.20552546334657643 ITERATION : 56, loss : 0.20552546334657643 ITERATION : 57, loss : 0.20552546334657643 ITERATION : 58, loss : 0.20552546334657643 ITERATION : 59, loss : 0.20552546334657643 ITERATION : 60, loss : 0.20552546334657643 ITERATION : 61, loss : 0.20552546334657643 ITERATION : 62, loss : 0.20552546334657643 ITERATION : 63, loss : 0.20552546334657643 ITERATION : 64, loss : 0.20552546334657643 ITERATION : 65, loss : 0.20552546334657643 ITERATION : 66, loss : 0.20552546334657643 ITERATION : 67, loss : 0.20552546334657643 ITERATION : 68, loss : 0.20552546334657643 ITERATION : 69, loss : 0.20552546334657643 ITERATION : 70, loss : 0.20552546334657643 ITERATION : 71, loss : 0.20552546334657643 ITERATION : 72, loss : 0.20552546334657643 ITERATION : 73, loss : 0.20552546334657643 ITERATION : 74, loss : 0.20552546334657643 ITERATION : 75, loss : 0.20552546334657643 ITERATION : 76, loss : 0.20552546334657643 ITERATION : 77, loss : 0.20552546334657643 ITERATION : 78, loss : 0.20552546334657643 ITERATION : 79, loss : 0.20552546334657643 ITERATION : 80, loss : 0.20552546334657643 ITERATION : 81, loss : 0.20552546334657643 ITERATION : 82, loss : 0.20552546334657643 ITERATION : 83, loss : 0.20552546334657643 ITERATION : 84, loss : 0.20552546334657643 ITERATION : 85, loss : 0.20552546334657643 ITERATION : 86, loss : 0.20552546334657643 ITERATION : 87, loss : 0.20552546334657643 ITERATION : 88, loss : 0.20552546334657643 ITERATION : 89, loss : 0.20552546334657643 ITERATION : 90, loss : 0.20552546334657643 ITERATION : 91, loss : 0.20552546334657643 ITERATION : 92, loss : 0.20552546334657643 ITERATION : 93, loss : 0.20552546334657643 ITERATION : 94, loss : 0.20552546334657643 ITERATION : 95, loss : 0.20552546334657643 ITERATION : 96, loss : 0.20552546334657643 ITERATION : 97, loss : 0.20552546334657643 ITERATION : 98, loss : 0.20552546334657643 ITERATION : 99, loss : 0.20552546334657643 ITERATION : 100, loss : 0.20552546334657643 
ITERATION : 1, loss : 0.21183834560890896 ITERATION : 2, loss : 0.21183834560890896 ITERATION : 3, loss : 0.21183834560890896 ITERATION : 4, loss : 0.21183834560890896 ITERATION : 5, loss : 0.21183834560890896 ITERATION : 6, loss : 0.21183834560890896 ITERATION : 7, loss : 0.21183834560890896 ITERATION : 8, loss : 0.21183834560890896 ITERATION : 9, loss : 0.21183834560890896 ITERATION : 10, loss : 0.21183834560890896 ITERATION : 11, loss : 0.21183834560890896 ITERATION : 12, loss : 0.21183834560890896 ITERATION : 13, loss : 0.21183834560890896 ITERATION : 14, loss : 0.21183834560890896 ITERATION : 15, loss : 0.21183834560890896 ITERATION : 16, loss : 0.21183834560890896 ITERATION : 17, loss : 0.21183834560890896 ITERATION : 18, loss : 0.21183834560890896 ITERATION : 19, loss : 0.21183834560890896 ITERATION : 20, loss : 0.21183834560890896 ITERATION : 21, loss : 0.21183834560890896 ITERATION : 22, loss : 0.21183834560890896 ITERATION : 23, loss : 0.21183834560890896 ITERATION : 24, loss : 0.21183834560890896 ITERATION : 25, loss : 0.21183834560890896 ITERATION : 26, loss : 0.21183834560890896 ITERATION : 27, loss : 0.21183834560890896 ITERATION : 28, loss : 0.21183834560890896 ITERATION : 29, loss : 0.21183834560890896 ITERATION : 30, loss : 0.21183834560890896 ITERATION : 31, loss : 0.21183834560890896 ITERATION : 32, loss : 0.21183834560890896 ITERATION : 33, loss : 0.21183834560890896 ITERATION : 34, loss : 0.21183834560890896 ITERATION : 35, loss : 0.21183834560890896 ITERATION : 36, loss : 0.21183834560890896 ITERATION : 37, loss : 0.21183834560890896 ITERATION : 38, loss : 0.21183834560890896 ITERATION : 39, loss : 0.21183834560890896 ITERATION : 40, loss : 0.21183834560890896 ITERATION : 41, loss : 0.21183834560890896 ITERATION : 42, loss : 0.21183834560890896 ITERATION : 43, loss : 0.21183834560890896 ITERATION : 44, loss : 0.21183834560890896 ITERATION : 45, loss : 0.21183834560890896 ITERATION : 46, loss : 0.21183834560890896 ITERATION : 47, loss : 0.21183834560890896 ITERATION : 48, loss : 0.21183834560890896 ITERATION : 49, loss : 0.21183834560890896 ITERATION : 50, loss : 0.21183834560890896 ITERATION : 51, loss : 0.21183834560890896 ITERATION : 52, loss : 0.21183834560890896 ITERATION : 53, loss : 0.21183834560890896 ITERATION : 54, loss : 0.21183834560890896 ITERATION : 55, loss : 0.21183834560890896 ITERATION : 56, loss : 0.21183834560890896 ITERATION : 57, loss : 0.21183834560890896 ITERATION : 58, loss : 0.21183834560890896 ITERATION : 59, loss : 0.21183834560890896 ITERATION : 60, loss : 0.21183834560890896 ITERATION : 61, loss : 0.21183834560890896 ITERATION : 62, loss : 0.21183834560890896 ITERATION : 63, loss : 0.21183834560890896 ITERATION : 64, loss : 0.21183834560890896 ITERATION : 65, loss : 0.21183834560890896 ITERATION : 66, loss : 0.21183834560890896 ITERATION : 67, loss : 0.21183834560890896 ITERATION : 68, loss : 0.21183834560890896 ITERATION : 69, loss : 0.21183834560890896 ITERATION : 70, loss : 0.21183834560890896 ITERATION : 71, loss : 0.21183834560890896 ITERATION : 72, loss : 0.21183834560890896 ITERATION : 73, loss : 0.21183834560890896 ITERATION : 74, loss : 0.21183834560890896 ITERATION : 75, loss : 0.21183834560890896 ITERATION : 76, loss : 0.21183834560890896 ITERATION : 77, loss : 0.21183834560890896 ITERATION : 78, loss : 0.21183834560890896 ITERATION : 79, loss : 0.21183834560890896 ITERATION : 80, loss : 0.21183834560890896 ITERATION : 81, loss : 0.21183834560890896 ITERATION : 82, loss : 0.21183834560890896 ITERATION : 83, loss : 0.21183834560890896 ITERATION : 84, loss : 0.21183834560890896 ITERATION : 85, loss : 0.21183834560890896 ITERATION : 86, loss : 0.21183834560890896 ITERATION : 87, loss : 0.21183834560890896 ITERATION : 88, loss : 0.21183834560890896 ITERATION : 89, loss : 0.21183834560890896 ITERATION : 90, loss : 0.21183834560890896 ITERATION : 91, loss : 0.21183834560890896 ITERATION : 92, loss : 0.21183834560890896 ITERATION : 93, loss : 0.21183834560890896 ITERATION : 94, loss : 0.21183834560890896 ITERATION : 95, loss : 0.21183834560890896 ITERATION : 96, loss : 0.21183834560890896 ITERATION : 97, loss : 0.21183834560890896 ITERATION : 98, loss : 0.21183834560890896 ITERATION : 99, loss : 0.21183834560890896 ITERATION : 100, loss : 0.21183834560890896 
ITERATION : 1, loss : 0.08631831739612243 ITERATION : 2, loss : 0.08631831739612243 ITERATION : 3, loss : 0.08631831739612243 ITERATION : 4, loss : 0.08631831739612243 ITERATION : 5, loss : 0.08631831739612243 ITERATION : 6, loss : 0.08631831739612243 ITERATION : 7, loss : 0.08631831739612243 ITERATION : 8, loss : 0.08631831739612243 ITERATION : 9, loss : 0.08631831739612243 ITERATION : 10, loss : 0.08631831739612243 ITERATION : 11, loss : 0.08631831739612243 ITERATION : 12, loss : 0.08631831739612243 ITERATION : 13, loss : 0.08631831739612243 ITERATION : 14, loss : 0.08631831739612243 ITERATION : 15, loss : 0.08631831739612243 ITERATION : 16, loss : 0.08631831739612243 ITERATION : 17, loss : 0.08631831739612243 ITERATION : 18, loss : 0.08631831739612243 ITERATION : 19, loss : 0.08631831739612243 ITERATION : 20, loss : 0.08631831739612243 ITERATION : 21, loss : 0.08631831739612243 ITERATION : 22, loss : 0.08631831739612243 ITERATION : 23, loss : 0.08631831739612243 ITERATION : 24, loss : 0.08631831739612243 ITERATION : 25, loss : 0.08631831739612243 ITERATION : 26, loss : 0.08631831739612243 ITERATION : 27, loss : 0.08631831739612243 ITERATION : 28, loss : 0.08631831739612243 ITERATION : 29, loss : 0.08631831739612243 ITERATION : 30, loss : 0.08631831739612243 ITERATION : 31, loss : 0.08631831739612243 ITERATION : 32, loss : 0.08631831739612243 ITERATION : 33, loss : 0.08631831739612243 ITERATION : 34, loss : 0.08631831739612243 ITERATION : 35, loss : 0.08631831739612243 ITERATION : 36, loss : 0.08631831739612243 ITERATION : 37, loss : 0.08631831739612243 ITERATION : 38, loss : 0.08631831739612243 ITERATION : 39, loss : 0.08631831739612243 ITERATION : 40, loss : 0.08631831739612243 ITERATION : 41, loss : 0.08631831739612243 ITERATION : 42, loss : 0.08631831739612243 ITERATION : 43, loss : 0.08631831739612243 ITERATION : 44, loss : 0.08631831739612243 ITERATION : 45, loss : 0.08631831739612243 ITERATION : 46, loss : 0.08631831739612243 ITERATION : 47, loss : 0.08631831739612243 ITERATION : 48, loss : 0.08631831739612243 ITERATION : 49, loss : 0.08631831739612243 ITERATION : 50, loss : 0.08631831739612243 ITERATION : 51, loss : 0.08631831739612243 ITERATION : 52, loss : 0.08631831739612243 ITERATION : 53, loss : 0.08631831739612243 ITERATION : 54, loss : 0.08631831739612243 ITERATION : 55, loss : 0.08631831739612243 ITERATION : 56, loss : 0.08631831739612243 ITERATION : 57, loss : 0.08631831739612243 ITERATION : 58, loss : 0.08631831739612243 ITERATION : 59, loss : 0.08631831739612243 ITERATION : 60, loss : 0.08631831739612243 ITERATION : 61, loss : 0.08631831739612243 ITERATION : 62, loss : 0.08631831739612243 ITERATION : 63, loss : 0.08631831739612243 ITERATION : 64, loss : 0.08631831739612243 ITERATION : 65, loss : 0.08631831739612243 ITERATION : 66, loss : 0.08631831739612243 ITERATION : 67, loss : 0.08631831739612243 ITERATION : 68, loss : 0.08631831739612243 ITERATION : 69, loss : 0.08631831739612243 ITERATION : 70, loss : 0.08631831739612243 ITERATION : 71, loss : 0.08631831739612243 ITERATION : 72, loss : 0.08631831739612243 ITERATION : 73, loss : 0.08631831739612243 ITERATION : 74, loss : 0.08631831739612243 ITERATION : 75, loss : 0.08631831739612243 ITERATION : 76, loss : 0.08631831739612243 ITERATION : 77, loss : 0.08631831739612243 ITERATION : 78, loss : 0.08631831739612243 ITERATION : 79, loss : 0.08631831739612243 ITERATION : 80, loss : 0.08631831739612243 ITERATION : 81, loss : 0.08631831739612243 ITERATION : 82, loss : 0.08631831739612243 ITERATION : 83, loss : 0.08631831739612243 ITERATION : 84, loss : 0.08631831739612243 ITERATION : 85, loss : 0.08631831739612243 ITERATION : 86, loss : 0.08631831739612243 ITERATION : 87, loss : 0.08631831739612243 ITERATION : 88, loss : 0.08631831739612243 ITERATION : 89, loss : 0.08631831739612243 ITERATION : 90, loss : 0.08631831739612243 ITERATION : 91, loss : 0.08631831739612243 ITERATION : 92, loss : 0.08631831739612243 ITERATION : 93, loss : 0.08631831739612243 ITERATION : 94, loss : 0.08631831739612243 ITERATION : 95, loss : 0.08631831739612243 ITERATION : 96, loss : 0.08631831739612243 ITERATION : 97, loss : 0.08631831739612243 ITERATION : 98, loss : 0.08631831739612243 ITERATION : 99, loss : 0.08631831739612243 ITERATION : 100, loss : 0.08631831739612243 
ITERATION : 1, loss : 0.24148431891274952 ITERATION : 2, loss : 0.24148431891274952 ITERATION : 3, loss : 0.24148431891274952 ITERATION : 4, loss : 0.24148431891274952 ITERATION : 5, loss : 0.24148431891274952 ITERATION : 6, loss : 0.24148431891274952 ITERATION : 7, loss : 0.24148431891274952 ITERATION : 8, loss : 0.24148431891274952 ITERATION : 9, loss : 0.24148431891274952 ITERATION : 10, loss : 0.24148431891274952 ITERATION : 11, loss : 0.24148431891274952 ITERATION : 12, loss : 0.24148431891274952 ITERATION : 13, loss : 0.24148431891274952 ITERATION : 14, loss : 0.24148431891274952 ITERATION : 15, loss : 0.24148431891274952 ITERATION : 16, loss : 0.24148431891274952 ITERATION : 17, loss : 0.24148431891274952 ITERATION : 18, loss : 0.24148431891274952 ITERATION : 19, loss : 0.24148431891274952 ITERATION : 20, loss : 0.24148431891274952 ITERATION : 21, loss : 0.24148431891274952 ITERATION : 22, loss : 0.24148431891274952 ITERATION : 23, loss : 0.24148431891274952 ITERATION : 24, loss : 0.24148431891274952 ITERATION : 25, loss : 0.24148431891274952 ITERATION : 26, loss : 0.24148431891274952 ITERATION : 27, loss : 0.24148431891274952 ITERATION : 28, loss : 0.24148431891274952 ITERATION : 29, loss : 0.24148431891274952 ITERATION : 30, loss : 0.24148431891274952 ITERATION : 31, loss : 0.24148431891274952 ITERATION : 32, loss : 0.24148431891274952 ITERATION : 33, loss : 0.24148431891274952 ITERATION : 34, loss : 0.24148431891274952 ITERATION : 35, loss : 0.24148431891274952 ITERATION : 36, loss : 0.24148431891274952 ITERATION : 37, loss : 0.24148431891274952 ITERATION : 38, loss : 0.24148431891274952 ITERATION : 39, loss : 0.24148431891274952 ITERATION : 40, loss : 0.24148431891274952 ITERATION : 41, loss : 0.24148431891274952 ITERATION : 42, loss : 0.24148431891274952 ITERATION : 43, loss : 0.24148431891274952 ITERATION : 44, loss : 0.24148431891274952 ITERATION : 45, loss : 0.24148431891274952 ITERATION : 46, loss : 0.24148431891274952 ITERATION : 47, loss : 0.24148431891274952 ITERATION : 48, loss : 0.24148431891274952 ITERATION : 49, loss : 0.24148431891274952 ITERATION : 50, loss : 0.24148431891274952 ITERATION : 51, loss : 0.24148431891274952 ITERATION : 52, loss : 0.24148431891274952 ITERATION : 53, loss : 0.24148431891274952 ITERATION : 54, loss : 0.24148431891274952 ITERATION : 55, loss : 0.24148431891274952 ITERATION : 56, loss : 0.24148431891274952 ITERATION : 57, loss : 0.24148431891274952 ITERATION : 58, loss : 0.24148431891274952 ITERATION : 59, loss : 0.24148431891274952 ITERATION : 60, loss : 0.24148431891274952 ITERATION : 61, loss : 0.24148431891274952 ITERATION : 62, loss : 0.24148431891274952 ITERATION : 63, loss : 0.24148431891274952 ITERATION : 64, loss : 0.24148431891274952 ITERATION : 65, loss : 0.24148431891274952 ITERATION : 66, loss : 0.24148431891274952 ITERATION : 67, loss : 0.24148431891274952 ITERATION : 68, loss : 0.24148431891274952 ITERATION : 69, loss : 0.24148431891274952 ITERATION : 70, loss : 0.24148431891274952 ITERATION : 71, loss : 0.24148431891274952 ITERATION : 72, loss : 0.24148431891274952 ITERATION : 73, loss : 0.24148431891274952 ITERATION : 74, loss : 0.24148431891274952 ITERATION : 75, loss : 0.24148431891274952 ITERATION : 76, loss : 0.24148431891274952 ITERATION : 77, loss : 0.24148431891274952 ITERATION : 78, loss : 0.24148431891274952 ITERATION : 79, loss : 0.24148431891274952 ITERATION : 80, loss : 0.24148431891274952 ITERATION : 81, loss : 0.24148431891274952 ITERATION : 82, loss : 0.24148431891274952 ITERATION : 83, loss : 0.24148431891274952 ITERATION : 84, loss : 0.24148431891274952 ITERATION : 85, loss : 0.24148431891274952 ITERATION : 86, loss : 0.24148431891274952 ITERATION : 87, loss : 0.24148431891274952 ITERATION : 88, loss : 0.24148431891274952 ITERATION : 89, loss : 0.24148431891274952 ITERATION : 90, loss : 0.24148431891274952 ITERATION : 91, loss : 0.24148431891274952 ITERATION : 92, loss : 0.24148431891274952 ITERATION : 93, loss : 0.24148431891274952 ITERATION : 94, loss : 0.24148431891274952 ITERATION : 95, loss : 0.24148431891274952 ITERATION : 96, loss : 0.24148431891274952 ITERATION : 97, loss : 0.24148431891274952 ITERATION : 98, loss : 0.24148431891274952 ITERATION : 99, loss : 0.24148431891274952 ITERATION : 100, loss : 0.24148431891274952 
gradient norm in None layer : 0.8259364764430936
gradient norm in None layer : 0.036142839831035015
gradient norm in None layer : 0.03223182506323419
gradient norm in None layer : 0.4865182998823386
gradient norm in None layer : 0.025926138565296835
gradient norm in None layer : 0.03150371590623282
gradient norm in None layer : 0.12969881586818402
gradient norm in None layer : 0.0047056319606856
gradient norm in None layer : 0.0053632465934605284
gradient norm in None layer : 0.10110084784333553
gradient norm in None layer : 0.0045308521630956266
gradient norm in None layer : 0.004641401467237558
gradient norm in None layer : 0.02860999231823209
gradient norm in None layer : 0.0007907900477464041
gradient norm in None layer : 0.000743163659870884
gradient norm in None layer : 0.027127651646407153
gradient norm in None layer : 0.0010150974806613273
gradient norm in None layer : 0.001044834695649939
gradient norm in None layer : 0.037113335160614935
gradient norm in None layer : 0.0004473138612957669
gradient norm in None layer : 0.10521568625972033
gradient norm in None layer : 0.005626800321693594
gradient norm in None layer : 0.0049000526080615414
gradient norm in None layer : 0.11844640900501101
gradient norm in None layer : 0.007090243836736738
gradient norm in None layer : 0.0072155181716639875
gradient norm in None layer : 0.16800130342340835
gradient norm in None layer : 0.0018539269437043288
gradient norm in None layer : 0.39511889282661283
gradient norm in None layer : 0.029407304327292726
gradient norm in None layer : 0.024317310313440574
gradient norm in None layer : 0.44875128421747956
gradient norm in None layer : 0.0852036911029911
gradient norm in None layer : 0.14361657454302637
gradient norm in None layer : 0.059216282135920756
gradient norm in None layer : 0.023317699961102556
Total gradient norm: 1.1820857284429598
invariance loss : 212.0784449220792, avg_den : 0.0, density loss : 0.1, mse loss : 0.2512547444189246, solver time : 0.8407738208770752 sec , total loss : 0.5633331893410037, running loss : 1.1238351705025231
Epoch 0/10 , batch 5/12500 
ITERATION : 1, loss : 0.1179390787657992 ITERATION : 2, loss : 0.1179390787657992 ITERATION : 3, loss : 0.1179390787657992 ITERATION : 4, loss : 0.1179390787657992 ITERATION : 5, loss : 0.1179390787657992 ITERATION : 6, loss : 0.1179390787657992 ITERATION : 7, loss : 0.1179390787657992 ITERATION : 8, loss : 0.1179390787657992 ITERATION : 9, loss : 0.1179390787657992 ITERATION : 10, loss : 0.1179390787657992 ITERATION : 11, loss : 0.1179390787657992 ITERATION : 12, loss : 0.1179390787657992 ITERATION : 13, loss : 0.1179390787657992 ITERATION : 14, loss : 0.1179390787657992 ITERATION : 15, loss : 0.1179390787657992 ITERATION : 16, loss : 0.1179390787657992 ITERATION : 17, loss : 0.1179390787657992 ITERATION : 18, loss : 0.1179390787657992 ITERATION : 19, loss : 0.1179390787657992 ITERATION : 20, loss : 0.1179390787657992 ITERATION : 21, loss : 0.1179390787657992 ITERATION : 22, loss : 0.1179390787657992 ITERATION : 23, loss : 0.1179390787657992 ITERATION : 24, loss : 0.1179390787657992 ITERATION : 25, loss : 0.1179390787657992 ITERATION : 26, loss : 0.1179390787657992 ITERATION : 27, loss : 0.1179390787657992 ITERATION : 28, loss : 0.1179390787657992 ITERATION : 29, loss : 0.1179390787657992 ITERATION : 30, loss : 0.1179390787657992 ITERATION : 31, loss : 0.1179390787657992 ITERATION : 32, loss : 0.1179390787657992 ITERATION : 33, loss : 0.1179390787657992 ITERATION : 34, loss : 0.1179390787657992 ITERATION : 35, loss : 0.1179390787657992 ITERATION : 36, loss : 0.1179390787657992 ITERATION : 37, loss : 0.1179390787657992 ITERATION : 38, loss : 0.1179390787657992 ITERATION : 39, loss : 0.1179390787657992 ITERATION : 40, loss : 0.1179390787657992 ITERATION : 41, loss : 0.1179390787657992 ITERATION : 42, loss : 0.1179390787657992 ITERATION : 43, loss : 0.1179390787657992 ITERATION : 44, loss : 0.1179390787657992 ITERATION : 45, loss : 0.1179390787657992 ITERATION : 46, loss : 0.1179390787657992 ITERATION : 47, loss : 0.1179390787657992 ITERATION : 48, loss : 0.1179390787657992 ITERATION : 49, loss : 0.1179390787657992 ITERATION : 50, loss : 0.1179390787657992 ITERATION : 51, loss : 0.1179390787657992 ITERATION : 52, loss : 0.1179390787657992 ITERATION : 53, loss : 0.1179390787657992 ITERATION : 54, loss : 0.1179390787657992 ITERATION : 55, loss : 0.1179390787657992 ITERATION : 56, loss : 0.1179390787657992 ITERATION : 57, loss : 0.1179390787657992 ITERATION : 58, loss : 0.1179390787657992 ITERATION : 59, loss : 0.1179390787657992 ITERATION : 60, loss : 0.1179390787657992 ITERATION : 61, loss : 0.1179390787657992 ITERATION : 62, loss : 0.1179390787657992 ITERATION : 63, loss : 0.1179390787657992 ITERATION : 64, loss : 0.1179390787657992 ITERATION : 65, loss : 0.1179390787657992 ITERATION : 66, loss : 0.1179390787657992 ITERATION : 67, loss : 0.1179390787657992 ITERATION : 68, loss : 0.1179390787657992 ITERATION : 69, loss : 0.1179390787657992 ITERATION : 70, loss : 0.1179390787657992 ITERATION : 71, loss : 0.1179390787657992 ITERATION : 72, loss : 0.1179390787657992 ITERATION : 73, loss : 0.1179390787657992 ITERATION : 74, loss : 0.1179390787657992 ITERATION : 75, loss : 0.1179390787657992 ITERATION : 76, loss : 0.1179390787657992 ITERATION : 77, loss : 0.1179390787657992 ITERATION : 78, loss : 0.1179390787657992 ITERATION : 79, loss : 0.1179390787657992 ITERATION : 80, loss : 0.1179390787657992 ITERATION : 81, loss : 0.1179390787657992 ITERATION : 82, loss : 0.1179390787657992 ITERATION : 83, loss : 0.1179390787657992 ITERATION : 84, loss : 0.1179390787657992 ITERATION : 85, loss : 0.1179390787657992 ITERATION : 86, loss : 0.1179390787657992 ITERATION : 87, loss : 0.1179390787657992 ITERATION : 88, loss : 0.1179390787657992 ITERATION : 89, loss : 0.1179390787657992 ITERATION : 90, loss : 0.1179390787657992 ITERATION : 91, loss : 0.1179390787657992 ITERATION : 92, loss : 0.1179390787657992 ITERATION : 93, loss : 0.1179390787657992 ITERATION : 94, loss : 0.1179390787657992 ITERATION : 95, loss : 0.1179390787657992 ITERATION : 96, loss : 0.1179390787657992 ITERATION : 97, loss : 0.1179390787657992 ITERATION : 98, loss : 0.1179390787657992 ITERATION : 99, loss : 0.1179390787657992 ITERATION : 100, loss : 0.1179390787657992 
ITERATION : 1, loss : 0.46961967695558643 ITERATION : 2, loss : 0.46961967695558643 ITERATION : 3, loss : 0.46961967695558643 ITERATION : 4, loss : 0.46961967695558643 ITERATION : 5, loss : 0.46961967695558643 ITERATION : 6, loss : 0.46961967695558643 ITERATION : 7, loss : 0.46961967695558643 ITERATION : 8, loss : 0.46961967695558643 ITERATION : 9, loss : 0.46961967695558643 ITERATION : 10, loss : 0.46961967695558643 ITERATION : 11, loss : 0.46961967695558643 ITERATION : 12, loss : 0.46961967695558643 ITERATION : 13, loss : 0.46961967695558643 ITERATION : 14, loss : 0.46961967695558643 ITERATION : 15, loss : 0.46961967695558643 ITERATION : 16, loss : 0.46961967695558643 ITERATION : 17, loss : 0.46961967695558643 ITERATION : 18, loss : 0.46961967695558643 ITERATION : 19, loss : 0.46961967695558643 ITERATION : 20, loss : 0.46961967695558643 ITERATION : 21, loss : 0.46961967695558643 ITERATION : 22, loss : 0.46961967695558643 ITERATION : 23, loss : 0.46961967695558643 ITERATION : 24, loss : 0.46961967695558643 ITERATION : 25, loss : 0.46961967695558643 ITERATION : 26, loss : 0.46961967695558643 ITERATION : 27, loss : 0.46961967695558643 ITERATION : 28, loss : 0.46961967695558643 ITERATION : 29, loss : 0.46961967695558643 ITERATION : 30, loss : 0.46961967695558643 ITERATION : 31, loss : 0.46961967695558643 ITERATION : 32, loss : 0.46961967695558643 ITERATION : 33, loss : 0.46961967695558643 ITERATION : 34, loss : 0.46961967695558643 ITERATION : 35, loss : 0.46961967695558643 ITERATION : 36, loss : 0.46961967695558643 ITERATION : 37, loss : 0.46961967695558643 ITERATION : 38, loss : 0.46961967695558643 ITERATION : 39, loss : 0.46961967695558643 ITERATION : 40, loss : 0.46961967695558643 ITERATION : 41, loss : 0.46961967695558643 ITERATION : 42, loss : 0.46961967695558643 ITERATION : 43, loss : 0.46961967695558643 ITERATION : 44, loss : 0.46961967695558643 ITERATION : 45, loss : 0.46961967695558643 ITERATION : 46, loss : 0.46961967695558643 ITERATION : 47, loss : 0.46961967695558643 ITERATION : 48, loss : 0.46961967695558643 ITERATION : 49, loss : 0.46961967695558643 ITERATION : 50, loss : 0.46961967695558643 ITERATION : 51, loss : 0.46961967695558643 ITERATION : 52, loss : 0.46961967695558643 ITERATION : 53, loss : 0.46961967695558643 ITERATION : 54, loss : 0.46961967695558643 ITERATION : 55, loss : 0.46961967695558643 ITERATION : 56, loss : 0.46961967695558643 ITERATION : 57, loss : 0.46961967695558643 ITERATION : 58, loss : 0.46961967695558643 ITERATION : 59, loss : 0.46961967695558643 ITERATION : 60, loss : 0.46961967695558643 ITERATION : 61, loss : 0.46961967695558643 ITERATION : 62, loss : 0.46961967695558643 ITERATION : 63, loss : 0.46961967695558643 ITERATION : 64, loss : 0.46961967695558643 ITERATION : 65, loss : 0.46961967695558643 ITERATION : 66, loss : 0.46961967695558643 ITERATION : 67, loss : 0.46961967695558643 ITERATION : 68, loss : 0.46961967695558643 ITERATION : 69, loss : 0.46961967695558643 ITERATION : 70, loss : 0.46961967695558643 ITERATION : 71, loss : 0.46961967695558643 ITERATION : 72, loss : 0.46961967695558643 ITERATION : 73, loss : 0.46961967695558643 ITERATION : 74, loss : 0.46961967695558643 ITERATION : 75, loss : 0.46961967695558643 ITERATION : 76, loss : 0.46961967695558643 ITERATION : 77, loss : 0.46961967695558643 ITERATION : 78, loss : 0.46961967695558643 ITERATION : 79, loss : 0.46961967695558643 ITERATION : 80, loss : 0.46961967695558643 ITERATION : 81, loss : 0.46961967695558643 ITERATION : 82, loss : 0.46961967695558643 ITERATION : 83, loss : 0.46961967695558643 ITERATION : 84, loss : 0.46961967695558643 ITERATION : 85, loss : 0.46961967695558643 ITERATION : 86, loss : 0.46961967695558643 ITERATION : 87, loss : 0.46961967695558643 ITERATION : 88, loss : 0.46961967695558643 ITERATION : 89, loss : 0.46961967695558643 ITERATION : 90, loss : 0.46961967695558643 ITERATION : 91, loss : 0.46961967695558643 ITERATION : 92, loss : 0.46961967695558643 ITERATION : 93, loss : 0.46961967695558643 ITERATION : 94, loss : 0.46961967695558643 ITERATION : 95, loss : 0.46961967695558643 ITERATION : 96, loss : 0.46961967695558643 ITERATION : 97, loss : 0.46961967695558643 ITERATION : 98, loss : 0.46961967695558643 ITERATION : 99, loss : 0.46961967695558643 ITERATION : 100, loss : 0.46961967695558643 
ITERATION : 1, loss : 0.18108946583467897 ITERATION : 2, loss : 0.18108946583467897 ITERATION : 3, loss : 0.18108946583467897 ITERATION : 4, loss : 0.18108946583467897 ITERATION : 5, loss : 0.18108946583467897 ITERATION : 6, loss : 0.18108946583467897 ITERATION : 7, loss : 0.18108946583467897 ITERATION : 8, loss : 0.18108946583467897 ITERATION : 9, loss : 0.18108946583467897 ITERATION : 10, loss : 0.18108946583467897 ITERATION : 11, loss : 0.18108946583467897 ITERATION : 12, loss : 0.18108946583467897 ITERATION : 13, loss : 0.18108946583467897 ITERATION : 14, loss : 0.18108946583467897 ITERATION : 15, loss : 0.18108946583467897 ITERATION : 16, loss : 0.18108946583467897 ITERATION : 17, loss : 0.18108946583467897 ITERATION : 18, loss : 0.18108946583467897 ITERATION : 19, loss : 0.18108946583467897 ITERATION : 20, loss : 0.18108946583467897 ITERATION : 21, loss : 0.18108946583467897 ITERATION : 22, loss : 0.18108946583467897 ITERATION : 23, loss : 0.18108946583467897 ITERATION : 24, loss : 0.18108946583467897 ITERATION : 25, loss : 0.18108946583467897 ITERATION : 26, loss : 0.18108946583467897 ITERATION : 27, loss : 0.18108946583467897 ITERATION : 28, loss : 0.18108946583467897 ITERATION : 29, loss : 0.18108946583467897 ITERATION : 30, loss : 0.18108946583467897 ITERATION : 31, loss : 0.18108946583467897 ITERATION : 32, loss : 0.18108946583467897 ITERATION : 33, loss : 0.18108946583467897 ITERATION : 34, loss : 0.18108946583467897 ITERATION : 35, loss : 0.18108946583467897 ITERATION : 36, loss : 0.18108946583467897 ITERATION : 37, loss : 0.18108946583467897 ITERATION : 38, loss : 0.18108946583467897 ITERATION : 39, loss : 0.18108946583467897 ITERATION : 40, loss : 0.18108946583467897 ITERATION : 41, loss : 0.18108946583467897 ITERATION : 42, loss : 0.18108946583467897 ITERATION : 43, loss : 0.18108946583467897 ITERATION : 44, loss : 0.18108946583467897 ITERATION : 45, loss : 0.18108946583467897 ITERATION : 46, loss : 0.18108946583467897 ITERATION : 47, loss : 0.18108946583467897 ITERATION : 48, loss : 0.18108946583467897 ITERATION : 49, loss : 0.18108946583467897 ITERATION : 50, loss : 0.18108946583467897 ITERATION : 51, loss : 0.18108946583467897 ITERATION : 52, loss : 0.18108946583467897 ITERATION : 53, loss : 0.18108946583467897 ITERATION : 54, loss : 0.18108946583467897 ITERATION : 55, loss : 0.18108946583467897 ITERATION : 56, loss : 0.18108946583467897 ITERATION : 57, loss : 0.18108946583467897 ITERATION : 58, loss : 0.18108946583467897 ITERATION : 59, loss : 0.18108946583467897 ITERATION : 60, loss : 0.18108946583467897 ITERATION : 61, loss : 0.18108946583467897 ITERATION : 62, loss : 0.18108946583467897 ITERATION : 63, loss : 0.18108946583467897 ITERATION : 64, loss : 0.18108946583467897 ITERATION : 65, loss : 0.18108946583467897 ITERATION : 66, loss : 0.18108946583467897 ITERATION : 67, loss : 0.18108946583467897 ITERATION : 68, loss : 0.18108946583467897 ITERATION : 69, loss : 0.18108946583467897 ITERATION : 70, loss : 0.18108946583467897 ITERATION : 71, loss : 0.18108946583467897 ITERATION : 72, loss : 0.18108946583467897 ITERATION : 73, loss : 0.18108946583467897 ITERATION : 74, loss : 0.18108946583467897 ITERATION : 75, loss : 0.18108946583467897 ITERATION : 76, loss : 0.18108946583467897 ITERATION : 77, loss : 0.18108946583467897 ITERATION : 78, loss : 0.18108946583467897 ITERATION : 79, loss : 0.18108946583467897 ITERATION : 80, loss : 0.18108946583467897 ITERATION : 81, loss : 0.18108946583467897 ITERATION : 82, loss : 0.18108946583467897 ITERATION : 83, loss : 0.18108946583467897 ITERATION : 84, loss : 0.18108946583467897 ITERATION : 85, loss : 0.18108946583467897 ITERATION : 86, loss : 0.18108946583467897 ITERATION : 87, loss : 0.18108946583467897 ITERATION : 88, loss : 0.18108946583467897 ITERATION : 89, loss : 0.18108946583467897 ITERATION : 90, loss : 0.18108946583467897 ITERATION : 91, loss : 0.18108946583467897 ITERATION : 92, loss : 0.18108946583467897 ITERATION : 93, loss : 0.18108946583467897 ITERATION : 94, loss : 0.18108946583467897 ITERATION : 95, loss : 0.18108946583467897 ITERATION : 96, loss : 0.18108946583467897 ITERATION : 97, loss : 0.18108946583467897 ITERATION : 98, loss : 0.18108946583467897 ITERATION : 99, loss : 0.18108946583467897 ITERATION : 100, loss : 0.18108946583467897 
ITERATION : 1, loss : 0.26490214073859913 ITERATION : 2, loss : 0.26490214073859913 ITERATION : 3, loss : 0.26490214073859913 ITERATION : 4, loss : 0.26490214073859913 ITERATION : 5, loss : 0.26490214073859913 ITERATION : 6, loss : 0.26490214073859913 ITERATION : 7, loss : 0.26490214073859913 ITERATION : 8, loss : 0.26490214073859913 ITERATION : 9, loss : 0.26490214073859913 ITERATION : 10, loss : 0.26490214073859913 ITERATION : 11, loss : 0.26490214073859913 ITERATION : 12, loss : 0.26490214073859913 ITERATION : 13, loss : 0.26490214073859913 ITERATION : 14, loss : 0.26490214073859913 ITERATION : 15, loss : 0.26490214073859913 ITERATION : 16, loss : 0.26490214073859913 ITERATION : 17, loss : 0.26490214073859913 ITERATION : 18, loss : 0.26490214073859913 ITERATION : 19, loss : 0.26490214073859913 ITERATION : 20, loss : 0.26490214073859913 ITERATION : 21, loss : 0.26490214073859913 ITERATION : 22, loss : 0.26490214073859913 ITERATION : 23, loss : 0.26490214073859913 ITERATION : 24, loss : 0.26490214073859913 ITERATION : 25, loss : 0.26490214073859913 ITERATION : 26, loss : 0.26490214073859913 ITERATION : 27, loss : 0.26490214073859913 ITERATION : 28, loss : 0.26490214073859913 ITERATION : 29, loss : 0.26490214073859913 ITERATION : 30, loss : 0.26490214073859913 ITERATION : 31, loss : 0.26490214073859913 ITERATION : 32, loss : 0.26490214073859913 ITERATION : 33, loss : 0.26490214073859913 ITERATION : 34, loss : 0.26490214073859913 ITERATION : 35, loss : 0.26490214073859913 ITERATION : 36, loss : 0.26490214073859913 ITERATION : 37, loss : 0.26490214073859913 ITERATION : 38, loss : 0.26490214073859913 ITERATION : 39, loss : 0.26490214073859913 ITERATION : 40, loss : 0.26490214073859913 ITERATION : 41, loss : 0.26490214073859913 ITERATION : 42, loss : 0.26490214073859913 ITERATION : 43, loss : 0.26490214073859913 ITERATION : 44, loss : 0.26490214073859913 ITERATION : 45, loss : 0.26490214073859913 ITERATION : 46, loss : 0.26490214073859913 ITERATION : 47, loss : 0.26490214073859913 ITERATION : 48, loss : 0.26490214073859913 ITERATION : 49, loss : 0.26490214073859913 ITERATION : 50, loss : 0.26490214073859913 ITERATION : 51, loss : 0.26490214073859913 ITERATION : 52, loss : 0.26490214073859913 ITERATION : 53, loss : 0.26490214073859913 ITERATION : 54, loss : 0.26490214073859913 ITERATION : 55, loss : 0.26490214073859913 ITERATION : 56, loss : 0.26490214073859913 ITERATION : 57, loss : 0.26490214073859913 ITERATION : 58, loss : 0.26490214073859913 ITERATION : 59, loss : 0.26490214073859913 ITERATION : 60, loss : 0.26490214073859913 ITERATION : 61, loss : 0.26490214073859913 ITERATION : 62, loss : 0.26490214073859913 ITERATION : 63, loss : 0.26490214073859913 ITERATION : 64, loss : 0.26490214073859913 ITERATION : 65, loss : 0.26490214073859913 ITERATION : 66, loss : 0.26490214073859913 ITERATION : 67, loss : 0.26490214073859913 ITERATION : 68, loss : 0.26490214073859913 ITERATION : 69, loss : 0.26490214073859913 ITERATION : 70, loss : 0.26490214073859913 ITERATION : 71, loss : 0.26490214073859913 ITERATION : 72, loss : 0.26490214073859913 ITERATION : 73, loss : 0.26490214073859913 ITERATION : 74, loss : 0.26490214073859913 ITERATION : 75, loss : 0.26490214073859913 ITERATION : 76, loss : 0.26490214073859913 ITERATION : 77, loss : 0.26490214073859913 ITERATION : 78, loss : 0.26490214073859913 ITERATION : 79, loss : 0.26490214073859913 ITERATION : 80, loss : 0.26490214073859913 ITERATION : 81, loss : 0.26490214073859913 ITERATION : 82, loss : 0.26490214073859913 ITERATION : 83, loss : 0.26490214073859913 ITERATION : 84, loss : 0.26490214073859913 ITERATION : 85, loss : 0.26490214073859913 ITERATION : 86, loss : 0.26490214073859913 ITERATION : 87, loss : 0.26490214073859913 ITERATION : 88, loss : 0.26490214073859913 ITERATION : 89, loss : 0.26490214073859913 ITERATION : 90, loss : 0.26490214073859913 ITERATION : 91, loss : 0.26490214073859913 ITERATION : 92, loss : 0.26490214073859913 ITERATION : 93, loss : 0.26490214073859913 ITERATION : 94, loss : 0.26490214073859913 ITERATION : 95, loss : 0.26490214073859913 ITERATION : 96, loss : 0.26490214073859913 ITERATION : 97, loss : 0.26490214073859913 ITERATION : 98, loss : 0.26490214073859913 ITERATION : 99, loss : 0.26490214073859913 ITERATION : 100, loss : 0.26490214073859913 
ITERATION : 1, loss : 0.1960418923490367 ITERATION : 2, loss : 0.1960418923490367 ITERATION : 3, loss : 0.1960418923490367 ITERATION : 4, loss : 0.1960418923490367 ITERATION : 5, loss : 0.1960418923490367 ITERATION : 6, loss : 0.1960418923490367 ITERATION : 7, loss : 0.1960418923490367 ITERATION : 8, loss : 0.1960418923490367 ITERATION : 9, loss : 0.1960418923490367 ITERATION : 10, loss : 0.1960418923490367 ITERATION : 11, loss : 0.1960418923490367 ITERATION : 12, loss : 0.1960418923490367 ITERATION : 13, loss : 0.1960418923490367 ITERATION : 14, loss : 0.1960418923490367 ITERATION : 15, loss : 0.1960418923490367 ITERATION : 16, loss : 0.1960418923490367 ITERATION : 17, loss : 0.1960418923490367 ITERATION : 18, loss : 0.1960418923490367 ITERATION : 19, loss : 0.1960418923490367 ITERATION : 20, loss : 0.1960418923490367 ITERATION : 21, loss : 0.1960418923490367 ITERATION : 22, loss : 0.1960418923490367 ITERATION : 23, loss : 0.1960418923490367 ITERATION : 24, loss : 0.1960418923490367 ITERATION : 25, loss : 0.1960418923490367 ITERATION : 26, loss : 0.1960418923490367 ITERATION : 27, loss : 0.1960418923490367 ITERATION : 28, loss : 0.1960418923490367 ITERATION : 29, loss : 0.1960418923490367 ITERATION : 30, loss : 0.1960418923490367 ITERATION : 31, loss : 0.1960418923490367 ITERATION : 32, loss : 0.1960418923490367 ITERATION : 33, loss : 0.1960418923490367 ITERATION : 34, loss : 0.1960418923490367 ITERATION : 35, loss : 0.1960418923490367 ITERATION : 36, loss : 0.1960418923490367 ITERATION : 37, loss : 0.1960418923490367 ITERATION : 38, loss : 0.1960418923490367 ITERATION : 39, loss : 0.1960418923490367 ITERATION : 40, loss : 0.1960418923490367 ITERATION : 41, loss : 0.1960418923490367 ITERATION : 42, loss : 0.1960418923490367 ITERATION : 43, loss : 0.1960418923490367 ITERATION : 44, loss : 0.1960418923490367 ITERATION : 45, loss : 0.1960418923490367 ITERATION : 46, loss : 0.1960418923490367 ITERATION : 47, loss : 0.1960418923490367 ITERATION : 48, loss : 0.1960418923490367 ITERATION : 49, loss : 0.1960418923490367 ITERATION : 50, loss : 0.1960418923490367 ITERATION : 51, loss : 0.1960418923490367 ITERATION : 52, loss : 0.1960418923490367 ITERATION : 53, loss : 0.1960418923490367 ITERATION : 54, loss : 0.1960418923490367 ITERATION : 55, loss : 0.1960418923490367 ITERATION : 56, loss : 0.1960418923490367 ITERATION : 57, loss : 0.1960418923490367 ITERATION : 58, loss : 0.1960418923490367 ITERATION : 59, loss : 0.1960418923490367 ITERATION : 60, loss : 0.1960418923490367 ITERATION : 61, loss : 0.1960418923490367 ITERATION : 62, loss : 0.1960418923490367 ITERATION : 63, loss : 0.1960418923490367 ITERATION : 64, loss : 0.1960418923490367 ITERATION : 65, loss : 0.1960418923490367 ITERATION : 66, loss : 0.1960418923490367 ITERATION : 67, loss : 0.1960418923490367 ITERATION : 68, loss : 0.1960418923490367 ITERATION : 69, loss : 0.1960418923490367 ITERATION : 70, loss : 0.1960418923490367 ITERATION : 71, loss : 0.1960418923490367 ITERATION : 72, loss : 0.1960418923490367 ITERATION : 73, loss : 0.1960418923490367 ITERATION : 74, loss : 0.1960418923490367 ITERATION : 75, loss : 0.1960418923490367 ITERATION : 76, loss : 0.1960418923490367 ITERATION : 77, loss : 0.1960418923490367 ITERATION : 78, loss : 0.1960418923490367 ITERATION : 79, loss : 0.1960418923490367 ITERATION : 80, loss : 0.1960418923490367 ITERATION : 81, loss : 0.1960418923490367 ITERATION : 82, loss : 0.1960418923490367 ITERATION : 83, loss : 0.1960418923490367 ITERATION : 84, loss : 0.1960418923490367 ITERATION : 85, loss : 0.1960418923490367 ITERATION : 86, loss : 0.1960418923490367 ITERATION : 87, loss : 0.1960418923490367 ITERATION : 88, loss : 0.1960418923490367 ITERATION : 89, loss : 0.1960418923490367 ITERATION : 90, loss : 0.1960418923490367 ITERATION : 91, loss : 0.1960418923490367 ITERATION : 92, loss : 0.1960418923490367 ITERATION : 93, loss : 0.1960418923490367 ITERATION : 94, loss : 0.1960418923490367 ITERATION : 95, loss : 0.1960418923490367 ITERATION : 96, loss : 0.1960418923490367 ITERATION : 97, loss : 0.1960418923490367 ITERATION : 98, loss : 0.1960418923490367 ITERATION : 99, loss : 0.1960418923490367 ITERATION : 100, loss : 0.1960418923490367 
ITERATION : 1, loss : 0.255937789810027 ITERATION : 2, loss : 0.255937789810027 ITERATION : 3, loss : 0.255937789810027 ITERATION : 4, loss : 0.255937789810027 ITERATION : 5, loss : 0.255937789810027 ITERATION : 6, loss : 0.255937789810027 ITERATION : 7, loss : 0.255937789810027 ITERATION : 8, loss : 0.255937789810027 ITERATION : 9, loss : 0.255937789810027 ITERATION : 10, loss : 0.255937789810027 ITERATION : 11, loss : 0.255937789810027 ITERATION : 12, loss : 0.255937789810027 ITERATION : 13, loss : 0.255937789810027 ITERATION : 14, loss : 0.255937789810027 ITERATION : 15, loss : 0.255937789810027 ITERATION : 16, loss : 0.255937789810027 ITERATION : 17, loss : 0.255937789810027 ITERATION : 18, loss : 0.255937789810027 ITERATION : 19, loss : 0.255937789810027 ITERATION : 20, loss : 0.255937789810027 ITERATION : 21, loss : 0.255937789810027 ITERATION : 22, loss : 0.255937789810027 ITERATION : 23, loss : 0.255937789810027 ITERATION : 24, loss : 0.255937789810027 ITERATION : 25, loss : 0.255937789810027 ITERATION : 26, loss : 0.255937789810027 ITERATION : 27, loss : 0.255937789810027 ITERATION : 28, loss : 0.255937789810027 ITERATION : 29, loss : 0.255937789810027 ITERATION : 30, loss : 0.255937789810027 ITERATION : 31, loss : 0.255937789810027 ITERATION : 32, loss : 0.255937789810027 ITERATION : 33, loss : 0.255937789810027 ITERATION : 34, loss : 0.255937789810027 ITERATION : 35, loss : 0.255937789810027 ITERATION : 36, loss : 0.255937789810027 ITERATION : 37, loss : 0.255937789810027 ITERATION : 38, loss : 0.255937789810027 ITERATION : 39, loss : 0.255937789810027 ITERATION : 40, loss : 0.255937789810027 ITERATION : 41, loss : 0.255937789810027 ITERATION : 42, loss : 0.255937789810027 ITERATION : 43, loss : 0.255937789810027 ITERATION : 44, loss : 0.255937789810027 ITERATION : 45, loss : 0.255937789810027 ITERATION : 46, loss : 0.255937789810027 ITERATION : 47, loss : 0.255937789810027 ITERATION : 48, loss : 0.255937789810027 ITERATION : 49, loss : 0.255937789810027 ITERATION : 50, loss : 0.255937789810027 ITERATION : 51, loss : 0.255937789810027 ITERATION : 52, loss : 0.255937789810027 ITERATION : 53, loss : 0.255937789810027 ITERATION : 54, loss : 0.255937789810027 ITERATION : 55, loss : 0.255937789810027 ITERATION : 56, loss : 0.255937789810027 ITERATION : 57, loss : 0.255937789810027 ITERATION : 58, loss : 0.255937789810027 ITERATION : 59, loss : 0.255937789810027 ITERATION : 60, loss : 0.255937789810027 ITERATION : 61, loss : 0.255937789810027 ITERATION : 62, loss : 0.255937789810027 ITERATION : 63, loss : 0.255937789810027 ITERATION : 64, loss : 0.255937789810027 ITERATION : 65, loss : 0.255937789810027 ITERATION : 66, loss : 0.255937789810027 ITERATION : 67, loss : 0.255937789810027 ITERATION : 68, loss : 0.255937789810027 ITERATION : 69, loss : 0.255937789810027 ITERATION : 70, loss : 0.255937789810027 ITERATION : 71, loss : 0.255937789810027 ITERATION : 72, loss : 0.255937789810027 ITERATION : 73, loss : 0.255937789810027 ITERATION : 74, loss : 0.255937789810027 ITERATION : 75, loss : 0.255937789810027 ITERATION : 76, loss : 0.255937789810027 ITERATION : 77, loss : 0.255937789810027 ITERATION : 78, loss : 0.255937789810027 ITERATION : 79, loss : 0.255937789810027 ITERATION : 80, loss : 0.255937789810027 ITERATION : 81, loss : 0.255937789810027 ITERATION : 82, loss : 0.255937789810027 ITERATION : 83, loss : 0.255937789810027 ITERATION : 84, loss : 0.255937789810027 ITERATION : 85, loss : 0.255937789810027 ITERATION : 86, loss : 0.255937789810027 ITERATION : 87, loss : 0.255937789810027 ITERATION : 88, loss : 0.255937789810027 ITERATION : 89, loss : 0.255937789810027 ITERATION : 90, loss : 0.255937789810027 ITERATION : 91, loss : 0.255937789810027 ITERATION : 92, loss : 0.255937789810027 ITERATION : 93, loss : 0.255937789810027 ITERATION : 94, loss : 0.255937789810027 ITERATION : 95, loss : 0.255937789810027 ITERATION : 96, loss : 0.255937789810027 ITERATION : 97, loss : 0.255937789810027 ITERATION : 98, loss : 0.255937789810027 ITERATION : 99, loss : 0.255937789810027 ITERATION : 100, loss : 0.255937789810027 
ITERATION : 1, loss : 0.022798997132628968 ITERATION : 2, loss : 0.023069933845406166 ITERATION : 3, loss : 0.023704211954715608 ITERATION : 4, loss : 0.024894800800867263 ITERATION : 5, loss : 0.026197677668563506 ITERATION : 6, loss : 0.027378305729926153 ITERATION : 7, loss : 0.028357000989889348 ITERATION : 8, loss : 0.02912918695013463 ITERATION : 9, loss : 0.02972038327359938 ITERATION : 10, loss : 0.030164353266145073 ITERATION : 11, loss : 0.030493527982906114 ITERATION : 12, loss : 0.030735502191614437 ITERATION : 13, loss : 0.03091234433082396 ITERATION : 14, loss : 0.031041077192979587 ITERATION : 15, loss : 0.031134539463852078 ITERATION : 16, loss : 0.03120227409764209 ITERATION : 17, loss : 0.03125130553497662 ITERATION : 18, loss : 0.03128677173427662 ITERATION : 19, loss : 0.03131241416462304 ITERATION : 20, loss : 0.0313309492376234 ITERATION : 21, loss : 0.03134434551511495 ITERATION : 22, loss : 0.031354027652049886 ITERATION : 23, loss : 0.03136102580966086 ITERATION : 24, loss : 0.03136608454396594 ITERATION : 25, loss : 0.03136974178485327 ITERATION : 26, loss : 0.03137238626422618 ITERATION : 27, loss : 0.0313742987453964 ITERATION : 28, loss : 0.03137568214554474 ITERATION : 29, loss : 0.03137668294520183 ITERATION : 30, loss : 0.03137740715789099 ITERATION : 31, loss : 0.031377931293234004 ITERATION : 32, loss : 0.03137831068905921 ITERATION : 33, loss : 0.031378585367760295 ITERATION : 34, loss : 0.03137878425432663 ITERATION : 35, loss : 0.031378928303476196 ITERATION : 36, loss : 0.0313790326433057 ITERATION : 37, loss : 0.03137910824027538 ITERATION : 38, loss : 0.031379163060984455 ITERATION : 39, loss : 0.031379202749035225 ITERATION : 40, loss : 0.03137923154156146 ITERATION : 41, loss : 0.03137925239026527 ITERATION : 42, loss : 0.03137926753020075 ITERATION : 43, loss : 0.03137927852411424 ITERATION : 44, loss : 0.031379286501367634 ITERATION : 45, loss : 0.03137929231545096 ITERATION : 46, loss : 0.03137929647667649 ITERATION : 47, loss : 0.03137929949477537 ITERATION : 48, loss : 0.03137930166603073 ITERATION : 49, loss : 0.031379303239283854 ITERATION : 50, loss : 0.03137930436401767 ITERATION : 51, loss : 0.031379305192837506 ITERATION : 52, loss : 0.031379305787699985 ITERATION : 53, loss : 0.03137930623646906 ITERATION : 54, loss : 0.03137930655129064 ITERATION : 55, loss : 0.031379306736283516 ITERATION : 56, loss : 0.03137930691884413 ITERATION : 57, loss : 0.03137930699761861 ITERATION : 58, loss : 0.03137930708937319 ITERATION : 59, loss : 0.03137930716626349 ITERATION : 60, loss : 0.03137930720200038 ITERATION : 61, loss : 0.03137930722151769 ITERATION : 62, loss : 0.03137930722871672 ITERATION : 63, loss : 0.03137930722871672 ITERATION : 64, loss : 0.03137930722871672 ITERATION : 65, loss : 0.03137930722871672 ITERATION : 66, loss : 0.03137930722871672 ITERATION : 67, loss : 0.03137930722871672 ITERATION : 68, loss : 0.03137930722871672 ITERATION : 69, loss : 0.03137930722871672 ITERATION : 70, loss : 0.03137930722871672 ITERATION : 71, loss : 0.03137930722871672 ITERATION : 72, loss : 0.03137930722871672 ITERATION : 73, loss : 0.03137930722871672 ITERATION : 74, loss : 0.03137930722871672 ITERATION : 75, loss : 0.03137930722871672 ITERATION : 76, loss : 0.03137930722871672 ITERATION : 77, loss : 0.03137930722871672 ITERATION : 78, loss : 0.03137930722871672 ITERATION : 79, loss : 0.03137930722871672 ITERATION : 80, loss : 0.03137930722871672 ITERATION : 81, loss : 0.03137930722871672 ITERATION : 82, loss : 0.03137930722871672 ITERATION : 83, loss : 0.03137930722871672 ITERATION : 84, loss : 0.03137930722871672 ITERATION : 85, loss : 0.03137930722871672 ITERATION : 86, loss : 0.03137930722871672 ITERATION : 87, loss : 0.03137930722871672 ITERATION : 88, loss : 0.03137930722871672 ITERATION : 89, loss : 0.03137930722871672 ITERATION : 90, loss : 0.03137930722871672 ITERATION : 91, loss : 0.03137930722871672 ITERATION : 92, loss : 0.03137930722871672 ITERATION : 93, loss : 0.03137930722871672 ITERATION : 94, loss : 0.03137930722871672 ITERATION : 95, loss : 0.03137930722871672 ITERATION : 96, loss : 0.03137930722871672 ITERATION : 97, loss : 0.03137930722871672 ITERATION : 98, loss : 0.03137930722871672 ITERATION : 99, loss : 0.03137930722871672 ITERATION : 100, loss : 0.03137930722871672 
ITERATION : 1, loss : 0.19760602826770687 ITERATION : 2, loss : 0.19760602826770687 ITERATION : 3, loss : 0.19760602826770687 ITERATION : 4, loss : 0.19760602826770687 ITERATION : 5, loss : 0.19760602826770687 ITERATION : 6, loss : 0.19760602826770687 ITERATION : 7, loss : 0.19760602826770687 ITERATION : 8, loss : 0.19760602826770687 ITERATION : 9, loss : 0.19760602826770687 ITERATION : 10, loss : 0.19760602826770687 ITERATION : 11, loss : 0.19760602826770687 ITERATION : 12, loss : 0.19760602826770687 ITERATION : 13, loss : 0.19760602826770687 ITERATION : 14, loss : 0.19760602826770687 ITERATION : 15, loss : 0.19760602826770687 ITERATION : 16, loss : 0.19760602826770687 ITERATION : 17, loss : 0.19760602826770687 ITERATION : 18, loss : 0.19760602826770687 ITERATION : 19, loss : 0.19760602826770687 ITERATION : 20, loss : 0.19760602826770687 ITERATION : 21, loss : 0.19760602826770687 ITERATION : 22, loss : 0.19760602826770687 ITERATION : 23, loss : 0.19760602826770687 ITERATION : 24, loss : 0.19760602826770687 ITERATION : 25, loss : 0.19760602826770687 ITERATION : 26, loss : 0.19760602826770687 ITERATION : 27, loss : 0.19760602826770687 ITERATION : 28, loss : 0.19760602826770687 ITERATION : 29, loss : 0.19760602826770687 ITERATION : 30, loss : 0.19760602826770687 ITERATION : 31, loss : 0.19760602826770687 ITERATION : 32, loss : 0.19760602826770687 ITERATION : 33, loss : 0.19760602826770687 ITERATION : 34, loss : 0.19760602826770687 ITERATION : 35, loss : 0.19760602826770687 ITERATION : 36, loss : 0.19760602826770687 ITERATION : 37, loss : 0.19760602826770687 ITERATION : 38, loss : 0.19760602826770687 ITERATION : 39, loss : 0.19760602826770687 ITERATION : 40, loss : 0.19760602826770687 ITERATION : 41, loss : 0.19760602826770687 ITERATION : 42, loss : 0.19760602826770687 ITERATION : 43, loss : 0.19760602826770687 ITERATION : 44, loss : 0.19760602826770687 ITERATION : 45, loss : 0.19760602826770687 ITERATION : 46, loss : 0.19760602826770687 ITERATION : 47, loss : 0.19760602826770687 ITERATION : 48, loss : 0.19760602826770687 ITERATION : 49, loss : 0.19760602826770687 ITERATION : 50, loss : 0.19760602826770687 ITERATION : 51, loss : 0.19760602826770687 ITERATION : 52, loss : 0.19760602826770687 ITERATION : 53, loss : 0.19760602826770687 ITERATION : 54, loss : 0.19760602826770687 ITERATION : 55, loss : 0.19760602826770687 ITERATION : 56, loss : 0.19760602826770687 ITERATION : 57, loss : 0.19760602826770687 ITERATION : 58, loss : 0.19760602826770687 ITERATION : 59, loss : 0.19760602826770687 ITERATION : 60, loss : 0.19760602826770687 ITERATION : 61, loss : 0.19760602826770687 ITERATION : 62, loss : 0.19760602826770687 ITERATION : 63, loss : 0.19760602826770687 ITERATION : 64, loss : 0.19760602826770687 ITERATION : 65, loss : 0.19760602826770687 ITERATION : 66, loss : 0.19760602826770687 ITERATION : 67, loss : 0.19760602826770687 ITERATION : 68, loss : 0.19760602826770687 ITERATION : 69, loss : 0.19760602826770687 ITERATION : 70, loss : 0.19760602826770687 ITERATION : 71, loss : 0.19760602826770687 ITERATION : 72, loss : 0.19760602826770687 ITERATION : 73, loss : 0.19760602826770687 ITERATION : 74, loss : 0.19760602826770687 ITERATION : 75, loss : 0.19760602826770687 ITERATION : 76, loss : 0.19760602826770687 ITERATION : 77, loss : 0.19760602826770687 ITERATION : 78, loss : 0.19760602826770687 ITERATION : 79, loss : 0.19760602826770687 ITERATION : 80, loss : 0.19760602826770687 ITERATION : 81, loss : 0.19760602826770687 ITERATION : 82, loss : 0.19760602826770687 ITERATION : 83, loss : 0.19760602826770687 ITERATION : 84, loss : 0.19760602826770687 ITERATION : 85, loss : 0.19760602826770687 ITERATION : 86, loss : 0.19760602826770687 ITERATION : 87, loss : 0.19760602826770687 ITERATION : 88, loss : 0.19760602826770687 ITERATION : 89, loss : 0.19760602826770687 ITERATION : 90, loss : 0.19760602826770687 ITERATION : 91, loss : 0.19760602826770687 ITERATION : 92, loss : 0.19760602826770687 ITERATION : 93, loss : 0.19760602826770687 ITERATION : 94, loss : 0.19760602826770687 ITERATION : 95, loss : 0.19760602826770687 ITERATION : 96, loss : 0.19760602826770687 ITERATION : 97, loss : 0.19760602826770687 ITERATION : 98, loss : 0.19760602826770687 ITERATION : 99, loss : 0.19760602826770687 ITERATION : 100, loss : 0.19760602826770687 
